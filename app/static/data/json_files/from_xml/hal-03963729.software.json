{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:45+0000", "md5": "C423EBEB2671FBD042EE381984106238", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 0, "offsetEnd": 9}, "context": "CamemBERT (Martin et al., 2020) and FlauBERT (Le et al., 2020) are two of the most popular contemporary French models, both trained with masked language modeling.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006771087646484375}, "created": {"value": false, "score": 0.00016069412231445312}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12, "offsetStart": 3850, "offsetEnd": 3871}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3", "normalizedForm": "DeBERTaV3", "offsetStart": 3, "offsetEnd": 12}, "context": "In DeBERTaV3, the authors hypothesized and showed that sharing token embeddings between the generator and the discriminator results in a tugof-war situation, where the MLM and RTD tasks pull the embedding vectors into opposing directions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": false, "score": 0.0007625818252563477}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}, {"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEMBERTA", "normalizedForm": "CAMEMBERTA", "offsetStart": 13, "offsetEnd": 23}, "context": "Architecture CAMEMBERTA is based on the DeBERTaV3 (He et al., 2021b) architecture which uses two vectors to encode the word and its position, with the premise being that the relative position of a word pair should also directly affect the computed attention weights. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004176616668701172}, "created": {"value": false, "score": 0.0024469494819641113}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8742814660072327}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEMBERTA", "normalizedForm": "CAMEMBERTA", "offsetStart": 13, "offsetEnd": 23}, "context": "We presented CAMEMBERTA, a data-efficient French language model trained on a large corpus of French text and the first publicly available DeBERTaV3-style pretrained model and implementation. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.893013000488281e-05}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8742814660072327}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 20, "offsetEnd": 29}, "context": "5 Moreover we reuse CamemBERT CCN et 's tokenizer (Kudo and Richardson, 2018).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999383807182312}, "created": {"value": false, "score": 4.482269287109375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FrALBERT", "normalizedForm": "FrALBERT", "offsetStart": 21, "offsetEnd": 29}, "context": "Other models include FrALBERT (Cattan et al., 2021), a French version of ALBERT (Lan et al., 2020), LePetit (Micheli et al., 2020) which is a small version of CamemBERT, and D'AlemBERT (Gabay et al., 2022), a RoBERTa (Liu et al., 2020) based language model targeted towards Early Modern French.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015674233436584473}, "created": {"value": false, "score": 0.00020629167556762695}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9646902680397034}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Cattan et al., 2021)", "normalizedForm": "Cattan et al., 2021", "refKey": 7, "offsetStart": 4033, "offsetEnd": 4054}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 23, "offsetEnd": 32}, "context": "We compare our models, CamemBERT CCN et , and CamemBERT 30% , on a diverse set of French downstream tasks and datasets, namely: Question Answering (QA) on FQuAD 1.0 (d'Hoffschmidt et al., 2020), Part-Of-Speech (POS) tagging and Dependency Parsing on GSD (McDonald et al., 2013), Rhapsodie (Lacheret et al., 2014), Sequoia (Candito and Seddah, 2012;Candito et al., 2014) in their UD v2.2 versions and the French Social Media Bank7  (Seddah et al., 2012), Named Entity Recognition (NER) on the 2008 version of FTB (Abeill\u00e9 et al., 2000;Candito and Crabb\u00e9, 2009) with NER annotation by Sagot et al. (2012), and the FLUE benchmark (Le et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985629916191101}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3", "normalizedForm": "DeBERTaV3", "offsetStart": 33, "offsetEnd": 42}, "context": "We propose a model trained using DeBERTaV3 style pre-training along with an optimized training implementation, which reduces training computation cost when compared to previous models, and hence greatly reduces the energy cost and environmental impact of language model training. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019782781600952148}, "created": {"value": true, "score": 0.9998267292976379}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}, {"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FlauBERT", "normalizedForm": "FlauBERT", "offsetStart": 36, "offsetEnd": 44}, "context": "CamemBERT (Martin et al., 2020) and FlauBERT (Le et al., 2020) are two of the most popular contemporary French models, both trained with masked language modeling.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006771087646484375}, "created": {"value": false, "score": 0.00016069412231445312}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994984865188599}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Le et al., 2020)", "normalizedForm": "Le et al., 2020", "refKey": 28, "offsetStart": 3885, "offsetEnd": 3902}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FlauBERT", "normalizedForm": "FlauBERT", "offsetStart": 38, "offsetEnd": 46}, "context": "Additionally, it is worth noting that FlauBERT was trained for 17 days with 32 V100 GPUs, which is equivalent to 60 days of training on 6 A40 GPUs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994984865188599}, "created": {"value": false, "score": 1.8835067749023438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994984865188599}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Le et al., 2020)", "normalizedForm": "Le et al., 2020", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3", "normalizedForm": "DeBERTaV3", "offsetStart": 40, "offsetEnd": 49}, "context": "Architecture CAMEMBERTA is based on the DeBERTaV3 (He et al., 2021b) architecture which uses two vectors to encode the word and its position, with the premise being that the relative position of a word pair should also directly affect the computed attention weights.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004176616668701172}, "created": {"value": false, "score": 0.0024469494819641113}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0, "offsetStart": 4900, "offsetEnd": 4918}, {"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0, "offsetStart": 4900, "offsetEnd": 4918}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 43, "offsetEnd": 52}, "context": "Nevertheless, we also ran experiments with CamemBERT OSCAR , and found that it performed slightly worse than CamemBERT CCN et , as shown in Table 5 Appendix A.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999947190284729}, "created": {"value": false, "score": 0.0008696913719177246}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 46, "offsetEnd": 55}, "context": "We compare our models, CamemBERT CCN et , and CamemBERT 30% , on a diverse set of French downstream tasks and datasets, namely: Question Answering (QA) on FQuAD 1.0 (d'Hoffschmidt et al., 2020), Part-Of-Speech (POS) tagging and Dependency Parsing on GSD (McDonald et al., 2013), Rhapsodie (Lacheret et al., 2014), Sequoia (Candito and Seddah, 2012;Candito et al., 2014) in their UD v2.2 versions and the French Social Media Bank7  (Seddah et al., 2012), Named Entity Recognition (NER) on the 2008 version of FTB (Abeill\u00e9 et al., 2000;Candito and Crabb\u00e9, 2009) with NER annotation by Sagot et al. (2012), and the FLUE benchmark (Le et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985629916191101}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3 TensorFLow 2", "normalizedForm": "DeBERTaV3 TensorFLow 2", "offsetStart": 46, "offsetEnd": 68}, "publisher": {"rawForm": "HuggingFace", "normalizedForm": "HuggingFace", "offsetStart": 97, "offsetEnd": 108}, "context": "We also note that at the time of writing, the DeBERTaV3 TensorFLow 2 implementation available on HuggingFace's Transformers library (Wolf et al., 2020) experiences heavy slowdowns with TPU backends. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.021601498126983643}, "created": {"value": false, "score": 0.0009943842887878418}, "shared": {"value": false, "score": 4.887580871582031e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.021601498126983643}, "created": {"value": false, "score": 0.0009943842887878418}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 47, "offsetEnd": 56}, "context": "Our results in Table 1, surprisingly show that CamemBERT 30% outperforms CamemBERT CCN et , while not being statistically better than our model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99720299243927}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELECTRA", "normalizedForm": "ELECTRA", "offsetStart": 49, "offsetEnd": 56}, "context": "Our training implementation is based on Nvidia's ELECTRA and BERT TensorFlow2 implementations. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5862536430358887}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9907827973365784}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Clark et al., 2020)", "normalizedForm": "Clark et al., 2020", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 50, "offsetEnd": 59}, "context": "Our experiments showed that our model outperforms CamemBERT 30% on all tasks except NER on FTB, and that it is able to match and even surpass CamemBERT CCN et .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9635665416717529}, "created": {"value": false, "score": 0.004678905010223389}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 61, "offsetEnd": 70}, "context": "The results shown in Table 2 show that our model outperforms CamemBERT 30% by 6.01 F1 points, but shows no statistically significant improvement over CamemBERT CCN et F1 score, and exact match (EM) score.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8821614980697632}, "created": {"value": false, "score": 2.6345252990722656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT TensorFlow2", "normalizedForm": "BERT TensorFlow2", "offsetStart": 61, "offsetEnd": 77}, "context": "Our training implementation is based on Nvidia's ELECTRA and BERT TensorFlow2 implementations. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5862536430358887}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5862536430358887}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 63, "offsetEnd": 72}, "context": "Table 1 shows that our proposed model consistently outperforms CamemBERT 30% , and competes with CamemBERT CCN et on all 4 treebanks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011252403259277344}, "created": {"value": false, "score": 0.0007715225219726562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 65, "offsetEnd": 74}, "context": "For a fair evaluation we reused the same corpus and tokenizer as CamemBERT CCN et , but using only 30% of the total number of input training tokens.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": false, "score": 4.76837158203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 68, "offsetEnd": 77}, "context": "Hence for a fair comparison, we train a RoBERTa model, which we dub CamemBERT 30% , using our same exact pretraining setup but with the MLM objective.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008287429809570312}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 73, "offsetEnd": 82}, "context": "Our results in Table 1, surprisingly show that CamemBERT 30% outperforms CamemBERT CCN et , while not being statistically better than our model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99720299243927}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 82, "offsetEnd": 91}, "context": "Moreover, our model implementation is able to match or outperform a fully trained CamemBERT model, trained on around 3 times more samples and more compute. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005558788776397705}, "created": {"value": false, "score": 0.3687937259674072}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELECTRA", "normalizedForm": "ELECTRA", "offsetStart": 83, "offsetEnd": 90}, "context": "He et al. (2021a) later showed that performance could be further improved by using ELECTRA's (Clark et al., 2020) self-supervised and sample-efficient replaced token detection objective.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9907827973365784}, "created": {"value": false, "score": 0.0006646513938903809}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9907827973365784}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Clark et al., 2020)", "normalizedForm": "Clark et al., 2020", "refKey": 8, "offsetStart": 878, "offsetEnd": 898}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEMBERTA", "normalizedForm": "CAMEMBERTA", "offsetStart": 84, "offsetEnd": 94}, "context": "This represents a 7.5-fold increase in computational resources employed compared to CAMEMBERTA.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8742814660072327}, "created": {"value": false, "score": 8.797645568847656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8742814660072327}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3", "normalizedForm": "DeBERTaV3", "offsetStart": 85, "offsetEnd": 112}, "context": "To achieve this goal, we propose a new data-efficient French language model based on DeBERTaV3 (He et al., 2021a). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012540817260742188}, "created": {"value": true, "score": 0.9998841285705566}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}, {"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 87, "offsetEnd": 96}, "context": "During pre-training, our model would have seen 133B tokens compared to 419B tokens for CamemBERT CCN et which was trained for 100K steps.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9964205026626587}, "created": {"value": false, "score": 0.00017470121383666992}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 96, "offsetEnd": 105}, "context": "Pre-training Compute and CO2 Impact Our model was trained for 8 days on 6 A40 GPUs, compared to CamemBERT which was trained on 256 V100 GPUs for one day, which is roughly equivalent to 28 days of training on 6 A40 GPUs, since an NVIDIA A40 GPU is about 1.5x faster than a V100 GPU on language modeling tasks according to recent benchmarks.8", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995734095573425}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 97, "offsetEnd": 106}, "context": "Table 1 shows that our proposed model consistently outperforms CamemBERT 30% , and competes with CamemBERT CCN et on all 4 treebanks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011252403259277344}, "created": {"value": false, "score": 0.0007715225219726562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "offsetStart": 100, "offsetEnd": 107}, "context": "We use the dataset splits as provided by their respective authors, and we finetune using welltested scripts from the Hugging Face Transformers library and the HOPS parser (Grobol and Crabb\u00e9, 2021). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9635215997695923}, "created": {"value": false, "score": 7.593631744384766e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9635215997695923}, "created": {"value": false, "score": 7.593631744384766e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 102, "offsetEnd": 111}, "context": "We pre-train on the French subset of CCNet4  (Wenzek et al., 2020), the same corpus used to pre-train CamemBERT CCN et (Martin et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.99138343334198}, "created": {"value": false, "score": 4.4465065002441406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12, "offsetStart": 7169, "offsetEnd": 7190}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 109, "offsetEnd": 118}, "context": "Nevertheless, we also ran experiments with CamemBERT OSCAR , and found that it performed slightly worse than CamemBERT CCN et , as shown in Table 5 Appendix A.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999947190284729}, "created": {"value": false, "score": 0.0008696913719177246}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEM", "normalizedForm": "CAMEM", "offsetStart": 116, "offsetEnd": 121}, "context": "We compared the performance of both models in addition to an MLM model trained from scratch under the same setup as CAMEM-BERTA, CamemBERT 30% , on a variety of downstream tasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998865127563477}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998934268951416}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEMBERTA", "normalizedForm": "CAMEMBERTA", "offsetStart": 128, "offsetEnd": 138}, "context": "Our experiments clearly show that given the same training corpus, tokenizer, and total number of examples seen during training, CAMEMBERTA outperforms the MLM trained CamemBERT model on all tasks except NER on FTB and POS tagging on Rhapsodie. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3838024139404297}, "created": {"value": false, "score": 8.7738037109375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8742814660072327}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 129, "offsetEnd": 138}, "context": "We compared the performance of both models in addition to an MLM model trained from scratch under the same setup as CAMEM-BERTA, CamemBERT 30% , on a variety of downstream tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998865127563477}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 134, "offsetEnd": 143}, "context": "Our results (Table 3) show that our model outperforms all models on the CLS movie classification task, and matches the performance of CamemBERT CCN et on the other FLUE tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994791150093079}, "created": {"value": false, "score": 0.00014579296112060547}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeBERTaV3", "normalizedForm": "DeBERTaV3", "offsetStart": 138, "offsetEnd": 147}, "context": "We presented CAMEMBERTA, a data-efficient French language model trained on a large corpus of French text and the first publicly available DeBERTaV3-style pretrained model and implementation.", "mentionContextAttributes": {"used": {"value": false, "score": 8.893013000488281e-05}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.47277241945266724}, "created": {"value": true, "score": 0.999925971031189}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}, {"label": "(He et al., 2021b)", "normalizedForm": "He et al., 2021b", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 142, "offsetEnd": 151}, "context": "Our experiments showed that our model outperforms CamemBERT 30% on all tasks except NER on FTB, and that it is able to match and even surpass CamemBERT CCN et .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9635671973228455}, "created": {"value": false, "score": 0.004678905010223389}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 150, "offsetEnd": 159}, "context": "The results shown in Table 2 show that our model outperforms CamemBERT 30% by 6.01 F1 points, but shows no statistically significant improvement over CamemBERT CCN et F1 score, and exact match (EM) score.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8821617364883423}, "created": {"value": false, "score": 2.6345252990722656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 159, "offsetEnd": 168}, "context": "Other models include FrALBERT (Cattan et al., 2021), a French version of ALBERT (Lan et al., 2020), LePetit (Micheli et al., 2020) which is a small version of CamemBERT, and D'AlemBERT (Gabay et al., 2022), a RoBERTa (Liu et al., 2020) based language model targeted towards Early Modern French.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015674233436584473}, "created": {"value": false, "score": 0.00020629167556762695}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELECTRA", "normalizedForm": "ELECTRA", "offsetStart": 166, "offsetEnd": 193}, "context": "Training Objective We follow the DeBER-TaV3 (He et al., 2021a) pretraining strategy by using the replaced token detection (RTD) pre-training loss first introduced in ELECTRA (Clark et al., 2020), with a generator and discriminator based on the DeBERTa architecture. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03577369451522827}, "created": {"value": false, "score": 0.0002339482307434082}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9907827973365784}, "created": {"value": true, "score": 0.967687726020813}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Clark et al., 2020)", "normalizedForm": "Clark et al., 2020", "refKey": 8}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 167, "offsetEnd": 176}, "context": "Our experiments clearly show that given the same training corpus, tokenizer, and total number of examples seen during training, CAMEMBERTA outperforms the MLM trained CamemBERT model on all tasks except NER on FTB and POS tagging on Rhapsodie. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3838024139404297}, "created": {"value": false, "score": 8.7738037109375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FlauBERT", "normalizedForm": "FlauBERT", "offsetStart": 175, "offsetEnd": 201}, "context": "Last but not least, other competitive language models for French are available and although not the primary focus of this paper, we conducted a comparative analysis involving FlauBERT (Le et al., 2020) and FrALBERT (Cattan et al., 2021). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9646902680397034}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994984865188599}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Le et al., 2020)", "normalizedForm": "Le et al., 2020", "refKey": 28}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FrALBERT", "normalizedForm": "FrALBERT", "offsetStart": 206, "offsetEnd": 235}, "context": "Last but not least, other competitive language models for French are available and although not the primary focus of this paper, we conducted a comparative analysis involving FlauBERT (Le et al., 2020) and FrALBERT (Cattan et al., 2021). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9646902680397034}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9646902680397034}, "created": {"value": false, "score": 0.026057660579681396}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Cattan et al., 2021)", "normalizedForm": "Cattan et al., 2021", "refKey": 7}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAMEM-", "normalizedForm": "CAMEM", "offsetStart": 236, "offsetEnd": 242}, "context": "Following the reports by Luccioni et al. ( 2022) and Cattan et al. (2022) on the environmental impact of language model training, we use Lannelongue et al.'s (2021) online carbon footprint calculator to provide the following estimates: CAMEM-BERTA's pre-training used 700kWh and emitted 36kg CO 2 compared to 3.32MWh and 170kg for CamemBERT.9", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998934268951416}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998934268951416}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 331, "offsetEnd": 340}, "context": "Following the reports by Luccioni et al. ( 2022) and Cattan et al. (2022) on the environmental impact of language model training, we use Lannelongue et al.'s (2021) online carbon footprint calculator to provide the following estimates: CAMEM-BERTA's pre-training used 700kWh and emitted 36kg CO 2 compared to 3.32MWh and 170kg for CamemBERT.9", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998934268951416}, "created": {"value": false, "score": 1.2278556823730469e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999962568283081}, "created": {"value": true, "score": 0.8620224595069885}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "(Martin et al., 2020)", "normalizedForm": "Martin et al., 2020", "refKey": 12}]}], "references": [{"refKey": 12, "tei": "<biblStruct xml:id=\"b12\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Maxime</forename><surname>Martin D'hoffschmidt</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wacim</forename><surname>Vidal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tom</forename><surname>Belblidia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><surname>Brendl\u00e9</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:2002.06071</idno>\n\t\t<title level=\"m\">FQuAD: French Question Answering Dataset</title>\n\t\t<imprint>\n\t\t\t<date>2020</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<monogr>\n\t\t<title level=\"m\" type=\"main\">Data-Efficient French Language Modeling with CamemBERTa</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wissam</forename><surname>Antoun</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Djam\u00e9</forename><surname>Seddah</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2023.findings-acl.320</idno>\n\t\t<idno>05F1C97B5DC6CA3CD393E25F0AF380F2</idno>\n\t\t<imprint>\n\t\t\t<date></date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 7, "tei": "<biblStruct xml:id=\"b7\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">On the Usability of Transformers-based models for a French Question-Answering task</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Oralie</forename><surname>Cattan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christophe</forename><surname>Servan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sophie</forename><surname>Rosset</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Recent Advances in Natural Language Processing (RANLP)</title>\n\t\t<imprint>\n\t\t\t<date>2021</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 28, "tei": "<biblStruct xml:id=\"b28\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">FlauBERT: Unsupervised language model pre-training for French</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hang</forename><surname>Le</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lo\u00efc</forename><surname>Vial</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jibril</forename><surname>Frej</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vincent</forename><surname>Segonne</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Maximin</forename><surname>Coavoux</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Lecouteux</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alexandre</forename><surname>Allauzen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benoit</forename><surname>Crabb\u00e9</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Laurent</forename><surname>Besacier</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Didier</forename><surname>Schwab</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>\n\t\t<meeting>the Twelfth Language Resources and Evaluation Conference</meeting>\n\t\t<imprint>\n\t\t\t<publisher>European Language Resources Association</publisher>\n\t\t\t<date>2020</date>\n\t\t\t<biblScope unit=\"page\">2490</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 8, "tei": "<biblStruct xml:id=\"b8\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">ELECTRA: Pretraining text encoders as discriminators rather than generators</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kevin</forename><surname>Clark</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Minh-Thang</forename><surname>Luong</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Quoc</forename><forename type=\"middle\">V</forename><surname>Le</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><forename type=\"middle\">D</forename><surname>Manning</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">ICLR</title>\n\t\t<imprint>\n\t\t\t<date>2020</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 21487, "id": "cd80c3b594f993687b91a820b05de5a3925e0f7b", "metadata": {"id": "cd80c3b594f993687b91a820b05de5a3925e0f7b"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03963729.grobid.tei.xml", "file_name": "hal-03963729.grobid.tei.xml"}