{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:50+0000", "md5": "FC2404C078F34E12FB2AD64426332028", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 0, "offsetEnd": 3}, "context": "AMD encountered an error during launch, so evaluation results only available for four of the matchers are presented in Table 13.", "mentionContextAttributes": {"used": {"value": true, "score": 0.990655243396759}, "created": {"value": false, "score": 2.3484230041503906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 0, "offsetEnd": 3}, "context": "AMD produced errors and an empty alignment file, so results are only available for three of the matchers: LogMap, LogMapLt, Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9928433299064636}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN and LogMap can both ask the oracle to analyze several conflicting correspondences simultaneously.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000731050968170166}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN is the system that improves the most, because of its high number of oracle requests, and its non-interactive performance was the lowest of the interactive systems, and thus the easiest to improve.", "mentionContextAttributes": {"used": {"value": false, "score": 0.021719694137573242}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 0, "offsetEnd": 5}, "context": "SEALS provided a software infrastructure for automatically executing evaluations and evaluation campaigns for typical semantic web tools, including ontology matching. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003854036331176758}, "created": {"value": false, "score": 0.01518547534942627}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 0, "offsetEnd": 5}, "context": "OLaLa outperformed all other matchers in the Nell-DBpedia task, whereas Matcha excelled on the larger dataset, Yago-Wikidata. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989826083183289}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 0, "offsetEnd": 5}, "context": "OLaLa, PropMatch, and SORBETMatcher are three new systems participating this year.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014269351959228516}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 0, "offsetEnd": 5}, "context": "OLaLa has shown notable performance improvements, with a (4%) increase in the discrete case and a (2%) increase in the continuous case concerning F-measure when compared to the sharp reference alignment.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01101374626159668}, "created": {"value": false, "score": 4.00543212890625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 0, "offsetEnd": 5}, "context": "OLaLa's F-measure has risen from (61%) to (65%) in the discrete case and to (63%) in the continuous case.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9845851063728333}, "created": {"value": false, "score": 4.494190216064453e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 0, "offsetEnd": 5}, "context": "SEALS, and Web format.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011396408081054688}, "created": {"value": false, "score": 8.630752563476562e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap requests feedback on only selected correspondences candidates (based on their similarity patterns or their involvement in unsatisfiabilities). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007023811340332031}, "created": {"value": false, "score": 1.7523765563964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap presents a maximum precision value of 1.0, however since only one correspondence was found by LogMap, the recall and hence the F1-measure is low (0.083). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08864885568618774}, "created": {"value": false, "score": 7.3909759521484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha finds 8 incorrect correspondences and thus is the worst-performing participant in terms of precision in the first test case. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.30678629875183105}, "created": {"value": false, "score": 4.6372413635253906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha finds 6 wrong correspondences where classes are matched to object properties as in the first test case. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.14807891845703125}, "created": {"value": false, "score": 9.298324584960938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha presents the lowest precision in this test case but the highest recall. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032880306243896484}, "created": {"value": false, "score": 5.1021575927734375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap computes 3 false positives, LogMapLt computes 5 false positives and Matcha 3 false positives. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011346518993377686}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha also showcased the ability to function with the original datasets, a capability it lacked in the 2022 evaluation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03718209266662598}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap, Matcha, and SOR-BETMatcher do not return any of those mappings. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1242484450340271}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha obtains the best results for the FNC application. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03362381458282471}, "created": {"value": false, "score": 2.09808349609375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha's F-measure jumped from (12%) in continuous and (14%) in discrete last year to (63%) in continuous and (65%) in discrete this year, primarily due to an increase in precision.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9986045956611633}, "created": {"value": false, "score": 9.882450103759766e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha in its current implementation is not recommended for MSE applications since it matches classes to properties.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001537799835205078}, "created": {"value": false, "score": 0.0005522370338439941}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatchaC", "normalizedForm": "MatchaC", "offsetStart": 0, "offsetEnd": 7}, "context": "MatchaC, the only system specifically designed to generate expressive correspondences, had some problems dealing with the datasets and was not able to generate any valid alignment.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012618541717529297}, "created": {"value": false, "score": 0.00025469064712524414}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.2259642481803894}, "created": {"value": false, "score": 0.00043004751205444336}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERTMap", "normalizedForm": "BERTMap", "offsetStart": 0, "offsetEnd": 7}, "context": "BERTMap also attains the best ranking scores of all tasks, though most systems do not provide ranking results in equivalence matching. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017260313034057617}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 2.5510787963867188e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt remains the system with the shortest runtime. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009746551513671875}, "created": {"value": false, "score": 2.777576446533203e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt is significantly slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004712343215942383}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt is significantly slower in every test case and almost constantly shows worse results -only in the first test case the recall of LogMapLt is higher than for LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009494423866271973}, "created": {"value": false, "score": 2.193450927734375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapKG", "normalizedForm": "LogMapKG", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapKG on the other hand tends to only align instances when it is applied to full-size datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.441375732421875e-05}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt stands out for its very fast computing speed. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.230571746826172e-05}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 0, "offsetEnd": 13}, "context": "SORBETMatcher attains the best MRR on 3 out of 5 subsumption tasks, while BERTSubs (IC) and OWL2Vec*+RF attain the best MRR on each of the remaining two, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004269659519195557}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 4, "offsetEnd": 8}, "context": "The MELT framework5  [22] was introduced in 2019 and is under active development.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026482343673706055}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 2.7418136596679688e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 4, "offsetEnd": 9}, "context": "The SEALS client was developed in 2011. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.90493392944336e-05}, "created": {"value": true, "score": 0.9902030229568481}, "shared": {"value": false, "score": 3.6954879760742188e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 4, "offsetEnd": 10}, "context": "The HOBBIT platform 4 was introduced in 2017.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021666288375854492}, "created": {"value": false, "score": 0.23444974422454834}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 4, "offsetEnd": 11}, "context": "The MatOnto Ontology v2.1 25 (847 classes, 96 properties and 131 individuals) bases on the upper-level ontology bfo2 26 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": true, "score": 0.9513481259346008}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 6, "offsetEnd": 12}, "context": "While LogMap makes use of user interactions exclusively in the post-matching steps to filter their candidate correspondences, ALIN can also add new candidate correspondences to its initial set. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.898143768310547e-05}, "created": {"value": false, "score": 3.24249267578125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 6, "offsetEnd": 12}, "context": "Since LogMap found only 59 correct correspondences out of the 302 reference correspondences, the recall is rather low, but the F1-measure is still the highest of the tested systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9777728915214539}, "created": {"value": false, "score": 9.5367431640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 6, "offsetEnd": 14}, "context": "While LogMapLt and LogMap are dedicated to generating simple correspondences, only LogMap was able to generate non-empty alignments. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8772717714309692}, "created": {"value": false, "score": 2.1219253540039062e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 7, "offsetEnd": 16}, "context": "OLaLa, PropMatch, and SORBETMatcher are three new systems participating this year.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014269351959228516}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 8, "offsetEnd": 14}, "context": "LogMap, Matcha, and SOR-BETMatcher do not return any of those mappings. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1242484450340271}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 9, "offsetEnd": 15}, "context": "ALIN and LogMap can both ask the oracle to analyze several conflicting correspondences simultaneously.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000731050968170166}, "created": {"value": false, "score": 5.602836608886719e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 9, "offsetEnd": 16}, "context": "Notably, LSMatch exhibited the most significant performance surge at (16%), closely followed by ALIN at (15%) and AMD at (14%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995926022529602}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 9, "offsetEnd": 18}, "context": "Notably, PropMatch exhibits consistently lower precision and recall across the three different versions of the reference alignment, primarily due to its narrow focus on property matching.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006216764450073242}, "created": {"value": false, "score": 7.128715515136719e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 9, "offsetEnd": 21}, "context": "Notably, GraphMatcher stood out by producing the highest F-measure under both continuous (73%) and discrete (73%) evaluation methodologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991662502288818}, "created": {"value": false, "score": 1.4781951904296875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatchaC", "normalizedForm": "MatchaC", "offsetStart": 11, "offsetEnd": 18}, "context": "This year, MatchaC, LogMap and LogMapLt have been registered to participate. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2259642481803894}, "created": {"value": false, "score": 0.00043004751205444336}, "shared": {"value": false, "score": 2.4318695068359375e-05}}, "documentContextAttributes": {"used": {"value": false, "score": 0.2259642481803894}, "created": {"value": false, "score": 0.00043004751205444336}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 12, "offsetEnd": 18}, "context": "In summary, LogMap stands out for its very fast computing speed with very high precision at the same time. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.225440979003906e-05}, "created": {"value": false, "score": 0.00019472837448120117}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 14, "offsetEnd": 20}, "context": "Surprisingly, LogMap performs the matching task significantly quicker than in the first test case and stands out for its very fast computation time of only 6s at a high precision of 0.881. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012658238410949707}, "created": {"value": false, "score": 3.790855407714844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 15, "offsetEnd": 18}, "context": "Four matchers (AMD, ALIN, LSMatch, and SORBETMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011765241622924805}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 16, "offsetEnd": 22}, "context": "This year, only LogMap has participated in the SPIMBENCH and Link Discovery tracks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5966901779174805}, "created": {"value": false, "score": 4.565715789794922e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 16, "offsetEnd": 22}, "context": "In our opinion, LogMap is definitely recommended for MSE applications where high precision is demanded. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012218952178955078}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 17, "offsetEnd": 22}, "context": "It relies on the SEALS client's Oracle class to simulate user interactions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009515881538391113}, "created": {"value": false, "score": 5.9723854064941406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 17, "offsetEnd": 23}, "context": "At the same time Matcha computes with 56 the highest number of true positives, which results in the best precision of the tested systems.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4162619113922119}, "created": {"value": false, "score": 1.4185905456542969e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 19, "offsetEnd": 25}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.818), but four other systems obtained an F-measure above 0.88 (OLaLa, SORBETMatcher, LogMapBio, and LogMap) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 19, "offsetEnd": 25}, "context": "While LogMapLt and LogMap are dedicated to generating simple correspondences, only LogMap was able to generate non-empty alignments. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8772717714309692}, "created": {"value": false, "score": 2.1219253540039062e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 19, "offsetEnd": 25}, "context": "Regarding runtime, Matcha (14:30:03) and LogMapLt (64:48:07) were the slowest systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998794794082642}, "created": {"value": false, "score": 3.039836883544922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 19, "offsetEnd": 28}, "context": "The exception were LogMapBio which increase in F-measure (from 0.895 to 0.898) and Matcha increased in recall+ (from 0.817 to 0.818), in size (from 1482 to 1484). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9533567428588867}, "created": {"value": false, "score": 8.940696716308594e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 19, "offsetEnd": 28}, "context": "On the other side, PropMatch does not match classes at all, while it dominates in matching properties. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007504820823669434}, "created": {"value": false, "score": 7.653236389160156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 19, "offsetEnd": 28}, "context": "On the other hand, PropMatch and SORBETMatcher have demonstrated similar performance in both discrete and continuous cases when compared to the sharp reference alignment in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6176577210426331}, "created": {"value": false, "score": 2.396106719970703e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 20, "offsetEnd": 24}, "context": "Four matchers (AMD, ALIN, LSMatch, and SORBETMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011765241622924805}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 20, "offsetEnd": 26}, "context": "This year, MatchaC, LogMap and LogMapLt have been registered to participate. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2259642481803894}, "created": {"value": false, "score": 0.00043004751205444336}, "shared": {"value": false, "score": 2.4318695068359375e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 21, "offsetEnd": 25}, "context": "Since last year, the MELT framework [22] has been adopted to facilitate the SEALS and HOBBIT wrapping and evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008088946342468262}, "created": {"value": false, "score": 0.001821279525756836}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 22, "offsetEnd": 27}, "context": "For some systems, the SEALS client has been used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02226346731185913}, "created": {"value": false, "score": 0.0009044408798217773}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 22, "offsetEnd": 27}, "context": "In terms of run time, OLaLa took the longer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979275465011597}, "created": {"value": false, "score": 7.700920104980469e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 22, "offsetEnd": 28}, "context": "However, two systems, Matcha and TOMATO, exhibited significant improvements this year.", "mentionContextAttributes": {"used": {"value": false, "score": 0.05490154027938843}, "created": {"value": false, "score": 0.00031697750091552734}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 22, "offsetEnd": 35}, "context": "OLaLa, PropMatch, and SORBETMatcher are three new systems participating this year.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014269351959228516}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 23, "offsetEnd": 29}, "context": "In terms of precision, Matcha and LogMapLt had a higher precision in detriment of recall. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995143413543701}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 23, "offsetEnd": 29}, "context": "It is supra-linear for LogMap in all datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009012222290039062}, "created": {"value": false, "score": 7.3909759521484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 23, "offsetEnd": 31}, "context": "In comparison to that, LogMapLt does not appear to bring any decisive advantage over LogMap.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009702444076538086}, "created": {"value": false, "score": 0.00018233060836791992}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 24, "offsetEnd": 28}, "context": "This year, two systems (ALIN, and LogMap) participated in the Interactive matching track. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9622641801834106}, "created": {"value": false, "score": 3.6835670471191406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 24, "offsetEnd": 30}, "context": "In direct comparison to LogMap, LogMapLt calculates the alignment in around half the time and achieves much lower precision (0.4) but due to a greater amount of correctly found correspondences, the F1-measure is better -although still low with 0.143. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002789318561553955}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 25, "offsetEnd": 31}, "context": "Based on its F1-measure, Matcha performs slightly better than the other systems in this test case.", "mentionContextAttributes": {"used": {"value": false, "score": 0.050202369689941406}, "created": {"value": false, "score": 3.0040740966796875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 25, "offsetEnd": 37}, "context": "The remaining 5 systems (GraphMatcher, LogMap, Matcha, OLaLa, and PropMatch) have a wide variation of confidence values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004512667655944824}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 26, "offsetEnd": 32}, "context": "The request intervals for LogMap and ALIN stay at a few milliseconds for most datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11620205640792847}, "created": {"value": false, "score": 1.621246337890625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 26, "offsetEnd": 33}, "context": "Four matchers (AMD, ALIN, LSMatch, and SORBETMatcher) do not match properties at all. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011765241622924805}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 29, "offsetEnd": 33}, "context": "Starting with this year, the MELT framework also supports the SSSOM [24] format.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040096044540405273}, "created": {"value": false, "score": 8.594989776611328e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepOnto", "normalizedForm": "DeepOnto", "offsetStart": 29, "offsetEnd": 37}, "context": "https://krr-oxford.github.io/DeepOnto/#/", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024813413619995117}, "created": {"value": false, "score": 1.4424324035644531e-05}, "shared": {"value": true, "score": 0.8526651263237}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999755620956421}, "created": {"value": false, "score": 8.559226989746094e-05}, "shared": {"value": true, "score": 0.8526651263237}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 29, "offsetEnd": 42}, "context": "It is also worth noting that SORBETMatcher is the only system can participate in both equivalence and subsumption matching.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013238787651062012}, "created": {"value": false, "score": 0.00022906064987182617}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 30, "offsetEnd": 35}, "context": "The results obtained with the SEALS client vary in some cases by 0.5% compared to the results presented in Section 4.2.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999936819076538}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 31, "offsetEnd": 39}, "context": "This year, MatchaC, LogMap and LogMapLt have been registered to participate. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.2259642481803894}, "created": {"value": false, "score": 0.00043004751205444336}, "shared": {"value": false, "score": 2.4318695068359375e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 32, "offsetEnd": 36}, "context": "Alternatively, they can use the MELT framework to assist them, as it can be used to wrap any matching system as docker container implementing the HTTP interface.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002250969409942627}, "created": {"value": false, "score": 0.0006147623062133789}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 32, "offsetEnd": 40}, "context": "In direct comparison to LogMap, LogMapLt calculates the alignment in around half the time and achieves much lower precision (0.4) but due to a greater amount of correctly found correspondences, the F1-measure is better -although still low with 0.143. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002789318561553955}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 32, "offsetEnd": 44}, "context": "However, it's worth noting that GraphMatcher experienced relatively small drops in F-measure when transitioning from discrete to continuous evaluation, primarily due to a decrease in precision.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9057496786117554}, "created": {"value": false, "score": 1.2159347534179688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 33, "offsetEnd": 46}, "context": "On the other hand, PropMatch and SORBETMatcher have demonstrated similar performance in both discrete and continuous cases when compared to the sharp reference alignment in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6176577210426331}, "created": {"value": false, "score": 2.396106719970703e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 34, "offsetEnd": 38}, "context": "They have been computed using the MELT framework without applying any threshold to the results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999961853027344}, "created": {"value": false, "score": 6.115436553955078e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 34, "offsetEnd": 40}, "context": "This year, two systems (ALIN, and LogMap) participated in the Interactive matching track. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9622641801834106}, "created": {"value": false, "score": 3.6835670471191406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 34, "offsetEnd": 40}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 34, "offsetEnd": 42}, "context": "In terms of precision, Matcha and LogMapLt had a higher precision in detriment of recall. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995143413543701}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 35, "offsetEnd": 39}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 35, "offsetEnd": 41}, "context": "In contrast to the results of 2022 Matcha performs the matching task almost as quickly as LogMap, which stood out for its very fast calculation time. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020449161529541016}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 35, "offsetEnd": 43}, "context": "LogMap computes 3 false positives, LogMapLt computes 5 false positives and Matcha 3 false positives. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011346518993377686}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 36, "offsetEnd": 40}, "context": "This year, most tracks have adopted MELT as their evaluation platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005083084106445312}, "created": {"value": false, "score": 0.002118408679962158}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 36, "offsetEnd": 40}, "context": "Out of the 11 alignment systems, 6 (ALIN, AMD, LogMapLt, LSMatch, SOR-BETMatcher, and TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014800667762756348}, "created": {"value": false, "score": 2.7894973754882812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 36, "offsetEnd": 41}, "context": "The evaluation was carried out on a Linux virtual machine with 128 GB of RAM and 16 vCPUs (2.4 GHz) processors. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 2.2530555725097656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9802322387695312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 36, "offsetEnd": 41}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor of MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006478428840637207}, "created": {"value": false, "score": 0.00021463632583618164}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 36, "offsetEnd": 41}, "context": "Regarding the ENVO-SWEET task, only OLaLa and the LogMap family systems achieved it with a similar performance to last year.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991023540496826}, "created": {"value": false, "score": 4.5299530029296875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 37, "offsetEnd": 41}, "context": "The request intervals for LogMap and ALIN stay at a few milliseconds for most datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11620205640792847}, "created": {"value": false, "score": 1.621246337890625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 38, "offsetEnd": 42}, "context": "In 2023, 12 systems were submitted as MELT Web docker container, 3 systems were submitted as SEALS package, 1 system was uploaded to the HOBBIT platform, and one system implemented the Web interface directly and provided hosting for the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7880107760429382}, "created": {"value": false, "score": 0.0002796053886413574}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 38, "offsetEnd": 44}, "context": "LogMapLt is significantly slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004712343215942383}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 38, "offsetEnd": 44}, "context": "Last year, similar to this year, only Matcha, LogMap and LogMapLt were able to generate non-empty alignments, with LogMapLt being able to generate a higher number of correspondences. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9325309991836548}, "created": {"value": false, "score": 5.4001808166503906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 39, "offsetEnd": 43}, "context": "The evaluation was performed using the MELT platform on a Windows 11 system with Intel Core i7-1260P CPU @2.10GHz and 16 GB RAM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999984860420227}, "created": {"value": false, "score": 2.872943878173828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 39, "offsetEnd": 43}, "context": "The evaluation was performed using the MELT platform.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999966621398926}, "created": {"value": false, "score": 0.00019401311874389648}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 39, "offsetEnd": 43}, "context": "The evaluation was performed using the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999966621398926}, "created": {"value": false, "score": 2.849102020263672e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 39, "offsetEnd": 45}, "context": "The remaining 5 systems (GraphMatcher, LogMap, Matcha, OLaLa, and PropMatch) have a wide variation of confidence values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004512667655944824}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 39, "offsetEnd": 52}, "context": "Four matchers (AMD, ALIN, LSMatch, and SORBETMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011765241622924805}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 40, "offsetEnd": 43}, "context": "Similar to the 2022 evaluation results, AMD does generate schema alignments but in the wrong format, therefore, they can not be evaluated.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08105093240737915}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 40, "offsetEnd": 44}, "context": "The evalua-tion was performed using the MELT platform.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 40, "offsetEnd": 45}, "context": "Some tracks are run exclusively through SEALS and others through HOBBIT, but several allow participants to choose their preferred platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009214162826538086}, "created": {"value": false, "score": 0.0005623698234558105}, "shared": {"value": false, "score": 0.00013327598571777344}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "In terms of the NELL-DBpedia test case, LogMap, OLaLa, Matcha, and AMD were able to generate results when applied to the full-size dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 2.372264862060547e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 40, "offsetEnd": 46}, "context": "The highest recall is again achieved by Matcha (0.84).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9098466038703918}, "created": {"value": false, "score": 0.0001927018165588379}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 41, "offsetEnd": 49}, "context": "Regarding runtime, Matcha (14:30:03) and LogMapLt (64:48:07) were the slowest systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998794794082642}, "created": {"value": false, "score": 3.039836883544922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 42, "offsetEnd": 45}, "context": "Out of the 11 alignment systems, 6 (ALIN, AMD, LogMapLt, LSMatch, SOR-BETMatcher, and TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014800667762756348}, "created": {"value": false, "score": 2.7894973754882812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 42, "offsetEnd": 50}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 42, "offsetEnd": 51}, "context": "Two systems produced coherent alignments (LogMapBio and LogMap). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.027911007404327393}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 42, "offsetEnd": 55}, "context": "Two systems were first-time participants (SORBETMatcher, OLaLa).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9952881336212158}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under a Intel Core CPU 2.00GHz x8 cores. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9938313961029053}, "created": {"value": false, "score": 0.0028766989707946777}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9802322387695312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under a Intel Core CPU 2.00GHz x8 processors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9942511320114136}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.86102294921875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9802322387695312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under an Intel Core CPU 2.00GHz x8 processors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9940751791000366}, "created": {"value": false, "score": 0.004393398761749268}, "shared": {"value": false, "score": 2.9802322387695312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9802322387695312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM It is seen that a similar number of systems have participated in the campaign through the years. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9851282238960266}, "created": {"value": false, "score": 0.001104593276977539}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999802112579346}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9802322387695312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepOnto", "normalizedForm": "DeepOnto", "offsetStart": 44, "offsetEnd": 60}, "context": "All our evaluations were conducted with the DeepOnto18  [38] library on a local machine with Intel Xeon Bronze 3204 CPU 1.90GHz x11 processors, 126GB RAM, and two Quadro RTX 8000 GPUs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999755620956421}, "created": {"value": false, "score": 8.559226989746094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999755620956421}, "created": {"value": false, "score": 8.559226989746094e-05}, "shared": {"value": true, "score": 0.8526651263237}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 45, "offsetEnd": 52}, "context": "https://raw.githubusercontent.com/iNovexIrad/MatOnto-Ontologies/master/matonto-release.ttl", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001417398452758789}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": true, "score": 0.9513481259346008}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": true, "score": 0.9513481259346008}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 46, "offsetEnd": 52}, "context": "Last year, similar to this year, only Matcha, LogMap and LogMapLt were able to generate non-empty alignments, with LogMapLt being able to generate a higher number of correspondences. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9325309991836548}, "created": {"value": false, "score": 5.4001808166503906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 47, "offsetEnd": 53}, "context": "The remaining 5 systems (GraphMatcher, LogMap, Matcha, OLaLa, and PropMatch) have a wide variation of confidence values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004512667655944824}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 47, "offsetEnd": 55}, "context": "Out of the 11 alignment systems, 6 (ALIN, AMD, LogMapLt, LSMatch, SOR-BETMatcher, and TOMATO) use 1.0 as the confidence value for all matches they identify. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.014800667762756348}, "created": {"value": false, "score": 2.7894973754882812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 48, "offsetEnd": 52}, "context": "For evaluating all possible submission formats, MELT framework is used.", "mentionContextAttributes": {"used": {"value": true, "score": 0.996480405330658}, "created": {"value": false, "score": 0.00012683868408203125}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 48, "offsetEnd": 52}, "context": "The impact of the oracle's errors is linear for ALIN in most tasks, as the F-measure according to the oracle remains approximately constant across all error rates.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011071443557739258}, "created": {"value": false, "score": 2.658367156982422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 48, "offsetEnd": 53}, "context": "In terms of the NELL-DBpedia test case, LogMap, OLaLa, Matcha, and AMD were able to generate results when applied to the full-size dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 2.372264862060547e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 49, "offsetEnd": 52}, "context": "Similar to the previous years, some systems like AMD need a post-processing step of the resulting alignment file to be able to parse it.", "mentionContextAttributes": {"used": {"value": false, "score": 5.996227264404297e-05}, "created": {"value": false, "score": 0.00011265277862548828}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 49, "offsetEnd": 53}, "context": "This year we evaluated all participants with the MELT framework to include all possible submission formats i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999711513519287}, "created": {"value": false, "score": 0.0003103017807006836}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 49, "offsetEnd": 55}, "context": "Investigating the reason for this low precision, Matcha appears to match classes with object  properties, e.g. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016478300094604492}, "created": {"value": false, "score": 2.658367156982422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 50, "offsetEnd": 56}, "context": "Regarding the ENVO-SWEET task, only OLaLa and the LogMap family systems achieved it with a similar performance to last year.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991023540496826}, "created": {"value": false, "score": 4.5299530029296875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 51, "offsetEnd": 59}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 51, "offsetEnd": 59}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 51, "offsetEnd": 59}, "context": "Apart from the runtime, the results for LogMap and LogMapLt do not change in comparison to the evaluation in 2022. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971451163291931}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pellet", "normalizedForm": "Pellet", "offsetStart": 52, "offsetEnd": 58}, "context": "Alignments are also checked for coherence using the Pellet reasoner. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995187520980835}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995187520980835}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapKG", "normalizedForm": "LogMapKG", "offsetStart": 52, "offsetEnd": 60}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 54, "offsetEnd": 59}, "context": "This year, three submission formats were allowed: (1) SEALS package, (2) HOBBIT, and (3) MELT Web interface.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5441403985023499}, "created": {"value": false, "score": 0.0001589059829711914}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 55, "offsetEnd": 59}, "context": "Second, for systems that have been well-adapted to the MELT platform, we used MELT to produce the output mappings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994677901268005}, "created": {"value": false, "score": 0.011402904987335205}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 55, "offsetEnd": 60}, "context": "The remaining 5 systems (GraphMatcher, LogMap, Matcha, OLaLa, and PropMatch) have a wide variation of confidence values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004512667655944824}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 55, "offsetEnd": 61}, "context": "Since OAEI 2017, a novel evaluation environment called HOBBIT (Section 2.1) was adopted for the HOBBIT Link Discovery track, and later extended to enable the evaluation of other tracks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014102458953857422}, "created": {"value": false, "score": 0.10334759950637817}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 55, "offsetEnd": 61}, "context": "In terms of the NELL-DBpedia test case, LogMap, OLaLa, Matcha, and AMD were able to generate results when applied to the full-size dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 2.372264862060547e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 56, "offsetEnd": 62}, "context": "Two systems produced coherent alignments (LogMapBio and LogMap). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.027911007404327393}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 57, "offsetEnd": 62}, "context": "Two systems were first-time participants (SORBETMatcher, OLaLa).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9952881336212158}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 57, "offsetEnd": 64}, "context": "Out of the 11 alignment systems, 6 (ALIN, AMD, LogMapLt, LSMatch, SOR-BETMatcher, and TOMATO) use 1.0 as the confidence value for all matches they identify. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.014800667762756348}, "created": {"value": false, "score": 2.7894973754882812e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 57, "offsetEnd": 65}, "context": "Last year, similar to this year, only Matcha, LogMap and LogMapLt were able to generate non-empty alignments, with LogMapLt being able to generate a higher number of correspondences. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9325309991836548}, "created": {"value": false, "score": 5.4001808166503906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Windows 11", "normalizedForm": "Windows 11", "offsetStart": 58, "offsetEnd": 68}, "context": "The evaluation was performed using the MELT platform on a Windows 11 system with Intel Core i7-1260P CPU @2.10GHz and 16 GB RAM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999984860420227}, "created": {"value": false, "score": 2.872943878173828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999984860420227}, "created": {"value": false, "score": 2.872943878173828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 59, "offsetEnd": 65}, "context": "Since the recall is the best of the participating systems, Matcha turns out to be the best-performing system based on its F1-measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07221090793609619}, "created": {"value": false, "score": 0.0001824498176574707}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 60, "offsetEnd": 66}, "context": "Some matching systems participated with different variants (Matcha and LogMap), whereas others were evaluated with different configurations, as requested by developers (see test case sections for details). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9725551605224609}, "created": {"value": false, "score": 0.00018900632858276367}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 62, "offsetEnd": 68}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 62, "offsetEnd": 74}, "context": "Several systems use reference alignments to a certain extent (GraphMatcher uses it in its 5-fold cross-validation and TOMATO uses it in its sampling process) for their model learning, as has happened with some ML-based systems in the past. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006644129753112793}, "created": {"value": false, "score": 3.409385681152344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 65, "offsetEnd": 70}, "context": "We evaluated all the participating systems that were packaged as SEALS packages or as web services using Docker (even those not registered to participate on this new track). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998176693916321}, "created": {"value": false, "score": 7.390975952148438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 65, "offsetEnd": 71}, "context": "Some tracks are run exclusively through SEALS and others through HOBBIT, but several allow participants to choose their preferred platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009214162826538086}, "created": {"value": false, "score": 0.0005623698234558105}, "shared": {"value": false, "score": 0.00013327598571777344}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 66, "offsetEnd": 75}, "context": "The remaining 5 systems (GraphMatcher, LogMap, Matcha, OLaLa, and PropMatch) have a wide variation of confidence values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004512667655944824}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 67, "offsetEnd": 70}, "context": "In terms of the NELL-DBpedia test case, LogMap, OLaLa, Matcha, and AMD were able to generate results when applied to the full-size dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 2.372264862060547e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 71, "offsetEnd": 74}, "context": "This is the second year of the track and five systems were registered: AMD, LogMap, LogMapLt, OLaLa and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8963443636894226}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 71, "offsetEnd": 77}, "context": "Some matching systems participated with different variants (Matcha and LogMap), whereas others were evaluated with different configurations, as requested by developers (see test case sections for details). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9725551605224609}, "created": {"value": false, "score": 0.00018900632858276367}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 71, "offsetEnd": 77}, "context": "A-LIOn produces moderate results but does not bring any advantage over LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.7738037109375e-05}, "created": {"value": false, "score": 1.5854835510253906e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 72, "offsetEnd": 77}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 72, "offsetEnd": 78}, "context": "OLaLa outperformed all other matchers in the Nell-DBpedia task, whereas Matcha excelled on the larger dataset, Yago-Wikidata. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989826083183289}, "created": {"value": false, "score": 3.910064697265625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 72, "offsetEnd": 78}, "context": "Besides the baselines (which need around 12 minutes for all test cases) LogMap (00:56:43) and SORBETMatcher (00:21:53) were the fastest systems.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994580149650574}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 73, "offsetEnd": 78}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 73, "offsetEnd": 78}, "context": "All evaluated systems compute the alignment in less than a minute except OLaLa.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976624250411987}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 73, "offsetEnd": 79}, "context": "This year, three submission formats were allowed: (1) SEALS package, (2) HOBBIT, and (3) MELT Web interface.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5441403985023499}, "created": {"value": false, "score": 0.0001589059829711914}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 75, "offsetEnd": 81}, "context": "LogMap computes 3 false positives, LogMapLt computes 5 false positives and Matcha 3 false positives. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011346518993377686}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 75, "offsetEnd": 82}, "context": "This year, 4 systems have registered to participate in the Multifarm track:LSMatch-Multilingual, LogMap, LogMapLt, and Matcha.", "mentionContextAttributes": {"used": {"value": false, "score": 0.029211580753326416}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 76, "offsetEnd": 81}, "context": "Since last year, the MELT framework [22] has been adopted to facilitate the SEALS and HOBBIT wrapping and evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008088946342468262}, "created": {"value": false, "score": 0.001821279525756836}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 76, "offsetEnd": 82}, "context": "This is the second year of the track and five systems were registered: AMD, LogMap, LogMapLt, OLaLa and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8963443636894226}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 76, "offsetEnd": 82}, "context": "All the systems registered to OAEI 2023 were run besides the fact that only LogMap has been registered to participate in all tracks and no system has been specifically registered to the Crosswalks task.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9944928884506226}, "created": {"value": false, "score": 2.586841583251953e-05}, "shared": {"value": false, "score": 3.707408905029297e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 77, "offsetEnd": 81}, "context": "As a baseline, we utilize a simple string matcher which is available through MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2962518334388733}, "created": {"value": false, "score": 0.0889885425567627}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 77, "offsetEnd": 82}, "context": "The OAEI evaluation was conducted in one of three alternative platforms: the SEALS client, the HOBBIT platform, or the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": false, "score": 8.654594421386719e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 78, "offsetEnd": 82}, "context": "Second, for systems that have been well-adapted to the MELT platform, we used MELT to produce the output mappings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994677901268005}, "created": {"value": false, "score": 0.011402904987335205}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 78, "offsetEnd": 84}, "context": "While most matchers demonstrated similar performance to previous evaluations, Matcha notably improved its results on both datasets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998061060905457}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 80, "offsetEnd": 86}, "context": "For this first year of the Pharmacogenomics track, 2 systems registered, namely LogMap and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831594228744507}, "created": {"value": false, "score": 0.00012612342834472656}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERTMap", "normalizedForm": "BERTMap", "offsetStart": 80, "offsetEnd": 87}, "context": "It is worth mentioning that the Bio-ML track has additional participants (e.g., BERTMap [58] and BERTSubs [59]) that are not listed in Table 8.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009117186069488525}, "created": {"value": false, "score": 2.5510787963867188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 2.5510787963867188e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58, "offsetStart": 35762, "offsetEnd": 35766}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 82, "offsetEnd": 87}, "context": "This year saw the return of different matchers and the introduction of a new one, OLaLa. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019124150276184082}, "created": {"value": false, "score": 0.04128134250640869}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 83, "offsetEnd": 89}, "context": "The exception were LogMapBio which increase in F-measure (from 0.895 to 0.898) and Matcha increased in recall+ (from 0.817 to 0.818), in size (from 1482 to 1484). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9533567428588867}, "created": {"value": false, "score": 8.940696716308594e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 83, "offsetEnd": 89}, "context": "While LogMapLt and LogMap are dedicated to generating simple correspondences, only LogMap was able to generate non-empty alignments. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8772717714309692}, "created": {"value": false, "score": 2.1219253540039062e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 83, "offsetEnd": 92}, "context": "For equivalence matching, top performing systems vary across different tasks, with LogMapBio attaining the best F1 on 2 out of 5 unsupervised tasks, and AMD, BERTMap, and SORBETMatcher attaining the best F1 on each of the remaining three, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0069664716720581055}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 84, "offsetEnd": 88}, "context": "It has also been highlighted the need to push the adoption of SSSOM [24] (this year MELT has incorporated the format but still few systems have adopted it), as a way for delivering richer alignments in terms of metadata and justifications [67].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005421042442321777}, "created": {"value": false, "score": 0.0010129809379577637}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 84, "offsetEnd": 92}, "context": "This is the second year of the track and five systems were registered: AMD, LogMap, LogMapLt, OLaLa and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8963443636894226}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 85, "offsetEnd": 88}, "context": "For systems requiring more RAM, the evaluation was carried out on a computer with an AMD Ryzen 7 5700G 3.80 GHz CPU and 32GB RAM, with 10GB of max heap space allocated to java.Each system was run ten times and the final result of a system for each error rate represents the average of these runs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998328685760498}, "created": {"value": false, "score": 6.413459777832031e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 85, "offsetEnd": 91}, "context": "In comparison to that, LogMapLt does not appear to bring any decisive advantage over LogMap.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009702444076538086}, "created": {"value": false, "score": 0.00018233060836791992}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 86, "offsetEnd": 92}, "context": "Since last year, the MELT framework [22] has been adopted to facilitate the SEALS and HOBBIT wrapping and evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008088946342468262}, "created": {"value": false, "score": 0.001821279525756836}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 89, "offsetEnd": 93}, "context": "This year, three submission formats were allowed: (1) SEALS package, (2) HOBBIT, and (3) MELT Web interface.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5441403985023499}, "created": {"value": false, "score": 0.0001589059829711914}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 90, "offsetEnd": 96}, "context": "In contrast to the results of 2022 Matcha performs the matching task almost as quickly as LogMap, which stood out for its very fast calculation time. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020449161529541016}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 91, "offsetEnd": 95}, "context": "For further analysis of the results, we also provide an online dashboard 37 generated with MELT [65].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998760223388672}, "created": {"value": false, "score": 3.1828880310058594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65, "offsetStart": 64335, "offsetEnd": 64339}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 91, "offsetEnd": 97}, "context": "For this first year of the Pharmacogenomics track, 2 systems registered, namely LogMap and Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9831594228744507}, "created": {"value": false, "score": 0.00012612342834472656}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 93, "offsetEnd": 98}, "context": "In 2023, 12 systems were submitted as MELT Web docker container, 3 systems were submitted as SEALS package, 1 system was uploaded to the HOBBIT platform, and one system implemented the Web interface directly and provided hosting for the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7880107760429382}, "created": {"value": false, "score": 0.0002796053886413574}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 93, "offsetEnd": 98}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only OLaLa, Matcha, and AMD were able to generate alignments with the original dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996137022972107}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 93, "offsetEnd": 101}, "context": "On the YagoWikidata dataset, two systems were not able to outperform the baseline, which are LogMapLt and LsMatch. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984458088874817}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 94, "offsetEnd": 99}, "context": "This is the second year of the track and five systems were registered: AMD, LogMap, LogMapLt, OLaLa and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8963443636894226}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 94, "offsetEnd": 107}, "context": "Besides the baselines (which need around 12 minutes for all test cases) LogMap (00:56:43) and SORBETMatcher (00:21:53) were the fastest systems.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994580149650574}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 95, "offsetEnd": 101}, "context": "The OAEI evaluation was conducted in one of three alternative platforms: the SEALS client, the HOBBIT platform, or the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": false, "score": 8.654594421386719e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 95, "offsetEnd": 103}, "context": "Other systems either fail to complete the task within the allocated 24-hour time limit such as LogMapLt and LsMatch, or produce an empty alignment file such as LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019341707229614258}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 96, "offsetEnd": 100}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor of MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006478428840637207}, "created": {"value": false, "score": 0.00021463632583618164}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 96, "offsetEnd": 100}, "context": "Notably, LSMatch exhibited the most significant performance surge at (16%), closely followed by ALIN at (15%) and AMD at (14%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995926022529602}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 96, "offsetEnd": 102}, "context": "Since OAEI 2017, a novel evaluation environment called HOBBIT (Section 2.1) was adopted for the HOBBIT Link Discovery track, and later extended to enable the evaluation of other tracks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014102458953857422}, "created": {"value": false, "score": 0.10334759950637817}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 97, "offsetEnd": 103}, "context": "This year, 4 systems have registered to participate in the Multifarm track:LSMatch-Multilingual, LogMap, LogMapLt, and Matcha. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.029211580753326416}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 100, "offsetEnd": 104}, "context": "Third, for systems that have been implemented elsewhere and are not easy to be made compatible with MELT, we used their source code.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9662821292877197}, "created": {"value": false, "score": 0.0006645321846008301}, "shared": {"value": false, "score": 3.2186508178710938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 100, "offsetEnd": 104}, "context": "In the final result tables, we used superscripts \u2020, \u2021, and * to indicate that the results came from MELT, source code implementation, and direct result submission, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999825954437256}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 100, "offsetEnd": 106}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only OLaLa, Matcha, and AMD were able to generate alignments with the original dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996137022972107}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 101, "offsetEnd": 107}, "context": "LogMap presents a maximum precision value of 1.0, however since only one correspondence was found by LogMap, the recall and hence the F1-measure is low (0.083). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08864885568618774}, "created": {"value": false, "score": 7.3909759521484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 104, "offsetEnd": 109}, "context": "It allows the development, evaluation, and packaging of matching systems for evaluation interfaces like SEALS or HOBBIT. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.921985626220703e-05}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 104, "offsetEnd": 110}, "context": "This is the second year of the track and five systems were registered: AMD, LogMap, LogMapLt, OLaLa and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8963443636894226}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "offsetStart": 105, "offsetEnd": 111}, "context": "We evaluated all the participating systems that were packaged as SEALS packages or as web services using Docker (even those not registered to participate on this new track). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998176693916321}, "created": {"value": false, "score": 7.390975952148438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": false, "score": 7.390975952148438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "offsetStart": 105, "offsetEnd": 111}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": false, "score": 7.390975952148438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 105, "offsetEnd": 113}, "context": "This year, 4 systems have registered to participate in the Multifarm track:LSMatch-Multilingual, LogMap, LogMapLt, and Matcha. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.029211580753326416}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 105, "offsetEnd": 113}, "context": "While generating a few number of correct correspondences, precision is higher with respect to recall for LogMapLt and Matcha are the systems that are able to deal with a higher number of matching pairs. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012063980102539062}, "created": {"value": false, "score": 3.3020973205566406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 106, "offsetEnd": 112}, "context": "AMD produced errors and an empty alignment file, so results are only available for three of the matchers: LogMap, LogMapLt, Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9928433299064636}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LsMatch", "normalizedForm": "LsMatch", "offsetStart": 106, "offsetEnd": 113}, "context": "On the YagoWikidata dataset, two systems were not able to outperform the baseline, which are LogMapLt and LsMatch. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984458088874817}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 108, "offsetEnd": 112}, "context": "The evaluation was carried out on a machine with a 5 core CPU @ 1.80 GHz with 16GB allocated RAM, using the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999679327011108}, "created": {"value": false, "score": 1.7642974853515625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LsMatch", "normalizedForm": "LsMatch", "offsetStart": 108, "offsetEnd": 115}, "context": "Other systems either fail to complete the task within the allocated 24-hour time limit such as LogMapLt and LsMatch, or produce an empty alignment file such as LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019341707229614258}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 112, "offsetEnd": 115}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only OLaLa, Matcha, and AMD were able to generate alignments with the original dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996137022972107}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 113, "offsetEnd": 119}, "context": "It allows the development, evaluation, and packaging of matching systems for evaluation interfaces like SEALS or HOBBIT. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.921985626220703e-05}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 114, "offsetEnd": 117}, "context": "Notably, LSMatch exhibited the most significant performance surge at (16%), closely followed by ALIN at (15%) and AMD at (14%).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995926022529602}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERTMap", "normalizedForm": "BERTMap", "offsetStart": 114, "offsetEnd": 121}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 2.5510787963867188e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 114, "offsetEnd": 122}, "context": "AMD produced errors and an empty alignment file, so results are only available for three of the matchers: LogMap, LogMapLt, Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9928433299064636}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 115, "offsetEnd": 123}, "context": "Last year, similar to this year, only Matcha, LogMap and LogMapLt were able to generate non-empty alignments, with LogMapLt being able to generate a higher number of correspondences. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9325309991836548}, "created": {"value": false, "score": 5.4001808166503906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 118, "offsetEnd": 123}, "context": "Since 2011, we have been using an environment for automatically processing evaluations which was developed within the SEALS (Semantic Evaluation At Large Scale) project 3 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006186962127685547}, "created": {"value": true, "score": 0.9428685307502747}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 118, "offsetEnd": 124}, "context": "While generating a few number of correct correspondences, precision is higher with respect to recall for LogMapLt and Matcha are the systems that are able to deal with a higher number of matching pairs. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012063980102539062}, "created": {"value": false, "score": 3.3020973205566406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 119, "offsetEnd": 123}, "context": "The OAEI evaluation was conducted in one of three alternative platforms: the SEALS client, the HOBBIT platform, or the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": false, "score": 8.654594421386719e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 119, "offsetEnd": 125}, "context": "This year, 4 systems have registered to participate in the Multifarm track:LSMatch-Multilingual, LogMap, LogMapLt, and Matcha. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.029211580753326416}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 122, "offsetEnd": 127}, "context": "The evaluation client 6 allows organizers to evaluate packaged systems whereby multiple submission formats are supported (SEALS packages or matchers implemented as Web services).", "mentionContextAttributes": {"used": {"value": false, "score": 0.002766430377960205}, "created": {"value": false, "score": 0.0002643465995788574}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERTMapLt", "normalizedForm": "BERTMapLt", "offsetStart": 123, "offsetEnd": 136}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61, "offsetStart": 50467, "offsetEnd": 50471}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61, "offsetStart": 50467, "offsetEnd": 50471}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 124, "offsetEnd": 130}, "context": "AMD produced errors and an empty alignment file, so results are only available for three of the matchers: LogMap, LogMapLt, Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9928433299064636}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 125, "offsetEnd": 133}, "context": "On the Nell-DBpedia dataset, all systems were able to outperform the basic string matcher, in terms of f-measure, except for LogMapLt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990215301513672}, "created": {"value": false, "score": 8.225440979003906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 126, "offsetEnd": 130}, "context": "While LogMap makes use of user interactions exclusively in the post-matching steps to filter their candidate correspondences, ALIN can also add new candidate correspondences to its initial set.", "mentionContextAttributes": {"used": {"value": false, "score": 3.898143768310547e-05}, "created": {"value": false, "score": 3.24249267578125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 130, "offsetEnd": 136}, "context": "Overall, the 2023 edition attracted more machine learning-based participants, which matches the original purpose of Bio-ML, while LogMap variants are the only symbolic participants.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01734215021133423}, "created": {"value": false, "score": 0.0001990199089050293}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Openjdk", "normalizedForm": "Openjdk", "offsetStart": 130, "offsetEnd": 137}, "version": {"rawForm": "1.8.0 265", "normalizedForm": "1.8.0 265", "offsetStart": 146, "offsetEnd": 155}, "context": "The evaluation was executed on a virtual machine (VM) with 32GB of RAM and 16 vCPUs (2.4 GHz), with Debian 9 operating system and Openjdk version 1.8.0 265. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999526739120483}, "created": {"value": false, "score": 8.177757263183594e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999526739120483}, "created": {"value": false, "score": 8.177757263183594e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 132, "offsetEnd": 145}, "context": "For subsumption matching, all the participating systems are machine learning-based, including BERTSubs (IC) [59], OWL2Vec*+RF [64], SORBETMatcher [63], and Word2Vec+Random Forest (RF).", "mentionContextAttributes": {"used": {"value": false, "score": 0.3217482566833496}, "created": {"value": false, "score": 8.225440979003906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63, "offsetStart": 51139, "offsetEnd": 51143}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 137, "offsetEnd": 142}, "context": "One reason might be that the properties are typed as rdf:Property and not distinguished into owl:ObjectProperty or owl:DatatypeProperty. OLaLa reaches the best score with 0.83 F-Measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10060787200927734}, "created": {"value": false, "score": 8.702278137207031e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 137, "offsetEnd": 143}, "context": "In 2023, 12 systems were submitted as MELT Web docker container, 3 systems were submitted as SEALS package, 1 system was uploaded to the HOBBIT platform, and one system implemented the Web interface directly and provided hosting for the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7880107760429382}, "created": {"value": false, "score": 0.0002796053886413574}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 137, "offsetEnd": 145}, "context": "LogMapLt is significantly slower in every test case and almost constantly shows worse results -only in the first test case the recall of LogMapLt is higher than for LogMap.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009494423866271973}, "created": {"value": false, "score": 2.193450927734375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 139, "offsetEnd": 142}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36].", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61, "offsetStart": 50467, "offsetEnd": 50471}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61, "offsetStart": 50467, "offsetEnd": 50471}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 139, "offsetEnd": 145}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 141, "offsetEnd": 145}, "context": "With the increasing usage of other programming languages than Java and increasing hardware requirements for matching systems, since 2021 the MELT Web interface was introduced to address this issue.", "mentionContextAttributes": {"used": {"value": false, "score": 4.124641418457031e-05}, "created": {"value": false, "score": 0.01589357852935791}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 143, "offsetEnd": 148}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.818), but four other systems obtained an F-measure above 0.88 (OLaLa, SORBETMatcher, LogMapBio, and LogMap) which is at least as good as the best systems in OAEI 2007-2010.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 145, "offsetEnd": 151}, "context": "This year, five matching systems (LogMap, LogMapLt, LogMapKG, Matcha and OLaLa) managed to generate an output for all of the track tasks, except Matcha failed to achieve alignment for the envo-sweet task. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9461040496826172}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 147, "offsetEnd": 152}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 148, "offsetEnd": 153}, "context": "The execution phase was terminated on September 30 \ud835\udc61\u210e , 2023, at which date participants had to submit the (near) final versions of their systems (SEALS-wrapped and/or HOBBIT-wrapped).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9584221243858337}, "created": {"value": false, "score": 0.00021892786026000977}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999946355819702}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 148, "offsetEnd": 155}, "context": "The second test case evaluates the matching systems to find correspondences between the large-sized MaterialInformation and the mid-sized BFO-based MatOnto. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4357531666755676}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": true, "score": 0.9513481259346008}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 149, "offsetEnd": 155}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36].", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 150, "offsetEnd": 163}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.818), but four other systems obtained an F-measure above 0.88 (OLaLa, SORBETMatcher, LogMapBio, and LogMap) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 153, "offsetEnd": 156}, "context": "For equivalence matching, top performing systems vary across different tasks, with LogMapBio attaining the best F1 on 2 out of 5 unsupervised tasks, and AMD, BERTMap, and SORBETMatcher attaining the best F1 on each of the remaining three, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0069664716720581055}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 154, "offsetEnd": 160}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TAXREF-LD", "normalizedForm": "TAXREF-LD", "offsetStart": 154, "offsetEnd": 167}, "context": "In 2021, we added a task to align two biological taxonomies with rather different but complementary scopes: the well-known NCBI taxonomy (NCBITAXON), and TAXREF-LD [42]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022238492965698242}, "created": {"value": true, "score": 0.9082379341125488}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00022238492965698242}, "created": {"value": true, "score": 0.9082379341125488}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 157, "offsetEnd": 163}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36].", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62, "offsetStart": 50491, "offsetEnd": 50495}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62, "offsetStart": 50491, "offsetEnd": 50495}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERTMap", "normalizedForm": "BERTMap", "offsetStart": 158, "offsetEnd": 165}, "context": "For equivalence matching, top performing systems vary across different tasks, with LogMapBio attaining the best F1 on 2 out of 5 unsupervised tasks, and AMD, BERTMap, and SORBETMatcher attaining the best F1 on each of the remaining three, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0069664716720581055}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 2.5510787963867188e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 160, "offsetEnd": 166}, "context": "Other systems either fail to complete the task within the allocated 24-hour time limit such as LogMapLt and LsMatch, or produce an empty alignment file such as LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019341707229614258}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 162, "offsetEnd": 170}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 163, "offsetEnd": 167}, "context": "Fourth, we also allowed participants (with trust) to directly upload output mappings if their systems had not been published and had not been made compatible with MELT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8763154149055481}, "created": {"value": false, "score": 0.006117463111877441}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 165, "offsetEnd": 171}, "context": "LogMapLt is significantly slower in every test case and almost constantly shows worse results -only in the first test case the recall of LogMapLt is higher than for LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009494423866271973}, "created": {"value": false, "score": 2.193450927734375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 165, "offsetEnd": 174}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.818), but four other systems obtained an F-measure above 0.88 (OLaLa, SORBETMatcher, LogMapBio, and LogMap) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 169, "offsetEnd": 175}, "context": "The execution phase was terminated on September 30 \ud835\udc61\u210e , 2023, at which date participants had to submit the (near) final versions of their systems (SEALS-wrapped and/or HOBBIT-wrapped).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9584221243858337}, "created": {"value": false, "score": 0.00021892786026000977}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 169, "offsetEnd": 176}, "context": "The first test case evaluates matching systems regarding their capability to find \"equal\" (=), \"superclass\" (>) and \"subclass\" (<) correspondences between the mid-sized MatOnto and the small-sized (since reduced) MaterialInformation ontology.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0479273796081543}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": true, "score": 0.9513481259346008}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 171, "offsetEnd": 184}, "context": "For equivalence matching, top performing systems vary across different tasks, with LogMapBio attaining the best F1 on 2 out of 5 unsupervised tasks, and AMD, BERTMap, and SORBETMatcher attaining the best F1 on each of the remaining three, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0069664716720581055}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapKG", "normalizedForm": "LogMapKG", "offsetStart": 172, "offsetEnd": 180}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 4.863739013671875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 180, "offsetEnd": 186}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.818), but four other systems obtained an F-measure above 0.88 (OLaLa, SORBETMatcher, LogMapBio, and LogMap) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 181, "offsetEnd": 187}, "context": "LogMapLt is significantly slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004712343215942383}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LsMatch", "normalizedForm": "LsMatch", "offsetStart": 182, "offsetEnd": 189}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 184, "offsetEnd": 197}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36].", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 195, "offsetEnd": 198}, "context": "Here, we include the results of 7 systems that were able to finish the task within the 24-hour time limit with a non-empty alignment file: LogMap, OLaLa, Matcha, LogMapLt, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993335604667664}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HOBBIT", "normalizedForm": "HOBBIT", "offsetStart": 199, "offsetEnd": 205}, "context": "It is a web interface for linked data and ontology matching evaluation, which requires systems to be wrapped inside docker containers and includes a SystemAdapter class, then being uploaded into the HOBBIT platform [23].", "mentionContextAttributes": {"used": {"value": false, "score": 0.00030744075775146484}, "created": {"value": false, "score": 0.005425393581390381}, "shared": {"value": false, "score": 3.933906555175781e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998733997344971}, "created": {"value": true, "score": 0.9941703081130981}, "shared": {"value": false, "score": 0.00013327598571777344}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23, "offsetStart": 3631, "offsetEnd": 3635}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 219, "offsetEnd": 223}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor of MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006478428840637207}, "created": {"value": false, "score": 0.00021463632583618164}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999967813491821}, "created": {"value": false, "score": 0.37911248207092285}, "shared": {"value": false, "score": 6.80685043334961e-05}}, "references": [{"label": "[65]", "normalizedForm": "[65]", "refKey": 65}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 243, "offsetEnd": 249}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 251, "offsetEnd": 260}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9790523648262024}, "created": {"value": false, "score": 0.00018912553787231445}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 266, "offsetEnd": 278}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap, BERTMapLt [58], AMD [61], Matcha, Matcha-DL [62], OLala, and SORBETMatcher [63]; and (ii) traditional systems including LogMap, LogMapBio, and LogMapLt [36]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.898220419883728}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 287, "offsetEnd": 299}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00013077259063720703}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SORBETMatcher", "normalizedForm": "SORBETMatcher", "offsetStart": 301, "offsetEnd": 314}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[63]", "normalizedForm": "[63]", "refKey": 63}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 316, "offsetEnd": 322}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.020921647548675537}, "shared": {"value": false, "score": 3.707408905029297e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 324, "offsetEnd": 330}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.009977996349334717}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}, {"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 332, "offsetEnd": 336}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0009139776229858398}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OLaLa", "normalizedForm": "OLaLa", "offsetStart": 342, "offsetEnd": 347}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 408, "offsetEnd": 416}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.0013328790664672852}, "shared": {"value": false, "score": 2.4318695068359375e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 418, "offsetEnd": 421}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch).", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999499320983887}, "created": {"value": false, "score": 0.00026029348373413086}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[61]", "normalizedForm": "[61]", "refKey": 61}, {"label": "[61]", "normalizedForm": "[61]", "refKey": 61}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 427, "offsetEnd": 434}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.00012552738189697266}, "shared": {"value": false, "score": 1.1920928955078125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PropMatch", "normalizedForm": "PropMatch", "offsetStart": 502, "offsetEnd": 511}, "context": "The highest average F [0.5|1|2] -measure and their corresponding precision and recall for each matcher with its F 1 -optimal threshold (ordered by F 1 -measure With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (GraphMatcher, SORBETMatcher, LogMap, Matcha, ALIN, and OLaLa); three systems performed better than StringEquiv baseline (LogMapLt, AMD, and LSMatch), and two systems performed worse than both baselines (TOMATO, and PropMatch). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 1.3113021850585938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999893307685852}, "created": {"value": false, "score": 0.04557830095291138}, "shared": {"value": false, "score": 2.384185791015625e-07}}}], "references": [{"refKey": 61, "tei": "<biblStruct xml:id=\"b61\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Stable Type Solutions of the Complex Laplacian Operators on Hermitian Manifolds</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Z</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">I</forename><forename type=\"middle\">F</forename><surname>Cruz</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/s00025-021-01512-4</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Results in Mathematics</title>\n\t\t<title level=\"j\" type=\"abbrev\">Results Math</title>\n\t\t<idno type=\"ISSN\">1422-6383</idno>\n\t\t<idno type=\"ISSNe\">1420-9012</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">76</biblScope>\n\t\t\t<biblScope unit=\"issue\">4</biblScope>\n\t\t\t<biblScope unit=\"page\">130</biblScope>\n\t\t\t<date type=\"published\" when=\"2021-09-18\">2021</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 62, "tei": "<biblStruct xml:id=\"b62\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">D</forename><surname>Faria</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">C</forename><surname>Silva</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Cotovio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Eug\u00e9nio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">C</forename><surname>Pesquita</surname></persName>\n\t\t</author>\n\t\t<title level=\"m\">Matcha and matcha-dl results for oaei</title>\n\t\t<imprint>\n\t\t\t<date>2022. 2022</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 58, "tei": "<biblStruct xml:id=\"b58\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">BERTMap: A BERT-Based Ontology Alignment System</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yuan</forename><surname>He</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jiaoyan</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Denvar</forename><surname>Antonyrajah</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ian</forename><surname>Horrocks</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1609/aaai.v36i5.20510</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Proceedings of the AAAI Conference on Artificial Intelligence</title>\n\t\t<title level=\"j\" type=\"abbrev\">AAAI</title>\n\t\t<idno type=\"ISSN\">2159-5399</idno>\n\t\t<idno type=\"ISSNe\">2374-3468</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">36</biblScope>\n\t\t\t<biblScope unit=\"issue\">5</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"5684\" to=\"5691\" />\n\t\t\t<date type=\"published\" when=\"2022-06-28\">2022</date>\n\t\t\t<publisher>Association for the Advancement of Artificial Intelligence (AAAI)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 63, "tei": "<biblStruct xml:id=\"b63\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Francis</forename><surname>Gosselin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Amal</forename><surname>Zouaq</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-031-47240-4_30</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Lecture Notes in Computer Science</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer Nature Switzerland</publisher>\n\t\t\t<date type=\"published\" when=\"2023\">2023</date>\n\t\t\t<biblScope unit=\"page\" from=\"561\" to=\"578\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 65, "tei": "<biblStruct xml:id=\"b65\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Visual Analysis of Ontology Matching Results with the MELT Dashboard</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jan</forename><surname>Portisch</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5420-0663</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sven</forename><surname>Hertling</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0333-5888</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Heiko</forename><surname>Paulheim</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-4386-8195</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-030-62327-2_32</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Lecture Notes in Computer Science</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer International Publishing</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n\t\t\t<biblScope unit=\"page\" from=\"186\" to=\"190\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 23, "tei": "<biblStruct xml:id=\"b23\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Introducing the HOBBIT platform into the Ontology Alignment Evaluation Campaign</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">E</forename><surname>Jim\u00e9nez-Ruiz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">T</forename><surname>Saveta</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">O</forename><surname>Zamazal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">S</forename><surname>Hertling</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>R\u00f6der</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">I</forename><surname>Fundulaki</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A.-C</forename><forename type=\"middle\">N</forename><surname>Ngomo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">A</forename><surname>Sherif</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Annane</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Z</forename><surname>Bellahsene</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">B</forename><surname>Yahia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">G</forename><surname>Diallo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">D</forename><surname>Faria</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Kachroudi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Khiat</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Lambrix</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">H</forename><surname>Li</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Mackeprang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Mohammadi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><surname>Rybinski</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">B</forename><forename type=\"middle\">S</forename><surname>Balasubramani</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">C</forename><surname>Trojahn</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 13th International Workshop on Ontology Matching</title>\n\t\t<meeting>the 13th International Workshop on Ontology Matching</meeting>\n\t\t<imprint>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 22142, "id": "0c08450d41ed9308dbd1776b917e8d3ff591aa7e", "metadata": {"id": "0c08450d41ed9308dbd1776b917e8d3ff591aa7e"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04366893.grobid.tei.xml", "file_name": "hal-04366893.grobid.tei.xml"}