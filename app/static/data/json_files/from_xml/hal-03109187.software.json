{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:47+0000", "md5": "694409428AAAD4F0ADC1A6DF3771EF77", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WikiScrap", "normalizedForm": "WikiScrap", "offsetStart": 0, "offsetEnd": 9}, "context": "WikiScrap We collected 500 Wikipedia articles for all the languages present in MLQA. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9974313378334045}, "created": {"value": false, "score": 0.00043338537216186523}, "shared": {"value": false, "score": 0.004990577697753906}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993914365768433}, "created": {"value": false, "score": 0.00043338537216186523}, "shared": {"value": false, "score": 0.004990577697753906}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 3, "offsetEnd": 8}, "context": "QG synth+trans (target language = es) Qu\u00e9 equipo gan\u00f3 el r\u00e9cord anterior?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9281601905822754}, "created": {"value": false, "score": 1.6450881958007812e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 3, "offsetEnd": 8}, "context": "QG synth+trans (target language = zh) \u7ea6\u7ff0\u2022\u57c3\u5c14\u7ef4\u572813\u5c81\u65f6\u5e26\u9886\u54ea\u652f\u7403\u961f\u8d62\u5f97\u7b2c33\u5c4a\u8d85\u7ea7\u7897? (Which team did John Elvey lead to win the 33rd Super Bowl at the age of 13?) QG synth+trans (target language = en) What team won the 33th Super Bowl?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9969362020492554}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 4, "offsetEnd": 10}, "context": "For MiniLM +synth-trans , we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM +synth , on both MLQA and XQuAD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9015941619873047}, "created": {"value": false, "score": 3.540515899658203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 4, "offsetEnd": 10}, "context": "Our MiniLM +synth-trans model outperforms its baseline by more than 4 Exact Match points, while XLM-R +synth-trans obtains a new state-of-the-art.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024169683456420898}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 6, "offsetEnd": 11}, "context": "QA No-synth Following previous works, we finetuned the multilingual models on SQuAD en , and consider them as our baselines.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009065866470336914}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 7, "offsetEnd": 12}, "context": "For QG synth+trans , we report the outputs given two target languages, the one of the context and English.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": false, "score": 1.7881393432617188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 12, "offsetEnd": 17}, "context": "For MiniLM +synth-trans , we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM +synth , on both MLQA and XQuAD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9015941619873047}, "created": {"value": false, "score": 3.540515899658203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 12, "offsetEnd": 17}, "context": "Our MiniLM +synth-trans model outperforms its baseline by more than 4 Exact Match points, while XLM-R +synth-trans obtains a new state-of-the-art.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024169683456420898}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "google", "normalizedForm": "google", "offsetStart": 12, "offsetEnd": 18}, "context": "We used the google translate API. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999890327453613}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999890327453613}, "created": {"value": false, "score": 7.283687591552734e-05}, "shared": {"value": true, "score": 0.9933797121047974}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 14, "offsetEnd": 19}, "context": "Answer 99% QG synth+trans (target language = de) Welcher Prozentsatz der Gebiete von Taiwan wird von der ROK kontrolliert?", "mentionContextAttributes": {"used": {"value": true, "score": 0.999169111251831}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 18, "offsetEnd": 23}, "context": "Answer Broncos QG synth What team did John Elway lead to victory at age 38? QG synth+trans (target language = en) What team did John Elway lead to win in the Super Bowl?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996229410171509}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 18, "offsetEnd": 23}, "context": "Answer Broncos QG synth Where did Peyton Manning condujo?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995632767677307}, "created": {"value": false, "score": 1.0371208190917969e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 18, "offsetEnd": 23}, "context": "Answer Ma Huan QG synth+trans (target language = de) Welcher chinesische traveller hat die fr\u00fchesten Erinnerungen an Kochi geschrieben?", "mentionContextAttributes": {"used": {"value": false, "score": 0.010905444622039795}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 2.0265579223632812e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 18, "offsetEnd": 24}, "context": "deliberately used MiniLM for both QA and QG: this allows a fairer investigation about the benefits of the proposed approach.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 5.91278076171875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "google", "normalizedForm": "google", "offsetStart": 18, "offsetEnd": 24}, "context": "https://translate.google.com", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018459558486938477}, "created": {"value": false, "score": 7.283687591552734e-05}, "shared": {"value": true, "score": 0.9933797121047974}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999890327453613}, "created": {"value": false, "score": 7.283687591552734e-05}, "shared": {"value": true, "score": 0.9933797121047974}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 21, "offsetEnd": 27}, "context": "Also, it outperforms MiniLM +SQuADtrans , indicating the benefit of our proposed approach.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025854110717773438}, "created": {"value": false, "score": 6.175041198730469e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 23, "offsetEnd": 28}, "context": "Answer Luzon Strait QG synth+trans (target language = de) Welcher Fluss ist direkt zum S\u00fcden von Taiwan?", "mentionContextAttributes": {"used": {"value": false, "score": 0.004073977470397949}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 25, "offsetEnd": 30}, "context": "Answer 180 kilometres QG synth+trans (target language = de) Wie weit ist die RAF von Taiwan aus der s\u00fcdlichen K\u00fcste von China?", "mentionContextAttributes": {"used": {"value": false, "score": 0.08074420690536499}, "created": {"value": false, "score": 8.702278137207031e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 26, "offsetEnd": 31}, "context": "Answer South China Sea QG synth+trans (target language = de) Welches Meer ist im S\u00fcdwesten von Taiwan?", "mentionContextAttributes": {"used": {"value": false, "score": 0.010025560855865479}, "created": {"value": false, "score": 1.3709068298339844e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth+", "normalizedForm": "synth+", "offsetStart": 27, "offsetEnd": 33}, "context": "In Table 1, we show how QG synth+trans can generate questions in the same language as the input. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002110600471496582}, "created": {"value": false, "score": 0.04101073741912842}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0002110600471496582}, "created": {"value": false, "score": 0.04101073741912842}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Multilingual MiniLM", "normalizedForm": "Multilingual MiniLM", "offsetStart": 31, "offsetEnd": 50}, "version": {"rawForm": "1", "normalizedForm": "1", "offsetStart": 52, "offsetEnd": 53}, "publisher": {"rawForm": "MiniLM-m", "normalizedForm": "MiniLM-m", "offsetStart": 55, "offsetEnd": 63}, "context": "For all our experiments we use Multilingual MiniLM v1 (MiniLM-m) (Wang et al., 2020), a 12-layer with 384 hidden size architecture distilled from XLM-R Base multilingual (Conneau et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7721900939941406}, "created": {"value": false, "score": 0.0010378360748291016}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7721900939941406}, "created": {"value": false, "score": 0.0010378360748291016}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46, "offsetStart": 13803, "offsetEnd": 13822}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 32, "offsetEnd": 37}, "context": "Synthetic without translation (+synth) Compared to the MiniLM baseline, we observe a small performance increase for MiniLM +synth (Exact Match increases from 29.5 to 33.1 on XQuAD and from 26.0 to 27.5 on MLQA).", "mentionContextAttributes": {"used": {"value": true, "score": 0.901000440120697}, "created": {"value": false, "score": 2.7060508728027344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 33, "offsetEnd": 38}, "context": "Notably, our multilingual XLM-R +synth-trans outperforms CamemBERT on PIAF, even if the latter is a pure monolingual, in-domain language model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025337934494018555}, "created": {"value": false, "score": 0.01555413007736206}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 35, "offsetEnd": 40}, "context": "Answer 35,808 square kilometres QG synth+trans (target language = de) Wie gro\u00df ist die RAF? (tr: How big is the RAF?) QG synth+trans (target language = ar) (tr: How many square miles is the island?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.06171935796737671}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 38, "offsetEnd": 43}, "context": "Answer massive flooding of Periyar QG synth+trans (target language = de) Welche Veranstaltung hat den Angriff auf Kochi im Jahr 1341 verursacht?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9497324824333191}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 41, "offsetEnd": 46}, "context": "(Which team won the previous record?) QG synth+trans (target language = en) What team did Menning win in the Super Bowl?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994968175888062}, "created": {"value": false, "score": 1.52587890625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 43, "offsetEnd": 48}, "context": "We report the BLEU-4 scores for MLQA on QG synth+trans on Table 5 and QG synth on Table 6. 9 With unseen during training, we mean not present in the QG dataset; obviously, the language should have been present in the first self-supervised stage.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997345805168152}, "created": {"value": false, "score": 3.5881996154785156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 45, "offsetEnd": 50}, "context": "In Table 2 we report the BLEU4 scores for QG synth+trans grouped by the language of the question.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997712969779968}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 46, "offsetEnd": 51}, "context": "(tr: Which sea is in southwest of Taiwan?) QG synth+trans (target language = ar) (tr: What is the ocean seen on the western side of Taiwan?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.02047717571258545}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 55, "offsetEnd": 61}, "context": "Synthetic without translation (+synth) Compared to the MiniLM baseline, we observe a small performance increase for MiniLM +synth (Exact Match increases from 29.5 to 33.1 on XQuAD and from 26.0 to 27.5 on MLQA).", "mentionContextAttributes": {"used": {"value": true, "score": 0.901000440120697}, "created": {"value": false, "score": 2.7060508728027344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 57, "offsetEnd": 62}, "context": "We then invoke the baseline model described above, QA No-synth , to predict the answer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9951895475387573}, "created": {"value": false, "score": 0.009352266788482666}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 57, "offsetEnd": 62}, "context": "(tr: Which event caused the attack on Kochi in 1341?) QG synth+trans (target language = ar) (tr: What event caused the destruction of Kathmandu?)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9986116886138916}, "created": {"value": false, "score": 3.337860107421875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 57, "offsetEnd": 62}, "context": "(tr: Which river is directly to the south of Taiwan?) QG synth+trans (target language = ar) (tr: What is the name of the nearby railway?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.10097527503967285}, "created": {"value": false, "score": 3.063678741455078e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 57, "offsetEnd": 66}, "context": "Notably, our multilingual XLM-R +synth-trans outperforms CamemBERT on PIAF, even if the latter is a pure monolingual, in-domain language model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025337934494018555}, "created": {"value": false, "score": 0.01555413007736206}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00025337934494018555}, "created": {"value": false, "score": 0.01555413007736206}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "offsetStart": 61, "offsetEnd": 68}, "context": "To evaluate our models, we used the official MLQA evaluation scripts. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999984622001648}, "created": {"value": false, "score": 7.164478302001953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999984622001648}, "created": {"value": false, "score": 7.164478302001953e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 70, "offsetEnd": 75}, "context": "(tr: Which Chinese traveler wrote the earliest memories of Kochi?) QG synth+trans (target language = ar) 15 (tr: Who wrote the first reference to Coty in the 15th century?)", "mentionContextAttributes": {"used": {"value": true, "score": 0.9960527420043945}, "created": {"value": false, "score": 1.621246337890625e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 73, "offsetEnd": 78}, "context": "We report the BLEU-4 scores for MLQA on QG synth+trans on Table 5 and QG synth on Table 6. 9 With unseen during training, we mean not present in the QG dataset; obviously, the language should have been present in the first self-supervised stage.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997345805168152}, "created": {"value": false, "score": 3.5881996154785156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 74, "offsetEnd": 79}, "context": "(tr: What percentage of the areas of Taiwan is controlled by the ROK?) QG synth+trans (target language = ar) ( ) (tr: What is the percentage of lands controlled by the (Divan)?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.3071818947792053}, "created": {"value": false, "score": 1.4066696166992188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 74, "offsetEnd": 79}, "context": "(tr: How far is the RAF from Taiwan from the southern coast of China?) QG synth+trans (target language = ar) (tr: How long are the Taiwan Islands from the coast of China?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.03615444898605347}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 75, "offsetEnd": 81}, "context": "In particular, we use a distilled version of XLM-R (Conneau et al., 2020): MiniLM-M (Wang et al., 2020) (see Section 4.3 for further details).", "mentionContextAttributes": {"used": {"value": true, "score": 0.958000659942627}, "created": {"value": false, "score": 8.392333984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46, "offsetStart": 11177, "offsetEnd": 11196}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 79, "offsetEnd": 84}, "context": "Answer Broncos QG synth What team did John Elway lead to victory at age 38? QG synth+trans (target language = en) What team did John Elway lead to win in the Super Bowl?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996229410171509}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 82, "offsetEnd": 88}, "context": "For MiniLM +synth-trans , we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM +synth , on both MLQA and XQuAD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9015941619873047}, "created": {"value": false, "score": 3.540515899658203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mechanical Turk", "normalizedForm": "Mechanical Turk", "offsetStart": 84, "offsetEnd": 99}, "context": "It contains about 100K question/paragraph/answer triplets in English, annotated via Mechanical Turk.2", "mentionContextAttributes": {"used": {"value": false, "score": 0.11116987466812134}, "created": {"value": false, "score": 2.1338462829589844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11116987466812134}, "created": {"value": false, "score": 2.1338462829589844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 102, "offsetEnd": 108}, "context": "For MiniLM +synth-trans , we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM +synth , on both MLQA and XQuAD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9015941619873047}, "created": {"value": false, "score": 3.540515899658203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 103, "offsetEnd": 108}, "context": "Our MiniLM +synth-trans model outperforms its baseline by more than 4 Exact Match points, while XLM-R +synth-trans obtains a new state-of-the-art.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024169683456420898}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 108, "offsetEnd": 113}, "context": "These synthetic questions seem much more relevant, coherent and fluent, if compared to those produced by QG synth : for the Spanish paragraph, the question is well formed and focused on the input answer; for Chinese (see bottom row of Table 1 for QG synth+trans ) is perfectly written.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003735840320587158}, "created": {"value": false, "score": 0.00013458728790283203}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 110, "offsetEnd": 115}, "context": "For MiniLM +synth-trans , we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM +synth , on both MLQA and XQuAD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9015941619873047}, "created": {"value": false, "score": 3.540515899658203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WikiScrap", "normalizedForm": "WikiScrap", "offsetStart": 111, "offsetEnd": 120}, "context": "Synth the QG model is trained on SQuAD en,qg (i.e., English data only) and the synthetic data are generated on WikiScrap.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993914365768433}, "created": {"value": false, "score": 3.4928321838378906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993914365768433}, "created": {"value": false, "score": 0.00043338537216186523}, "shared": {"value": false, "score": 0.004990577697753906}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 116, "offsetEnd": 122}, "context": "Synthetic without translation (+synth) Compared to the MiniLM baseline, we observe a small performance increase for MiniLM +synth (Exact Match increases from 29.5 to 33.1 on XQuAD and from 26.0 to 27.5 on MLQA).", "mentionContextAttributes": {"used": {"value": true, "score": 0.901000440120697}, "created": {"value": false, "score": 2.7060508728027344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 121, "offsetEnd": 126}, "context": "Answer 35,808 square kilometres QG synth+trans (target language = de) Wie gro\u00df ist die RAF? (tr: How big is the RAF?) QG synth+trans (target language = ar) (tr: How many square miles is the island?)", "mentionContextAttributes": {"used": {"value": false, "score": 0.06171935796737671}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 124, "offsetEnd": 129}, "context": "Synthetic without translation (+synth) Compared to the MiniLM baseline, we observe a small performance increase for MiniLM +synth (Exact Match increases from 29.5 to 33.1 on XQuAD and from 26.0 to 27.5 on MLQA).", "mentionContextAttributes": {"used": {"value": true, "score": 0.901000440120697}, "created": {"value": false, "score": 2.7060508728027344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 125, "offsetEnd": 131}, "context": "The abscissa x corresponds to the progressively increasing number of synthetic samples used; at x = 0, it corresponds to the MiniLM +trans baseline, where the model has access only to the original English data from SQuAD en .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9351305365562439}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 135, "offsetEnd": 140}, "context": "While still relevant to the context, the synthetic questions are generated in English: for instance, in Table 1 we observe that the QG synth model outputs English questions for the paragraphs in Chinese and Spanish.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5407398343086243}, "created": {"value": false, "score": 3.600120544433594e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 141, "offsetEnd": 147}, "context": "Hidden distillation effect The relative improvement for our best synthetic configuration +synthtrans, over the baseline, is above 60% EM for MiniLM (from 29.5 to 49.5 on XQuAD and from 26.0 to 41.4 on MLQA).", "mentionContextAttributes": {"used": {"value": false, "score": 0.2049599289894104}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 147, "offsetEnd": 152}, "context": "QG synth+trans (target language = zh) \u7ea6\u7ff0\u2022\u57c3\u5c14\u7ef4\u572813\u5c81\u65f6\u5e26\u9886\u54ea\u652f\u7403\u961f\u8d62\u5f97\u7b2c33\u5c4a\u8d85\u7ea7\u7897? (Which team did John Elvey lead to win the 33rd Super Bowl at the age of 13?) QG synth+trans (target language = en) What team won the 33th Super Bowl?", "mentionContextAttributes": {"used": {"value": true, "score": 0.9969362020492554}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 150, "offsetEnd": 156}, "context": "Cross Lingual Generalisation To explore the models' effectiveness in dealing with cross-lingual inputs, we report in Figure 1 the performance for our MiniLM +synth-trans setup, varying the number of samples and the languages present in the synthetic data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3241667151451111}, "created": {"value": false, "score": 0.012351632118225098}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 158, "offsetEnd": 163}, "context": "Cross Lingual Generalisation To explore the models' effectiveness in dealing with cross-lingual inputs, we report in Figure 1 the performance for our MiniLM +synth-trans setup, varying the number of samples and the languages present in the synthetic data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3241667151451111}, "created": {"value": false, "score": 0.012351632118225098}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 162, "offsetEnd": 167}, "context": "q/c en es de ar hi vi zh en 14.5 8.9 7.2 5.9 6.5 8.4 6.0 es 9.0 10. 6.6 4.2 5.9   In addition, we report the F1 scores for XLM-R finetuned on SQuAD en and XLM-R +synth-trans on all the language pairs, on both MLQA and XQuAD in Tables 7,8, 9 and 10.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998517036437988}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiniLM", "normalizedForm": "MiniLM", "offsetStart": 168, "offsetEnd": 174}, "context": "Significantly higher than that observed for XLM-R (+11.7% on XQuAD and +2.71% on MLQA), it indicates that XLM-R provides superior cross-lingual transfer abilities than MiniLM, a fact that we hypothesize due to distillation.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6253040432929993}, "created": {"value": false, "score": 4.76837158203125e-06}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9861528873443604}, "created": {"value": false, "score": 0.05507516860961914}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "references": [{"label": "(Wang et al., 2020)", "normalizedForm": "Wang et al., 2020", "refKey": 46}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "synth", "normalizedForm": "synth", "offsetStart": 250, "offsetEnd": 255}, "context": "These synthetic questions seem much more relevant, coherent and fluent, if compared to those produced by QG synth : for the Spanish paragraph, the question is well formed and focused on the input answer; for Chinese (see bottom row of Table 1 for QG synth+trans ) is perfectly written.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003735840320587158}, "created": {"value": false, "score": 0.00013458728790283203}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999854326248169}, "created": {"value": true, "score": 0.9990202188491821}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}], "references": [{"refKey": 46, "tei": "<biblStruct xml:id=\"b46\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wenhui</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Furu</forename><surname>Wei</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Li</forename><surname>Dong</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hangbo</forename><surname>Bao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nan</forename><surname>Yang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ming</forename><surname>Zhou</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:2002.10957</idno>\n\t\t<title level=\"m\">Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers</title>\n\t\t<imprint>\n\t\t\t<date>2020</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 5075, "id": "6c8fa4b1f5d4f5250091808bafb3c117914c57f6", "metadata": {"id": "6c8fa4b1f5d4f5250091808bafb3c117914c57f6"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03109187.grobid.tei.xml", "file_name": "hal-03109187.grobid.tei.xml"}