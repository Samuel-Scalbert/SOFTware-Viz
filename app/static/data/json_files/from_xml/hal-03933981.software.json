{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:38+0000", "md5": "E882F11DC33F344619E7C12F4D0331D4", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 0, "offsetEnd": 5}, "context": "SPICE instead parses reference captions to a graph containing semantic elements, their attributes, and relations to one another, and evaluates the candidate graph via synonym lemma matching. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004991292953491211}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 0, "offsetEnd": 5}, "context": "SPICE views graphs as sets of node, node-attribute, and node-relation-node tuples.", "mentionContextAttributes": {"used": {"value": false, "score": 7.414817810058594e-05}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 0, "offsetEnd": 5}, "context": "SPICE+emb appears correlated to Sentence-BERT, and significantly alters system ranking compared to SPIDEr.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008801400661468506}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 0, "offsetEnd": 5}, "context": "SPICE+ is thus able to identify a limitation of the baseline system, and could provide a more comprehensive analysis of captioning systems in this manner.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014919638633728027}, "created": {"value": false, "score": 0.0005597472190856934}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 0, "offsetEnd": 6}, "context": "SPICE+ alters the three processing steps, by performing dependency annotation with a pre-trained language model, adding new linguistic rules and post-processing to semantic graph construction, and evaluating candidates on deep embedding comparison 3 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010609626770019531}, "created": {"value": false, "score": 6.878376007080078e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 0, "offsetEnd": 6}, "context": "SPICE+ retains a tuple comparison approach, but replaces binary synonym matching with a continuous similarity measure. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.49826431274414e-05}, "created": {"value": false, "score": 3.075599670410156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 0, "offsetEnd": 6}, "context": "SPICE+ slightly improves on SPICE, indicating that the pre-trained dependency annotator and additional graph parsing rules are beneficial. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010207891464233398}, "created": {"value": false, "score": 2.09808349609375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 0, "offsetEnd": 6}, "context": "SPICE+emb also significantly outperforms CIDEr and SPIDEr on MM and total accuracy, the current accepted metrics for audio captioning. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": false, "score": 2.753734588623047e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 4, "offsetEnd": 9}, "context": "For SPICE, most incorrect captions are concentrated at 0, and give little information on the degree of similarity between candidates and references.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002792537212371826}, "created": {"value": false, "score": 9.298324584960938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 6, "offsetEnd": 12}, "context": "Thus, SPICE+ replaces the original PCFG parser with a language model trained on Universal Dependencies parsing.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001666545867919922}, "created": {"value": false, "score": 0.00010216236114501953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 8, "offsetEnd": 13}, "context": "Because SPICE+ compares semantic elements extracted from captions, it can also enable better understanding the behavior of captioning systems in such conditions.", "mentionContextAttributes": {"used": {"value": false, "score": 3.7550926208496094e-05}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 9, "offsetEnd": 14}, "context": "Overall, SPICE+emb is worse than Sentence-BERT on total accuracy, with a smaller difference when penalizing fluency through error detection.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016132593154907227}, "created": {"value": false, "score": 1.3113021850585938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 10, "offsetEnd": 15}, "context": "Combining SPICE+emb with CIDEr to obtain a SPIDEr equivalent did not improve performance in our experiments.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": false, "score": 0.0003314018249511719}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 14, "offsetEnd": 20}, "context": "We introduced SPICE+, a modification of SPICE including pre-trained language models for dependency annotation and graph comparison. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.224082946777344e-05}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 14, "offsetEnd": 20}, "context": "Examples from Clotho [11] and AudioCaps [12] associate several human reference captions to examples, each describing events relevant to the annotator instead of the entire scene.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013489127159118652}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11, "offsetStart": 2770, "offsetEnd": 2774}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 19, "offsetEnd": 25}, "context": "The currently used SPIDEr score, as well as Sentence-BERT and SPICE+emb, are shown in Table 2 for systems of the DCASE2022 challenge on the Clotho-testing dataset 4 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 22, "offsetEnd": 27}, "context": "Next, the behavior of SPICE+ on absolute scoring of captions is evaluated.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9977807402610779}, "created": {"value": false, "score": 3.325939178466797e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 26, "offsetEnd": 31}, "context": "In this paper, we propose SPICE+, a modification of SPICE that improves caption annotation and comparison with pre-trained language models.", "mentionContextAttributes": {"used": {"value": false, "score": 9.357929229736328e-05}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 27, "offsetEnd": 32}, "context": "The ranking performance of SPICE+ is first evaluated on the FENSE benchmark against current metrics CIDEr, SPICE, and SPIDEr, as well as the FENSE metric based on S-BERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8600531816482544}, "created": {"value": false, "score": 0.00011432170867919922}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 28, "offsetEnd": 33}, "context": "SPICE+ slightly improves on SPICE, indicating that the pre-trained dependency annotator and additional graph parsing rules are beneficial.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010207891464233398}, "created": {"value": false, "score": 2.09808349609375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 30, "offsetEnd": 36}, "context": "As a workaround, they propose SPIDEr-max, where the maximum SPIDEr score out of several candidates produced by the system is retained.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025957822799682617}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioCaps", "normalizedForm": "AudioCaps", "offsetStart": 30, "offsetEnd": 39}, "context": "Examples from Clotho [11] and AudioCaps [12] associate several human reference captions to examples, each describing events relevant to the annotator instead of the entire scene.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013489127159118652}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8459182381629944}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12, "offsetStart": 2789, "offsetEnd": 2793}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 31, "offsetEnd": 36}, "context": "Most n-gram metrics as well as SPICE perform poorly, cementing the need for further research in caption evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 8.785724639892578e-05}, "created": {"value": false, "score": 4.470348358154297e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 31, "offsetEnd": 36}, "context": "The original implementation of SPICE compares candidate and reference graphs as sets of tuples through synonym comparison.", "mentionContextAttributes": {"used": {"value": false, "score": 9.715557098388672e-05}, "created": {"value": false, "score": 0.00244981050491333}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 31, "offsetEnd": 37}, "context": "From empirical observations on Clotho examples, this parser has a high error rate, which propagates to poor rule-based parsing and leads to incomplete or incorrect semantic graphs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006570219993591309}, "created": {"value": false, "score": 4.1365623474121094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 33, "offsetEnd": 38}, "context": "SPI-DEr [10], the combination of SPICE and CIDEr, was found to outperform both in correlation to human assessments, and is now the main metric for evaluating AAC systems.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6580777764320374}, "created": {"value": false, "score": 2.6941299438476562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 33, "offsetEnd": 38}, "context": "Five rules are added compared to SPICE to handle formulations often found in audio captions, such as open clausal complements (e.g.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003771781921386719}, "created": {"value": false, "score": 0.00010979175567626953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 36, "offsetEnd": 42}, "context": "Labb\u00e9 et al. [13] further note that SPIDEr shows high variability to small differences in caption formulation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.06092947721481323}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 40, "offsetEnd": 45}, "context": "We introduced SPICE+, a modification of SPICE including pre-trained language models for dependency annotation and graph comparison.", "mentionContextAttributes": {"used": {"value": false, "score": 7.224082946777344e-05}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 41, "offsetEnd": 46}, "context": "As a first experiment in this direction, SPICE+emb is computed for the DCASE2022 challenge baseline with varying number of generated captions from 1 to 20, obtained with a beam size of 25.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9857958555221558}, "created": {"value": false, "score": 5.5789947509765625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 42, "offsetEnd": 47}, "context": "In contrast, both embedding-based metrics SPICE+emb and Sentence-BERT provide a bimodal distribution, with some overlap.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001323223114013672}, "created": {"value": false, "score": 5.8531761169433594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 43, "offsetEnd": 49}, "context": "Combining SPICE+emb with CIDEr to obtain a SPIDEr equivalent did not improve performance in our experiments.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": false, "score": 0.0003314018249511719}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MPNet", "normalizedForm": "MPNet", "offsetStart": 44, "offsetEnd": 53}, "context": "However, similar results are obtained using MPNet [22].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9916937947273254}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9916937947273254}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 47, "offsetEnd": 52}, "context": "Interestingly, the distribution is similar for SPICE+ with synonym matching, with only a slight shift of correct caption scores to higher values.", "mentionContextAttributes": {"used": {"value": false, "score": 0.026676714420318604}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE+", "normalizedForm": "SPICE+", "offsetStart": 48, "offsetEnd": 54}, "context": "Compared to full sentence embedding comparison, SPICE+ is more interpretable as it evaluates individual semantic elements. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.453296661376953e-05}, "created": {"value": false, "score": 9.298324584960938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": true, "score": 0.9998939037322998}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 51, "offsetEnd": 57}, "context": "SPICE+emb also significantly outperforms CIDEr and SPIDEr on MM and total accuracy, the current accepted metrics for audio captioning. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020073652267456055}, "created": {"value": false, "score": 2.753734588623047e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 52, "offsetEnd": 57}, "context": "In this paper, we propose SPICE+, a modification of SPICE that improves caption annotation and comparison with pre-trained language models.", "mentionContextAttributes": {"used": {"value": false, "score": 9.357929229736328e-05}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioCaps", "normalizedForm": "AudioCaps", "offsetStart": 52, "offsetEnd": 61}, "context": "250 pairs (921 and 1000 for MM resp.) are formed on AudioCaps and Clotho. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8459182381629944}, "created": {"value": false, "score": 4.220008850097656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8459182381629944}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 53, "offsetEnd": 58}, "context": "sult, captioning-specific alternatives CIDEr [8] and SPICE [9] were proposed.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005713045597076416}, "created": {"value": false, "score": 0.0001112222671508789}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9, "offsetStart": 2056, "offsetEnd": 2059}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 53, "offsetEnd": 59}, "context": "Note that the benchmark removes all punctuation from Clotho captions, which increases the error rate of dependency annotation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.17505449056625366}, "created": {"value": false, "score": 2.1338462829589844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 60, "offsetEnd": 66}, "context": "As a workaround, they propose SPIDEr-max, where the maximum SPIDEr score out of several candidates produced by the system is retained.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025957822799682617}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 61, "offsetEnd": 66}, "context": "The final metric is the pseudo F-score, which is referred as SPICE+emb in experiments.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2623494267463684}, "created": {"value": false, "score": 4.363059997558594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 62, "offsetEnd": 67}, "context": "The currently used SPIDEr score, as well as Sentence-BERT and SPICE+emb, are shown in Table 2 for systems of the DCASE2022 challenge on the Clotho-testing dataset 4 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 62, "offsetEnd": 68}, "context": "Figure 1 presents the distributions of scores for HI pairs on Clotho, i.e. correct and incorrect captions.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9819584488868713}, "created": {"value": false, "score": 1.2159347534179688e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 66, "offsetEnd": 72}, "context": "250 pairs (921 and 1000 for MM resp.) are formed on AudioCaps and Clotho. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8459182381629944}, "created": {"value": false, "score": 4.220008850097656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 70, "offsetEnd": 75}, "context": "Systems are currently evaluated by image captioning metrics CIDEr and SPICE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005870223045349121}, "created": {"value": false, "score": 0.0001176595687866211}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 76, "offsetEnd": 81}, "context": "In this paper, we propose to combine the semantic graph parsing paradigm of SPICE with the strengths of deep language models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013124942779541016}, "created": {"value": true, "score": 0.9999103546142578}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 98, "offsetEnd": 103}, "context": "The contributions of this paper are: (i) we identify limitations in the current implementation of SPICE, namely that semantic graphs are incomplete, and candidate evaluation through synonym matching is too restrictive, (ii) we replace components of SPICE with pre-trained models to produce comprehensive semantic representations, and (iii) we propose a score based on the embedding similarity between candidate and reference sub-graphs, that is suitable in the current general task setting but can be adapted to specific sub-tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010176301002502441}, "created": {"value": false, "score": 0.1299789547920227}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 99, "offsetEnd": 105}, "context": "SPICE+emb appears correlated to Sentence-BERT, and significantly alters system ranking compared to SPIDEr.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008801400661468506}, "created": {"value": false, "score": 8.463859558105469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 107, "offsetEnd": 112}, "context": "The ranking performance of SPICE+ is first evaluated on the FENSE benchmark against current metrics CIDEr, SPICE, and SPIDEr, as well as the FENSE metric based on S-BERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.860053539276123}, "created": {"value": false, "score": 0.00011432170867919922}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIDEr", "normalizedForm": "SPIDEr", "offsetStart": 118, "offsetEnd": 124}, "context": "The ranking performance of SPICE+ is first evaluated on the FENSE benchmark against current metrics CIDEr, SPICE, and SPIDEr, as well as the FENSE metric based on S-BERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.860053539276123}, "created": {"value": false, "score": 0.00011432170867919922}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.9979896545410156}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 128, "offsetEnd": 133}, "context": "The proposed metric evaluates a candidate caption against an arbitrarily large set of references, following the same process as SPICE [9].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001703500747680664}, "created": {"value": false, "score": 0.0015075206756591797}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9, "offsetStart": 5401, "offsetEnd": 5404}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AudioCaps", "normalizedForm": "AudioCaps", "offsetStart": 130, "offsetEnd": 139}, "context": "Combined with fluency error detection, the metric achieves competitive performance on the FENSE benchmark, with 84.0% accuracy on AudioCaps and 74.1% on Clotho. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6003060936927795}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8459182381629944}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[12]", "normalizedForm": "[12]", "refKey": 12}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 140, "offsetEnd": 146}, "context": "The currently used SPIDEr score, as well as Sentence-BERT and SPICE+emb, are shown in Table 2 for systems of the DCASE2022 challenge on the Clotho-testing dataset 4 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Clotho", "normalizedForm": "Clotho", "offsetStart": 153, "offsetEnd": 159}, "context": "Combined with fluency error detection, the metric achieves competitive performance on the FENSE benchmark, with 84.0% accuracy on AudioCaps and 74.1% on Clotho. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6003060936927795}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.985508143901825}, "created": {"value": false, "score": 5.316734313964844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[11]", "normalizedForm": "[11]", "refKey": 11}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDify", "normalizedForm": "UDify", "offsetStart": 153, "offsetEnd": 162}, "context": "Furthermore, no decision threshold or tuple weighting is applied to the similarity matrix S. The dependency and part-of-speech annotations are done with UDify [21]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9970332384109497}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9970332384109497}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPICE", "normalizedForm": "SPICE", "offsetStart": 249, "offsetEnd": 254}, "context": "The contributions of this paper are: (i) we identify limitations in the current implementation of SPICE, namely that semantic graphs are incomplete, and candidate evaluation through synonym matching is too restrictive, (ii) we replace components of SPICE with pre-trained models to produce comprehensive semantic representations, and (iii) we propose a score based on the embedding similarity between candidate and reference sub-graphs, that is suitable in the current general task setting but can be adapted to specific sub-tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010176301002502441}, "created": {"value": false, "score": 0.1299789547920227}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993883371353149}, "created": {"value": true, "score": 0.999937891960144}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}], "references": [{"refKey": 9, "tei": "<biblStruct xml:id=\"b9\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">SPICE: Semantic Propositional Image Caption Evaluation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Peter</forename><surname>Anderson</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Basura</forename><surname>Fernando</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mark</forename><surname>Johnson</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Stephen</forename><surname>Gould</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-319-46454-1_24</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Lecture Notes in Computer Science</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer International Publishing</publisher>\n\t\t\t<date type=\"published\" when=\"2016\">2016</date>\n\t\t\t<biblScope unit=\"page\" from=\"382\" to=\"398\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 11, "tei": "<biblStruct xml:id=\"b11\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Clotho: an Audio Captioning Dataset</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Konstantinos</forename><surname>Drossos</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Samuel</forename><surname>Lipping</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tuomas</forename><surname>Virtanen</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp40776.2020.9052990</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2020-05\">2020</date>\n\t\t\t<biblScope unit=\"page\">740</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 12, "tei": "<biblStruct xml:id=\"b12\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">AudioCaps: Generating captions for audios in the wild</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">D</forename><surname>Kim</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">B</forename><surname>Kim</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">H</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">G</forename><surname>Kim</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Conference of the North American Chapter of the Association for Computational Linguistics: Human Language</title>\n\t\t<title level=\"s\">Long and Short Papers</title>\n\t\t<imprint>\n\t\t\t<date>2019. 2019</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">132</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 14552, "id": "b256bff10b1bab245b357dd5ab53ec77dafaec45", "metadata": {"id": "b256bff10b1bab245b357dd5ab53ec77dafaec45"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03933981.grobid.tei.xml", "file_name": "hal-03933981.grobid.tei.xml"}