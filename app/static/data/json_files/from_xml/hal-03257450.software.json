{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:53+0000", "md5": "56362BC4B6F32780EB02C094BD3509AA", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 0, "offsetEnd": 8}, "context": "DeepSHAP combines efficient, analytical computation of SHAP values for simple network modules (linear, maxout, activation) with DeepLIFT's mutiplier composition rule to backpropagate these attribution values down to the input layer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015234947204589844}, "created": {"value": false, "score": 1.6927719116210938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 0, "offsetEnd": 8}, "context": "DeepSHAP [23] combines the principles of DeepLIFT and SHAP.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005789995193481445}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23, "offsetStart": 4174, "offsetEnd": 4178}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 0, "offsetEnd": 8}, "context": "DeepSHAP, a feature attribution method, is employed to figure out which timefrequency bins of the input spectrogram are used by the DNN to estimate the mask.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4856085181236267}, "created": {"value": false, "score": 5.698204040527344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 0, "offsetEnd": 13}, "context": "DeepSHAP [23] combines ideas from SHapley Additive exPlanations (SHAP) [23] and DeepLIFT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0420689582824707}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepExplainer", "normalizedForm": "DeepExplainer", "offsetStart": 12, "offsetEnd": 26}, "context": "We used the DeepExplainer3 component of the toolkit, which computes the SHAP values analytically for simple DNN modules (linear, sigmoid) or using the gradient for complex modules (Bi-LSTM) and backpropagates them with DeepLIFT's multiplier composition rule. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 15, "offsetEnd": 28}, "context": "Others such as DeepLIFT [20] are designed for a wider range of architectures. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.046627044677734e-05}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 23, "offsetEnd": 31}, "context": "A natural way of using DeepSHAP is to assume that each magnitude STFT coefficient |x1(n , f )| is an input feature and to compute the contribution of that feature to every timefrequency bin M(n, f ) of the output mask. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.030423641204833984}, "created": {"value": false, "score": 1.8477439880371094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 34, "offsetEnd": 42}, "context": "Section 2 provides an overview of DeepSHAP.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015223026275634766}, "created": {"value": false, "score": 5.1856040954589844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 39, "offsetEnd": 47}, "context": "Section 3 describes the application of DeepSHAP to speech enhancement models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007573366165161133}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 41, "offsetEnd": 49}, "context": "DeepSHAP [23] combines the principles of DeepLIFT and SHAP.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005789995193481445}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 44, "offsetEnd": 49}, "context": "This system follows the nnet1 recipe of the Kaldi ASR toolkit [34], involving a 7-layer multi layered perceptron (MLP)-based acoustic model and a 3-gram language model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03912544250488281}, "created": {"value": false, "score": 4.696846008300781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.03912544250488281}, "created": {"value": false, "score": 4.696846008300781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 50, "offsetEnd": 58}, "context": "We employ the Deep SHapley Additive exPlanations (DeepSHAP) feature attribution method to quantify the contribution of every timefrequency bin in the input noisy speech signal to every timefrequency bin in the output time-frequency mask.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.0031769275665283203}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FNETWORK", "normalizedForm": "FNETWORK", "offsetStart": 73, "offsetEnd": 81}, "context": "FSSN has a lower change in speech relevance score (10.7%) as compared to FNETWORK (16.4%) indicating better generalization capability for FSSN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.042034149169921875}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9756399393081665}, "created": {"value": false, "score": 0.0001049041748046875}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 80, "offsetEnd": 88}, "context": "DeepSHAP [23] combines ideas from SHapley Additive exPlanations (SHAP) [23] and DeepLIFT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0420689582824707}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VOCADOM", "normalizedForm": "VOCADOM", "offsetStart": 108, "offsetEnd": 115}, "context": "This work was made with the support of the French National Research Agency, in the framework of the project VOCADOM \"Robust voice command adapted to the user and to the context for AAL\" (ANR-16-CE33-0006). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.13004374504089355}, "created": {"value": false, "score": 0.02149224281311035}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.13004374504089355}, "created": {"value": false, "score": 0.02149224281311035}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FNETWORK", "normalizedForm": "FNETWORK", "offsetStart": 111, "offsetEnd": 119}, "context": "The speech enhancement models trained on the three different noise conditions are denoted as FCHIME, FSSN, and FNETWORK, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9756399393081665}, "created": {"value": false, "score": 0.0001049041748046875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9756399393081665}, "created": {"value": false, "score": 0.0001049041748046875}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 128, "offsetEnd": 136}, "context": "DeepSHAP combines efficient, analytical computation of SHAP values for simple network modules (linear, maxout, activation) with DeepLIFT's mutiplier composition rule to backpropagate these attribution values down to the input layer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015234947204589844}, "created": {"value": false, "score": 1.6927719116210938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 178, "offsetEnd": 186}, "context": "It was shown in [23] that multiple feature attribution techniques such as layer wise relevance propagation (LRP), local interpretable model-agnostic explanations (LIME) [24] and DeepLIFT are special cases of DeepSHAP, therefore we use DeepSHAP to explain the performance of speech enhancement models in this work. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.013791561126708984}, "created": {"value": false, "score": 3.075599670410156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 208, "offsetEnd": 216}, "context": "It was shown in [23] that multiple feature attribution techniques such as layer wise relevance propagation (LRP), local interpretable model-agnostic explanations (LIME) [24] and DeepLIFT are special cases of DeepSHAP, therefore we use DeepSHAP to explain the performance of speech enhancement models in this work. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.013791561126708984}, "created": {"value": false, "score": 3.075599670410156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepLIFT", "normalizedForm": "DeepLIFT", "offsetStart": 219, "offsetEnd": 227}, "context": "We used the DeepExplainer3 component of the toolkit, which computes the SHAP values analytically for simple DNN modules (linear, sigmoid) or using the gradient for complex modules (Bi-LSTM) and backpropagates them with DeepLIFT's multiplier composition rule. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730984568595886}, "created": {"value": false, "score": 0.18237751722335815}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepSHAP", "normalizedForm": "DeepSHAP", "offsetStart": 235, "offsetEnd": 243}, "context": "It was shown in [23] that multiple feature attribution techniques such as layer wise relevance propagation (LRP), local interpretable model-agnostic explanations (LIME) [24] and DeepLIFT are special cases of DeepSHAP, therefore we use DeepSHAP to explain the performance of speech enhancement models in this work. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.013791561126708984}, "created": {"value": false, "score": 3.075599670410156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9980412721633911}, "created": {"value": false, "score": 0.013819396495819092}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[23]", "normalizedForm": "[23]", "refKey": 23}]}], "references": [{"refKey": 23, "tei": "<biblStruct xml:id=\"b23\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Ecosystem Resilience and Productivity: Are Predictions Possible?</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Per</forename><surname>Lundberg</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Peter</forename><surname>Frodin</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.2307/3546781</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Oikos</title>\n\t\t<title level=\"j\" type=\"abbrev\">Oikos</title>\n\t\t<idno type=\"ISSN\">0030-1299</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">81</biblScope>\n\t\t\t<biblScope unit=\"issue\">3</biblScope>\n\t\t\t<biblScope unit=\"page\">603</biblScope>\n\t\t\t<date type=\"published\" when=\"1998-04\">2017</date>\n\t\t\t<publisher>JSTOR</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 9543, "id": "2e79396af910f5982515dabadc0469a8eb8239ab", "metadata": {"id": "2e79396af910f5982515dabadc0469a8eb8239ab"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03257450.grobid.tei.xml", "file_name": "hal-03257450.grobid.tei.xml"}