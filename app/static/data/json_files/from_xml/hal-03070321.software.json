{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:52+0000", "md5": "C3BAE9C113DD75EBC228CFC7141DBF39", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 0, "offsetEnd": 10}, "context": "WavAugment is publicly available at github.com/facebookresearch/WavAugment. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.475780487060547e-05}, "created": {"value": false, "score": 0.0002154707908630371}, "shared": {"value": true, "score": 0.989205002784729}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 0, "offsetEnd": 10}, "context": "WavAugment builds upon a C++ API to libsox1 that implements dozens of audio processing transformations. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.552436828613281e-05}, "created": {"value": false, "score": 0.024256527423858643}, "shared": {"value": false, "score": 5.125999450683594e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 0, "offsetEnd": 10}, "context": "WavAugment has a Pytorch [19] interface and Pytorch-and libsox-based effects can be interleaved transparently.", "mentionContextAttributes": {"used": {"value": false, "score": 7.939338684082031e-05}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriLight", "normalizedForm": "LibriLight", "offsetStart": 0, "offsetEnd": 10}, "context": "LibriLight (3h and 45h) and using LibriSpeech (100h). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999831914901733}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999831914901733}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpecAugment", "normalizedForm": "SpecAugment", "offsetStart": 0, "offsetEnd": 16}, "context": "SpecAugment [17] is a spectral-domain augmentation whose effect is to mask bands of frequency and/or time. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.9948692321777344e-05}, "created": {"value": false, "score": 1.8358230590820312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11752033233642578}, "created": {"value": false, "score": 2.3245811462402344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 13, "offsetEnd": 23}, "context": "We introduce WavAugment, that implements these augmentations in the time domain and is optimized for applying augmentations on-the-fly as part of data loading.", "mentionContextAttributes": {"used": {"value": false, "score": 3.147125244140625e-05}, "created": {"value": true, "score": 0.9999314546585083}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 19, "offsetEnd": 29}, "context": "Here, we introduce WavAugment, a time-domain data augmentation library and find that applying augmentation in the past is generally more efficient and yields better performances than other methods. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.936622619628906e-05}, "created": {"value": true, "score": 0.9999405145645142}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 19, "offsetEnd": 29}, "context": "We have introduced WavAugment, a library for time-domain data augmentation and illustrated its use in the context of unsupervised contrastive representation learning, and in the context of learning with limited supervision. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001342296600341797}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ct", "normalizedForm": "ct", "offsetStart": 23, "offsetEnd": 25}, "context": "At each step, we apply ct to a predictor neural network P red with several outputs P red k each one reconstructing future representations z t+k (0 < k \u2264 K, K = 12). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9437274932861328}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993683695793152}, "created": {"value": false, "score": 0.0031656622886657715}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 23, "offsetEnd": 33}, "context": "For this, we developed WavAugment, a library that implements timedomain augmentations. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.300739288330078e-05}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 34, "offsetEnd": 45}, "context": "LibriLight (3h and 45h) and using LibriSpeech (100h). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999831914901733}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999831914901733}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "libsox", "normalizedForm": "libsox", "offsetStart": 36, "offsetEnd": 43}, "context": "WavAugment builds upon a C++ API to libsox1 that implements dozens of audio processing transformations. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.552436828613281e-05}, "created": {"value": false, "score": 0.024256527423858643}, "shared": {"value": false, "score": 5.125999450683594e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 7.939338684082031e-05}, "created": {"value": false, "score": 0.024256527423858643}, "shared": {"value": false, "score": 5.125999450683594e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Challenge", "normalizedForm": "Challenge", "offsetStart": 53, "offsetEnd": 62}, "context": "We selected the three dev datasets of the ZeroSpeech Challenge 2017, covering English, French, and Mandarin.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985664486885071}, "created": {"value": false, "score": 0.0031981468200683594}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999519944190979}, "created": {"value": false, "score": 0.0031981468200683594}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9,", "normalizedForm": "[9", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "libsox", "normalizedForm": "libsox", "offsetStart": 56, "offsetEnd": 62}, "context": "WavAugment has a Pytorch [19] interface and Pytorch-and libsox-based effects can be interleaved transparently.", "mentionContextAttributes": {"used": {"value": false, "score": 7.939338684082031e-05}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 7.939338684082031e-05}, "created": {"value": false, "score": 0.024256527423858643}, "shared": {"value": false, "score": 5.125999450683594e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpecAugment", "normalizedForm": "SpecAugment", "offsetStart": 56, "offsetEnd": 71}, "context": "The last two augmentations are similar to those used in SpecAugment [17]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11752033233642578}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11752033233642578}, "created": {"value": false, "score": 2.3245811462402344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 62, "offsetEnd": 72}, "context": "We explore how to perform data augmentation and introduce the WavAugment package.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9998975992202759}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 64, "offsetEnd": 74}, "context": "WavAugment is publicly available at github.com/facebookresearch/WavAugment.", "mentionContextAttributes": {"used": {"value": false, "score": 8.475780487060547e-05}, "created": {"value": false, "score": 0.0002154707908630371}, "shared": {"value": true, "score": 0.989205002784729}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0001404285430908203}, "created": {"value": true, "score": 0.9999423027038574}, "shared": {"value": true, "score": 0.989205002784729}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Challenge", "normalizedForm": "Challenge", "offsetStart": 76, "offsetEnd": 85}, "context": "For training, we used both the small indomain training sets provided by the Challenge (45h, 24h, and 2h30, respectively), and our own, larger, out-of-domain training sets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999519944190979}, "created": {"value": false, "score": 2.0503997802734375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999519944190979}, "created": {"value": false, "score": 0.0031981468200683594}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9,", "normalizedForm": "[9", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Challenge", "normalizedForm": "Challenge", "offsetStart": 94, "offsetEnd": 103}, "context": "As in the previous experiment, the metrics are the within-and across-ABX test provided by the Challenge. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9825122356414795}, "created": {"value": false, "score": 4.589557647705078e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999519944190979}, "created": {"value": false, "score": 0.0031981468200683594}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9,", "normalizedForm": "[9", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ct", "normalizedForm": "ct", "offsetStart": 98, "offsetEnd": 100}, "context": "The sequence (zt) is then passed to a recurrent context network to build our final representation ct.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993683695793152}, "created": {"value": false, "score": 0.0031656622886657715}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993683695793152}, "created": {"value": false, "score": 0.0031656622886657715}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpecAugment", "normalizedForm": "SpecAugment", "offsetStart": 119, "offsetEnd": 130}, "context": "Interestingly, the two most popular data augmentation techniques that are typically done in the spectral domain (as in SpecAugment) do not work very well for CPC training. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.127357482910156e-05}, "created": {"value": false, "score": 2.3245811462402344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.11752033233642578}, "created": {"value": false, "score": 2.3245811462402344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ct", "normalizedForm": "ct", "offsetStart": 129, "offsetEnd": 131}, "context": "As discussed in Section 3.1, the encoded representations zt are used in two ways: (a) to calculate the contextual representation ct, and (b) as target predictions (positive or negative candidates).We refer to the representation zt as past and the targets z + , z -as future.", "mentionContextAttributes": {"used": {"value": true, "score": 0.922447681427002}, "created": {"value": false, "score": 4.947185516357422e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993683695793152}, "created": {"value": false, "score": 0.0031656622886657715}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Challenge", "normalizedForm": "Challenge", "offsetStart": 175, "offsetEnd": 184}, "context": "This metric has been shown to be useful to analyse the linguistic content of speech features without having to train a classifier [23], and has been used in the Zero Resource Challenge series [9,10,24].", "mentionContextAttributes": {"used": {"value": false, "score": 0.001269996166229248}, "created": {"value": false, "score": 0.0008546113967895508}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999519944190979}, "created": {"value": false, "score": 0.0031981468200683594}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9,", "normalizedForm": "[9", "refKey": 9, "offsetStart": 8524, "offsetEnd": 8527}]}], "references": [{"refKey": 9, "tei": "<biblStruct xml:id=\"b9\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">The Zero Resource Speech Challenge 2015: Proposed Approaches and Results</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Maarten</forename><surname>Versteegh</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xavier</forename><surname>Anguera</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Aren</forename><surname>Jansen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Emmanuel</forename><surname>Dupoux</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1016/j.procs.2016.04.031</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Procedia Computer Science</title>\n\t\t<title level=\"j\" type=\"abbrev\">Procedia Computer Science</title>\n\t\t<idno type=\"ISSN\">1877-0509</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">81</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"67\" to=\"72\" />\n\t\t\t<date type=\"published\" when=\"2016\">2016</date>\n\t\t\t<publisher>Elsevier BV</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 20651, "id": "9a82db7d63ef771202d53e355dcece5cef7cd1e0", "metadata": {"id": "9a82db7d63ef771202d53e355dcece5cef7cd1e0"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03070321.grobid.tei.xml", "file_name": "hal-03070321.grobid.tei.xml"}