{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:45+0000", "md5": "0C5DF65573BF40130F33999FA29B5DB7", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 4, "offsetEnd": 10}, "context": "For sBLIMP, the candidates are slightly different. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032015442848205566}, "created": {"value": false, "score": 1.4543533325195312e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 4, "offsetEnd": 10}, "context": "For sWUGGY, let's assume that we have N words w 1 , . . .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9606029987335205}, "created": {"value": false, "score": 2.014636993408203e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 8, "offsetEnd": 14}, "context": "Syntax: sBLIMP acceptability metrics.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007449030876159668}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 9, "offsetEnd": 15}, "context": "Lexicon: sWUGGY spot-the-word metrics.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005626082420349121}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spot", "normalizedForm": "Spot", "offsetStart": 10, "offsetEnd": 14}, "context": "Table S3: Spot-the-word accuracy (higher is better) on sWUGGY dev as a function of the masking parameters to compute the pseudo-probabilities. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8456151485443115}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8456151485443115}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 10, "offsetEnd": 16}, "context": "The final sWUGGY test and development sets consists of 20,000 and 5,000 pairs respectively, with the existing words being part of the LibriSpeech train vocabulary.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5385091304779053}, "created": {"value": false, "score": 4.4465065002441406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 10, "offsetEnd": 17}, "context": "We used a PyTorch implementation of CPC7  (Rivi\u00e8re et al., 2020), which is a modified version of the CPC model that stabilizes the CPC training by replacing batch normalization with a channel-wise normalization and improves the CPC model by replacing the linear classifier W k in equation ( 2) with a 1-layer Transformer network (Vaswani et al., 2017). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9232500195503235}, "created": {"value": false, "score": 1.7881393432617188e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9232500195503235}, "created": {"value": false, "score": 1.7881393432617188e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 16, "offsetEnd": 22}, "context": "Finally, in our sWUGGY dataset, we extend this logic to the lexical level by comparing the pseudo-probability associated to words and nonwords.", "mentionContextAttributes": {"used": {"value": false, "score": 0.018830478191375732}, "created": {"value": false, "score": 0.02733933925628662}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 25, "offsetEnd": 31}, "context": "Stimuli in the sSIMI and sBLIMP test sets are split evenly among the four different voices, and sWUGGY uses all four for each test set stimulus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6928260922431946}, "created": {"value": false, "score": 4.76837158203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 27, "offsetEnd": 38}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "All models were trained on LibriSpeech 960h. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999790191650391}, "created": {"value": false, "score": 5.125999450683594e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 30, "offsetEnd": 41}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "We used as a training set the LibriSpeech 960h dataset (Panayotov et al., 2015). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998478889465332}, "created": {"value": false, "score": 0.00015544891357421875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WUGGY", "normalizedForm": "WUGGY", "offsetStart": 31, "offsetEnd": 66}, "context": "The nonwords are produced with WUGGY (Keuleers and Brysbaert, 2010), which generates for a given word, a list of candidate nonwords best matched in phonotactics and syllabic structure. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9554746747016907}, "created": {"value": false, "score": 0.007094919681549072}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9554746747016907}, "created": {"value": false, "score": 0.007094919681549072}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 32, "offsetEnd": 38}, "context": "We also prepared additional OOV-sWUGGY test and development sets consisting of 20,000 and 5,000 pairs respectively, with existing words which do not appear in the LibriSpeech training set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5498854517936707}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 32, "offsetEnd": 43}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "A phonetic transcription of the LibriSpeech dataset was also employed.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999338388442993}, "created": {"value": false, "score": 2.1219253540039062e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 35, "offsetEnd": 46}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "Pairs containing a word not in the LibriSpeech train set Panayotov et al. (2015) were discarded.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999487400054932}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "fairseq", "normalizedForm": "fairseq", "offsetStart": 36, "offsetEnd": 61}, "context": "All the implementation was done via fairseq (Ott et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999642372131348}, "created": {"value": false, "score": 0.0003986954689025879}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999642372131348}, "created": {"value": false, "score": 0.0003986954689025879}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mturk", "normalizedForm": "mturk", "offsetStart": 37, "offsetEnd": 42}, "context": "We selected as a development set the mturk-771 dataset, which was, in preliminary study using character-and word-based LMs, both highly correlated with all other datasets and was large enough to be used as a development set. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9953041076660156}, "created": {"value": false, "score": 0.17451757192611694}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.997417688369751}, "created": {"value": false, "score": 0.17451757192611694}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Radinsky et al., 2011)", "normalizedForm": "Radinsky et al., 2011", "refKey": 33}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Librispeech", "normalizedForm": "Librispeech", "offsetStart": 43, "offsetEnd": 54}, "context": "We generated a forced-alignment version of Librispeech using the abkhazia library3 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.834130048751831}, "created": {"value": false, "score": 0.09115457534790039}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.834130048751831}, "created": {"value": false, "score": 0.09115457534790039}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 47, "offsetEnd": 53}, "context": "We first show the algorithm that we applied to sWUGGY, then we just modify slightly the algorithm for the sBLIMP dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9951646327972412}, "created": {"value": false, "score": 0.022321462631225586}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 47, "offsetEnd": 58}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The k-means training was done on the subset of LibriSpeech containing 100 hours of clean speech.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999815225601196}, "created": {"value": false, "score": 7.140636444091797e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 53, "offsetEnd": 64}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "For the second, we retrieved the audio extracts from LibriSpeech corresponding to each word, following the process presented in (Chung and Glass, 2018). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999873638153076}, "created": {"value": false, "score": 0.00013947486877441406}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 53, "offsetEnd": 64}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "We showed that a simple CPC+clustering+LM trained on LibriSpeech can perform above chance on all of these tests, outperforming n-gram models, while being worse than text-based models trained on the same data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4729694724082947}, "created": {"value": false, "score": 5.5909156799316406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY dev", "normalizedForm": "sWUGGY dev", "offsetStart": 55, "offsetEnd": 65}, "context": "Table S3: Spot-the-word accuracy (higher is better) on sWUGGY dev as a function of the masking parameters to compute the pseudo-probabilities. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8456151485443115}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8456151485443115}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 60, "offsetEnd": 71}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI", "offsetStart": 73, "offsetEnd": 78}, "context": "The 4 datasets are composed of speech sounds extracted from LibriSpeech (sSIMI), or synthetic stimuli constructed with the Google API4 using 4 different voices, two males and two females (sWUGGY, sBLIMP, sSIMI)5 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982765913009644}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 62, "offsetEnd": 68}, "context": "Table S4 shows the detailed results on the various subsets of sBLIMP of our best model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996278285980225}, "created": {"value": false, "score": 0.0001944899559020996}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 65, "offsetEnd": 71}, "context": "We describe here our sampling method to balance ngram scores for sWUGGY and sBLIMP datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03686040639877319}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 76, "offsetEnd": 82}, "context": "We describe here our sampling method to balance ngram scores for sWUGGY and sBLIMP datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03686040639877319}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 77, "offsetEnd": 88}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The datasets containing words or sentences were filtered to only contain the LibriSpeech vocabulary, and are split into dev and test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999169111251831}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 81, "offsetEnd": 92}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The performance gap between the RoBERTa large system and our toplines trained on LibriSpeech suggest that much is to be gained by increasing the size of the training set, which can be obtained by large unlabelled audio datasets like LibriVox. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.012247562408447266}, "created": {"value": false, "score": 0.00019186735153198242}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 96, "offsetEnd": 102}, "context": "Stimuli in the sSIMI and sBLIMP test sets are split evenly among the four different voices, and sWUGGY uses all four for each test set stimulus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6928260922431946}, "created": {"value": false, "score": 4.76837158203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 98, "offsetEnd": 104}, "context": "We adapted the code used to generate the BLIMP dataset (Warstadt et al., 2019) in order to create sBLIMP, specifically tailored for speech purposes.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5362345576286316}, "created": {"value": true, "score": 0.5752239227294922}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 106, "offsetEnd": 112}, "context": "We first show the algorithm that we applied to sWUGGY, then we just modify slightly the algorithm for the sBLIMP dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9951646327972412}, "created": {"value": false, "score": 0.022321462631225586}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 110, "offsetEnd": 121}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The synthesised subset is composed of 9744 and 705 word pairs for the test and dev sets respectively, and the LibriSpeech subset is composed of 3753 and 309 pairs for the test and dev sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7293131351470947}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 110, "offsetEnd": 121}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "For topline comparison, we trained a BERT model on force-aligned phonemes using the gold transcription of the LibriSpeech dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.00010156631469726562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google API", "normalizedForm": "Google API", "offsetStart": 123, "offsetEnd": 134}, "context": "The 4 datasets are composed of speech sounds extracted from LibriSpeech (sSIMI), or synthetic stimuli constructed with the Google API4 using 4 different voices, two males and two females (sWUGGY, sBLIMP, sSIMI)5 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982765913009644}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9982765913009644}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 134, "offsetEnd": 145}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The final sWUGGY test and development sets consists of 20,000 and 5,000 pairs respectively, with the existing words being part of the LibriSpeech train vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5385090708732605}, "created": {"value": false, "score": 4.4465065002441406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 134, "offsetEnd": 145}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "In addition to the BERT trained on forced alignments, we also included a BERT model trained on the gold phonetic transcription of the LibriSpeech dataset, with the difference that we only mask one token instead of a span of tokens.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995445609092712}, "created": {"value": false, "score": 6.16312026977539e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 147, "offsetEnd": 153}, "context": "We set up four metrics with their accompanying datasets, to evaluate the sLMs at four levels: phonetic (the Libri-light ABX metrics), lexical (the sWUGGY spot-the-word metrics), syntactic (the sBLIMP acceptability metrics) and semantic (the sSIMI similarity metric).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": false, "score": 0.00030803680419921875}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 153, "offsetEnd": 159}, "context": "The sentence acceptability accuracy is reported similarly to the spot-the-word accuracy with the pairs of grammatical and ungrammatical sentences in the sBLIMP dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9967302083969116}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 153, "offsetEnd": 159}, "context": "Almost all of the subsets show better than chance scores (11/12), and of the phoneme ngrams controls (11/12), Table S4: Sentence acceptability accuracy (sBLIMP dev set, higher is better, chance level at 50%) for our best CPC+kmeans 50+BERT model, compared to phone ngram baselines, text-based transformer toplines, and human scores (from Warstadt et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": false, "score": 1.1920928955078125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 157, "offsetEnd": 168}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "The natural subset is therefore smaller than its synthesized counterpart as we had to discard pairs from the test and dev sets which were not present in the LibriSpeech test and dev sets respectively. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999624490737915}, "created": {"value": false, "score": 2.276897430419922e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 163, "offsetEnd": 174}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "We also prepared additional OOV-sWUGGY test and development sets consisting of 20,000 and 5,000 pairs respectively, with existing words which do not appear in the LibriSpeech training set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5498830676078796}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 172, "offsetEnd": 183}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "As each word consists of possibly several voices, we averaged the similarity distance over pairs of the same voice for the synthetic subset, and all possible pairs for the LibriSpeech subset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999895095825195}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 188, "offsetEnd": 194}, "context": "The 4 datasets are composed of speech sounds extracted from LibriSpeech (sSIMI), or synthetic stimuli constructed with the Google API4 using 4 different voices, two males and two females (sWUGGY, sBLIMP, sSIMI)5 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982765913009644}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 193, "offsetEnd": 199}, "context": "We set up four metrics with their accompanying datasets, to evaluate the sLMs at four levels: phonetic (the Libri-light ABX metrics), lexical (the sWUGGY spot-the-word metrics), syntactic (the sBLIMP acceptability metrics) and semantic (the sSIMI similarity metric).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": false, "score": 0.00030803680419921875}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 196, "offsetEnd": 202}, "context": "The 4 datasets are composed of speech sounds extracted from LibriSpeech (sSIMI), or synthetic stimuli constructed with the Google API4 using 4 different voices, two males and two females (sWUGGY, sBLIMP, sSIMI)5 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9982765913009644}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sWUGGY", "normalizedForm": "sWUGGY", "offsetStart": 197, "offsetEnd": 203}, "context": "We now have a list of N pairs of grammatical and non-grammatical sentences and we want to choose K pairs among them such that the accuracy of the chosen pairs is as close to 50% as possible as for sWUGGY.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005092442035675049}, "created": {"value": false, "score": 0.06150740385055542}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984965324401855}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sBLIMP", "normalizedForm": "sBLIMP", "offsetStart": 210, "offsetEnd": 216}, "context": "Such methods have been used in NLP to evaluate the syntactic abilities of language models, by comparing the probabilities of grammatical versus ungrammatical sentences (Warstadt et al., 2019), and we built the sBLIMP dataset upon this work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.001544356346130371}, "created": {"value": true, "score": 0.9757153987884521}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999587535858154}, "created": {"value": true, "score": 0.9926003813743591}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 220, "offsetEnd": 231}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "For an absolute topline comparison, we used the pretrained RoBERTa large model (Liu et al., 2019), which was trained on 50K subword units on a huge dataset of total 160GB, 3000 times bigger than the transcription of the LibriSpeech 960h dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999722242355347}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 264, "offsetEnd": 275}, "publisher": {"rawForm": "sSIMI", "normalizedForm": "sSIMI"}, "context": "Next, we apply these metrics to a simple baseline system (Section 3.3), built on contrastive pretraining (Contrastive Predictive Coding, CPC, van den Oord et al., 2018;Rivi\u00e8re et al., 2020), followed by k-means clustering, which we use to decode a speech dataset (LibriSpeech, Panayotov et al., 2015) into pseudo-text.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9791210889816284}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999934434890747}, "created": {"value": false, "score": 0.009227752685546875}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mturk", "normalizedForm": "mturk", "offsetStart": 462, "offsetEnd": 467}, "context": "The similarity-based datasets include WordSim-353 (Yang and Powers, 2006), WordSim-353-SIM (Agirre et al., 2009), mc-30 (Miller andCharles, 1991), rg-65 Rubenstein and Goodenough (1965), Rare-Word (or rw) (Luong et al., 2013), simLex999 (Hill et al., 2015), simverb-3500 (Gerz et al., 2016), verb-143 (Baker et al., 2014) , YP-130 Yang and Powers (2006) and the relatedness-based datasets include MEN (Bruni et al., 2012), Wordsim-353-REL (Agirre et al., 2009), mturk-287 (Radinsky et al., 2011), mturk-771 (Halawi et al., 2012).", "mentionContextAttributes": {"used": {"value": true, "score": 0.997417688369751}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.997417688369751}, "created": {"value": false, "score": 0.17451757192611694}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Radinsky et al., 2011)", "normalizedForm": "Radinsky et al., 2011", "refKey": 33, "offsetStart": 15232, "offsetEnd": 15255}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mturk", "normalizedForm": "mturk", "offsetStart": 497, "offsetEnd": 502}, "context": "The similarity-based datasets include WordSim-353 (Yang and Powers, 2006), WordSim-353-SIM (Agirre et al., 2009), mc-30 (Miller andCharles, 1991), rg-65 Rubenstein and Goodenough (1965), Rare-Word (or rw) (Luong et al., 2013), simLex999 (Hill et al., 2015), simverb-3500 (Gerz et al., 2016), verb-143 (Baker et al., 2014) , YP-130 Yang and Powers (2006) and the relatedness-based datasets include MEN (Bruni et al., 2012), Wordsim-353-REL (Agirre et al., 2009), mturk-287 (Radinsky et al., 2011), mturk-771 (Halawi et al., 2012).", "mentionContextAttributes": {"used": {"value": true, "score": 0.997417688369751}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.997417688369751}, "created": {"value": false, "score": 0.17451757192611694}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Halawi et al., 2012)", "normalizedForm": "Halawi et al., 2012", "refKey": 20, "offsetStart": 15267, "offsetEnd": 15288}]}], "references": [{"refKey": 33, "tei": "<biblStruct xml:id=\"b33\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">A word at a time</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kira</forename><surname>Radinsky</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eugene</forename><surname>Agichtein</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Evgeniy</forename><surname>Gabrilovich</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Shaul</forename><surname>Markovitch</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/1963405.1963455</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 20th international conference on World wide web</title>\n\t\t<meeting>the 20th international conference on World wide web</meeting>\n\t\t<imprint>\n\t\t\t<publisher>ACM</publisher>\n\t\t\t<date type=\"published\" when=\"2011-03-28\">2011</date>\n\t\t\t<biblScope unit=\"page\">346</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 20, "tei": "<biblStruct xml:id=\"b20\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Large-scale learning of word relatedness with constraints</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guy</forename><surname>Halawi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Gideon</forename><surname>Dror</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Evgeniy</forename><surname>Gabrilovich</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yehuda</forename><surname>Koren</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/2339530.2339751</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>\n\t\t<meeting>the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>\n\t\t<imprint>\n\t\t\t<publisher>ACM</publisher>\n\t\t\t<date type=\"published\" when=\"2012-08-12\">2012</date>\n\t\t\t<biblScope unit=\"page\">1414</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 13267, "id": "fa085a6cbac0888e76b25bbb58413c22b669468c", "metadata": {"id": "fa085a6cbac0888e76b25bbb58413c22b669468c"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03070362.grobid.tei.xml", "file_name": "hal-03070362.grobid.tei.xml"}