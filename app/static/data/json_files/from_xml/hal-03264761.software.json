{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T17:15+0000", "md5": "57BD72C4A3684BDED3F6952576455FB5", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 2, "offsetEnd": 5}, "context": "A CRF forces the model to consider all labels of a sequence instead of making an independent prediction for each token.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020623207092285156}, "created": {"value": false, "score": 0.0001437664031982422}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 4, "offsetEnd": 8}, "context": "For BERT, we use the PyTorch implementation of huggingface13 version 2.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993002414703369}, "created": {"value": false, "score": 1.722574234008789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 4, "offsetEnd": 11}, "context": "For SciBERT, we used the uncased model with the SciBERT vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998211860656738}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 4, "offsetEnd": 11}, "version": {"rawForm": "1.1", "normalizedForm": "1.1", "offsetStart": 29, "offsetEnd": 32}, "context": "For BioBERT, we used version 1.1. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 4, "offsetEnd": 11}, "context": "For RoBERTa, we increased the number of epochs for fine-tuning to 10, as it was done in the original paper.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 6, "offsetEnd": 13}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033836960792541504}, "created": {"value": false, "score": 7.778406143188477e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 8, "offsetEnd": 12}, "context": "[61] or BERT) [38].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9967494010925293}, "created": {"value": false, "score": 6.616115570068359e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38, "offsetStart": 51555, "offsetEnd": 51559}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 9, "offsetEnd": 16}, "context": "Overall, SciBERT uncased is the best performing model with a macro F1-score of .80. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.020895183086395264}, "created": {"value": false, "score": 1.1980533599853516e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 11, "offsetEnd": 15}, "context": "There, the BERT pre-training procedure is modified by exchanging static with dynamic masking, using larger byte-pair encoding and batches size, and increasing the size of the dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019860267639160156}, "created": {"value": false, "score": 0.00011140108108520508}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 13, "offsetEnd": 25}, "context": "Furthermore, RoBERTa [65] is employed, another new model, which outperforms BERT on the General Language Understanding Evaluation (GLUE) benchmark. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.744001388549805e-05}, "created": {"value": false, "score": 0.004420459270477295}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExaCT", "normalizedForm": "ExaCT", "offsetStart": 14, "offsetEnd": 24}, "context": "For instance, ExaCT [40] extracts information containing PICO elements based on a SVM. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015854835510253906}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00015854835510253906}, "created": {"value": false, "score": 4.231929779052734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 15, "offsetEnd": 22}, "context": "Interestingly, RoBERTa delivers comparable results even though it is a model trained on general data.", "mentionContextAttributes": {"used": {"value": false, "score": 5.525350570678711e-05}, "created": {"value": false, "score": 0.0008388161659240723}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 18, "offsetEnd": 30}, "context": "Contrary to that, SciBERT [63] is trained from scratch with an own vocabulary. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002943277359008789}, "created": {"value": false, "score": 2.390146255493164e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 20, "offsetEnd": 24}, "context": "For fine-tuning the BERT model, we used the uncased base model with 12 transformer blocks, a hidden size of 768, 12 attention heads, a learning rate of 2e-5 with Adam optimizer for 3 epochs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": false, "score": 2.9146671295166016e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 21, "offsetEnd": 25}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008782148361206055}, "created": {"value": false, "score": 7.063150405883789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "offsetStart": 21, "offsetEnd": 28}, "context": "For BERT, we use the PyTorch implementation of huggingface13 version 2.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993002414703369}, "created": {"value": false, "score": 1.722574234008789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998788237571716}, "created": {"value": false, "score": 0.0011254549026489258}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 24, "offsetEnd": 31}, "context": "Interestingly here, the SciBERT cased model performs the best with a F1-score of .65. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003639042377471924}, "created": {"value": false, "score": 2.1636486053466797e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 26, "offsetEnd": 33}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "In the binary evaluation, BioBERT is slightly better with the exception of the noOccurrence class. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004870057106018066}, "created": {"value": false, "score": 1.519918441772461e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 28, "offsetEnd": 35}, "context": "We chose to use the uncased SciBERT model, meaning that we ignore the capitalization of words. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994412660598755}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 29, "offsetEnd": 36}, "context": "However, the improvement for RoBERTa is only marginal.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008884787559509277}, "created": {"value": false, "score": 0.0001214146614074707}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 31, "offsetEnd": 38}, "context": "The confusion matrices for the SciBERT SentClf and its counterpart with the weighted loss function are shown exemplary in Figure 2. The Support relation was not as often misclassified as with the unweighted loss function.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999435544013977}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 36, "offsetEnd": 40}, "context": "As it was the case for the original BERT, the uncased model of SciBERT performs slightly better for sentence classification tasks than the cased model.", "mentionContextAttributes": {"used": {"value": false, "score": 5.65648078918457e-05}, "created": {"value": false, "score": 1.3768672943115234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 38, "offsetEnd": 42}, "context": "Comparing the specialized and general BERT model, the Bio-and SciBERT increase the performance by up to .06", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002592802047729492}, "created": {"value": false, "score": 8.577108383178711e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 41, "offsetEnd": 45}, "context": "A similar situation was observed for the BERT cased model on the gold standard, where the 0 F1-score of the NoOccurrence class lowered the macro F1-score significantly with respect to the other models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995772242546082}, "created": {"value": false, "score": 3.88026237487793e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Semantic Scholar", "normalizedForm": "Semantic Scholar", "offsetStart": 45, "offsetEnd": 61}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033836960792541504}, "created": {"value": false, "score": 7.778406143188477e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0033836960792541504}, "created": {"value": false, "score": 7.778406143188477e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Sci-", "normalizedForm": "Sci", "offsetStart": 48, "offsetEnd": 52}, "context": "The same configuration was used for fine-tuning Sci-and BioBERT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.978767454624176}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.978767454624176}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 48, "offsetEnd": 52}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313787937164307}, "created": {"value": false, "score": 2.9981136322021484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 48, "offsetEnd": 55}, "context": "For SciBERT, we used the uncased model with the SciBERT vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998211860656738}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 50, "offsetEnd": 54}, "context": "In line with their work, we experimented with the BERT [38] base model to address parts of the AM pipeline [17].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9583075046539307}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38, "offsetStart": 14884, "offsetEnd": 14888}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 52, "offsetEnd": 56}, "context": "As an encoder for phrase pairs, we evaluate various BERT models as detailed above, just as we do for the SentClf task.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014515101909637451}, "created": {"value": false, "score": 0.00040394067764282227}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 53, "offsetEnd": 57}, "context": "The authors initialize the weights with the original BERT model and train on PubMed abstracts and full articles.", "mentionContextAttributes": {"used": {"value": false, "score": 0.19998383522033691}, "created": {"value": false, "score": 0.10226678848266602}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 54, "offsetEnd": 61}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313859462738037}, "created": {"value": false, "score": 2.9981136322021484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 56, "offsetEnd": 63}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "The same configuration was used for fine-tuning Sci-and BioBERT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.978767454624176}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 58, "offsetEnd": 62}, "context": "Therefore, the vocabulary is the same as for the original BERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.06315416097640991}, "created": {"value": false, "score": 0.0012533068656921387}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 62, "offsetEnd": 69}, "context": "Comparing the specialized and general BERT model, the Bio-and SciBERT increase the performance by up to .06 ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002592802047729492}, "created": {"value": false, "score": 8.577108383178711e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RobotReviewer", "normalizedForm": "RobotReviewer", "offsetStart": 62, "offsetEnd": 79}, "context": "Another system facilitating the evidence gathering process is RobotReviewer [44], which summarizes the key information of a clinical trial. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.131959915161133e-05}, "created": {"value": false, "score": 0.0002809762954711914}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.131959915161133e-05}, "created": {"value": false, "score": 0.0002809762954711914}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 63, "offsetEnd": 70}, "context": "As it was the case for the original BERT, the uncased model of SciBERT performs slightly better for sentence classification tasks than the cased model.", "mentionContextAttributes": {"used": {"value": false, "score": 5.65648078918457e-05}, "created": {"value": false, "score": 1.3768672943115234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 64, "offsetEnd": 71}, "context": "Interestingly, comparing the two domain adapted models, Bio-and SciBERT, there were no regular errors, which allows any conclusion about the advantages or disadvantages of one model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989938735961914}, "created": {"value": false, "score": 2.3066997528076172e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 66, "offsetEnd": 73}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313787937164307}, "created": {"value": false, "score": 2.9981136322021484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "offsetStart": 67, "offsetEnd": 74}, "context": "The outcome pipeline implementation was done with the same Python, PyTorch and transformer versions as the previous experiments. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998788237571716}, "created": {"value": false, "score": 0.0011254549026489258}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998788237571716}, "created": {"value": false, "score": 0.0011254549026489258}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 68, "offsetEnd": 72}, "context": "We employed a sequence tagging approach combining a domain specific BERT model with a GRU and CRF to identify and classify argument components.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979864954948425}, "created": {"value": false, "score": 0.004142105579376221}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 70, "offsetEnd": 77}, "context": "We speculate that parts of the web crawl data which was used to train RoBERTa contain PubMed articles, since they are freely available on the web.", "mentionContextAttributes": {"used": {"value": true, "score": 0.962836503982544}, "created": {"value": false, "score": 0.00019478797912597656}, "shared": {"value": false, "score": 0.09434199333190918}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 71, "offsetEnd": 74}, "context": "The shallow layer can be either a simple dense layer or one of the RNN CRF combinations for sequence modelling described above.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006957054138183594}, "created": {"value": false, "score": 5.370378494262695e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 74, "offsetEnd": 78}, "context": "The differences of the various shallow layers, which are required to make BERT suitable for sequence tagging, are shown exemplary in Table 4 for the uncased BERT base model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010109126567840576}, "created": {"value": false, "score": 1.8894672393798828e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 74, "offsetEnd": 81}, "context": "This is notable in the slightly increased, but more stable performance of SciBERT on the glaucoma and mixed test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8445721864700317}, "created": {"value": false, "score": 9.483098983764648e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 74, "offsetEnd": 81}, "context": "Moreover, comparing the confusion matrices of the weighted and unweighted SciBERT model, shown below, indicates a reduced error rate for the support class.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9180506467819214}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 75, "offsetEnd": 78}, "context": "The same sequence tagging architecture with the LSTM in combination with a CRF was experimented for the outcome detection and classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999750256538391}, "created": {"value": false, "score": 0.0016965866088867188}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 76, "offsetEnd": 80}, "context": "Furthermore, RoBERTa [65] is employed, another new model, which outperforms BERT on the General Language Understanding Evaluation (GLUE) benchmark.", "mentionContextAttributes": {"used": {"value": false, "score": 8.744001388549805e-05}, "created": {"value": false, "score": 0.004420459270477295}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 83, "offsetEnd": 90}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0788440704345703e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 84, "offsetEnd": 87}, "context": "Interestingly, adding a uni-directional GRU or LSTM between the transformer and the CRF does not increase the overall results.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019292831420898438}, "created": {"value": false, "score": 5.9664249420166016e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 90, "offsetEnd": 93}, "context": "For the sequence tagging architecture, we experimented with the GRU in combination with a CRF, because it provided slightly better results than the LSTM for the argument component detection.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9941543936729431}, "created": {"value": false, "score": 0.01691126823425293}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 91, "offsetEnd": 95}, "context": "Similar to sequence tagging, one can see a notable increase in performance when applying a BERT model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014853477478027344}, "created": {"value": false, "score": 0.00019240379333496094}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 94, "offsetEnd": 97}, "context": "We employed a sequence tagging approach combining a domain specific BERT model with a GRU and CRF to identify and classify argument components.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979864954948425}, "created": {"value": false, "score": 0.004142105579376221}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 96, "offsetEnd": 101}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0788440704345703e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 100, "offsetEnd": 103}, "context": "For sequence tagging, each of the embeddings were combined with either (i) a GRU, (ii) a GRU with a CRF, (iii) a LSTM, or (iv) a LSTM with a CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999897301197052}, "created": {"value": false, "score": 1.996755599975586e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 105, "offsetEnd": 108}, "context": "The idea is to reduce the number of invalid BI sequences not with a second (upper) RNN layer, but with a CRF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00047320127487182617}, "created": {"value": false, "score": 0.00019598007202148438}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 106, "offsetEnd": 109}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0788440704345703e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 109, "offsetEnd": 120}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008782148361206055}, "created": {"value": false, "score": 7.063150405883789e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 114, "offsetEnd": 117}, "context": "Recently, Jin and Szolovits [43] proposed deep learning models to address PICO elements detection, such as BiLSTM CRF combinations, and methods to improve the generalization of these models.", "mentionContextAttributes": {"used": {"value": false, "score": 7.253885269165039e-05}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 114, "offsetEnd": 118}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9707997441291809}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 119, "offsetEnd": 126}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 119, "offsetEnd": 126}, "context": "Similarly to the relation classification results, we can observe an increase in performance on the specialized Bio-and SciBERT models compared to the general BERT model. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.976395845413208}, "created": {"value": false, "score": 1.9371509552001953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 120, "offsetEnd": 127}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9707997441291809}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 123, "offsetEnd": 126}, "context": "We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of .87 for component detection and .68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of .80 for outcome classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6730418801307678}, "created": {"value": false, "score": 0.000376284122467041}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 125, "offsetEnd": 132}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033836960792541504}, "created": {"value": false, "score": 7.778406143188477e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999978244304657}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 126, "offsetEnd": 133}, "context": "Looking at the main difference in the results, finetuning transformers shows a significant improvement to other models, where SciBERT with .87 ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8662868142127991}, "created": {"value": false, "score": 5.900859832763672e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 132, "offsetEnd": 139}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9707997441291809}, "created": {"value": false, "score": 0.00011307001113891602}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 141, "offsetEnd": 144}, "context": "For sequence tagging, each of the embeddings were combined with either (i) a GRU, (ii) a GRU with a CRF, (iii) a LSTM, or (iv) a LSTM with a CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999897301197052}, "created": {"value": false, "score": 1.996755599975586e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 142, "offsetEnd": 147}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 152, "offsetEnd": 155}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 157, "offsetEnd": 161}, "context": "The differences of the various shallow layers, which are required to make BERT suitable for sequence tagging, are shown exemplary in Table 4 for the uncased BERT base model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010109126567840576}, "created": {"value": false, "score": 1.8894672393798828e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 158, "offsetEnd": 162}, "context": "Similarly to the relation classification results, we can observe an increase in performance on the specialized Bio-and SciBERT models compared to the general BERT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.976395845413208}, "created": {"value": false, "score": 1.9371509552001953e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 168, "offsetEnd": 171}, "context": "Taking a look at the various options for the sequence modelling shallow layer on top of the transformer in Table 4, the most notable difference is achieved by adding a CRF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08863306045532227}, "created": {"value": false, "score": 2.014636993408203e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 178, "offsetEnd": 185}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 183, "offsetEnd": 190}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9707997441291809}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959925413131714}, "created": {"value": false, "score": 0.10356330871582031}, "shared": {"value": false, "score": 0.09434199333190918}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 204, "offsetEnd": 208}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008781552314758301}, "created": {"value": false, "score": 7.05718994140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997737407684326}, "created": {"value": true, "score": 0.645095705986023}, "shared": {"value": false, "score": 1.2516975402832031e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 208, "offsetEnd": 213}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 2.0802021026611328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 218, "offsetEnd": 221}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902844429016}, "created": {"value": false, "score": 0.338853657245636}, "shared": {"value": false, "score": 7.748603820800781e-07}}}], "references": [{"refKey": 38, "tei": "<biblStruct xml:id=\"b38\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Exploring teachers\u2019 confidence in addressing mental health issues in learners with Profound and Multiple Learning Difficulties (PMLD) pre and post training</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Devlin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ming-Wei</forename><surname>Chang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kristina</forename><surname>Toutanova</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.16922/wje.p5</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Cylchgrawn Addysg Cymru / Wales Journal of Education</title>\n\t\t<title level=\"j\" type=\"abbrev\">WJE</title>\n\t\t<idno type=\"ISSN\">2059-3708</idno>\n\t\t<idno type=\"ISSNe\">2059-3716</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"page\">4186</biblScope>\n\t\t\t<date type=\"published\" when=\"2024-03-28\">2019</date>\n\t\t\t<publisher>University of Wales Press/Gwasg Prifysgol Cymru</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 65431, "id": "d97e5aae4b4d32c1e6e46e683bfc30340cca19c0", "metadata": {"id": "d97e5aae4b4d32c1e6e46e683bfc30340cca19c0"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-03264761.grobid.tei.xml", "file_name": "hal-03264761.grobid.tei.xml"}