{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:09+0000", "md5": "129C1A5EF962805A136E3396B57D1F94", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 0, "offsetEnd": 8}, "context": "Argument Mining One of the latest advances in the field of artificial argumentation [21] deals with the automatic processing of text to extract argumentative structures.", "mentionContextAttributes": {"used": {"value": false, "score": 7.712841033935547e-05}, "created": {"value": false, "score": 0.19798403978347778}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 0, "offsetEnd": 8}, "context": "Argument Mining pipeline The whole AM pipeline (i.e., mining both argumentative components and the relations connecting them) has been implemented in few application scenarios.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013303756713867188}, "created": {"value": false, "score": 0.0030672550201416016}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 0, "offsetEnd": 8}, "context": "Argument Components For this task, the IAA was calculated for tokenlevel annotation.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 2, "offsetEnd": 5}, "context": "A CRF forces the model to consider all labels of a sequence instead of making an independent prediction for each token.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020629167556762695}, "created": {"value": false, "score": 0.0001437664031982422}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 2, "offsetEnd": 10}, "context": "\u2022 Argument Components: Comprising major claims, claims and evidence, where a major claim is a general statement about properties of treatments or diseases, a claim is a concluding statement, and an evidence/premise is an observation or measurement in the study (see subsection 3.2.1).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008663535118103027}, "created": {"value": false, "score": 8.428096771240234e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 4, "offsetEnd": 8}, "context": "For BERT, we use the PyTorch implementation of huggingface13 version 2.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993002414703369}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 4, "offsetEnd": 11}, "context": "For SciBERT, we used the uncased model with the SciBERT vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998212456703186}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 4, "offsetEnd": 11}, "version": {"rawForm": "1.1", "normalizedForm": "1.1", "offsetStart": 29, "offsetEnd": 32}, "context": "For BioBERT, we used version 1.1. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 4, "offsetEnd": 11}, "context": "For RoBERTa, we increased the number of epochs for fine-tuning to 10, as it was done in the original paper.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 6, "offsetEnd": 13}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033835768699645996}, "created": {"value": false, "score": 7.772445678710938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 8, "offsetEnd": 12}, "context": "[61] or BERT) [38].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9967494010925293}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38, "offsetStart": 51555, "offsetEnd": 51559}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 9, "offsetEnd": 16}, "context": "Overall, SciBERT uncased is the best performing model with a macro F1-score of .80. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.020895183086395264}, "created": {"value": false, "score": 1.1920928955078125e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 11, "offsetEnd": 15}, "context": "There, the BERT pre-training procedure is modified by exchanging static with dynamic masking, using larger byte-pair encoding and batches size, and increasing the size of the dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019854307174682617}, "created": {"value": false, "score": 0.00011134147644042969}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 13, "offsetEnd": 25}, "context": "Furthermore, RoBERTa [65] is employed, another new model, which outperforms BERT on the General Language Understanding Evaluation (GLUE) benchmark. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.738040924072266e-05}, "created": {"value": false, "score": 0.004420340061187744}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExaCT", "normalizedForm": "ExaCT", "offsetStart": 14, "offsetEnd": 24}, "context": "For instance, ExaCT [40] extracts information containing PICO elements based on a SVM. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015854835510253906}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00015854835510253906}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 15, "offsetEnd": 22}, "context": "Interestingly, RoBERTa delivers comparable results even though it is a model trained on general data.", "mentionContextAttributes": {"used": {"value": false, "score": 5.519390106201172e-05}, "created": {"value": false, "score": 0.0008387565612792969}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 18, "offsetEnd": 30}, "context": "Contrary to that, SciBERT [63] is trained from scratch with an own vocabulary. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002943873405456543}, "created": {"value": false, "score": 2.384185791015625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 20, "offsetEnd": 24}, "context": "For fine-tuning the BERT model, we used the uncased base model with 12 transformer blocks, a hidden size of 768, 12 attention heads, a learning rate of 2e-5 with Adam optimizer for 3 epochs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": false, "score": 2.9087066650390625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 21, "offsetEnd": 25}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008781552314758301}, "created": {"value": false, "score": 7.05718994140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 21, "offsetEnd": 28}, "context": "For BERT, we use the PyTorch implementation of huggingface13 version 2.3.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993002414703369}, "created": {"value": false, "score": 1.71661376953125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998788833618164}, "created": {"value": false, "score": 0.0011253952980041504}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 24, "offsetEnd": 31}, "context": "Interestingly here, the SciBERT cased model performs the best with a F1-score of .65. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003639042377471924}, "created": {"value": false, "score": 2.1576881408691406e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 26, "offsetEnd": 33}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "In the binary evaluation, BioBERT is slightly better with the exception of the noOccurrence class. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004870057106018066}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 28, "offsetEnd": 35}, "context": "We chose to use the uncased SciBERT model, meaning that we ignore the capitalization of words. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994413256645203}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 29, "offsetEnd": 36}, "context": "However, the improvement for RoBERTa is only marginal.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008884787559509277}, "created": {"value": false, "score": 0.00012135505676269531}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 31, "offsetEnd": 38}, "context": "The confusion matrices for the SciBERT SentClf and its counterpart with the weighted loss function are shown exemplary in Figure 2. The Support relation was not as often misclassified as with the unweighted loss function.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999436140060425}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 33, "offsetEnd": 41}, "context": "This new research area is called Argument(ation) Mining (AM) [7,8,9,10], and it mainly consists of two standard tasks: (i) the identification of arguments within the text, that may be further split in the detection of argument components (e.g., claims, evidence) and the identification of their textual boundaries; (ii) the prediction of the relations holding between the arguments identified in the first stage.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032941699028015137}, "created": {"value": false, "score": 0.0020369291305541992}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 36, "offsetEnd": 40}, "context": "As it was the case for the original BERT, the uncased model of SciBERT performs slightly better for sentence classification tasks than the cased model.", "mentionContextAttributes": {"used": {"value": false, "score": 5.650520324707031e-05}, "created": {"value": false, "score": 1.3709068298339844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 38, "offsetEnd": 42}, "context": "Comparing the specialized and general BERT model, the Bio-and SciBERT increase the performance by up to .06", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002593398094177246}, "created": {"value": false, "score": 8.571147918701172e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 41, "offsetEnd": 45}, "context": "A similar situation was observed for the BERT cased model on the gold standard, where the 0 F1-score of the NoOccurrence class lowered the macro F1-score significantly with respect to the other models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995772242546082}, "created": {"value": false, "score": 3.8743019104003906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 44, "offsetEnd": 52}, "context": "Here, we follow existing work on end-to-end Argument Mining systems [66,29] to count true/false positives and false negatives for relation/component combinations to calculate the overall performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07469296455383301}, "created": {"value": true, "score": 0.9996125102043152}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Semantic Scholar", "normalizedForm": "Semantic Scholar", "offsetStart": 45, "offsetEnd": 61}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033835768699645996}, "created": {"value": false, "score": 7.772445678710938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0033835768699645996}, "created": {"value": false, "score": 7.772445678710938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Sci-", "normalizedForm": "Sci", "offsetStart": 48, "offsetEnd": 52}, "context": "The same configuration was used for fine-tuning Sci-and BioBERT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9787676930427551}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9787676930427551}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 48, "offsetEnd": 52}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used.", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313913106918335}, "created": {"value": false, "score": 2.9921531677246094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 48, "offsetEnd": 55}, "context": "For SciBERT, we used the uncased model with the SciBERT vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998212456703186}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 50, "offsetEnd": 54}, "context": "In line with their work, we experimented with the BERT [38] base model to address parts of the AM pipeline [17].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9583072662353516}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38, "offsetStart": 14884, "offsetEnd": 14888}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 51, "offsetEnd": 59}, "context": "More precisely, our pipeline is composed of (i) an Argument Mining module to extract and classify argumentative components (i.e., evidence and claims of the trial) and their relations (i.e., support, attack), and (ii) an outcome analysis module to identify and classify the effects (i.e., improved, increased, decreased, no difference, no occurrence) of an intervention on the outcome of the trial, based on PICO elements.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9913152456283569}, "created": {"value": false, "score": 0.0009600520133972168}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 52, "offsetEnd": 56}, "context": "As an encoder for phrase pairs, we evaluate various BERT models as detailed above, just as we do for the SentClf task.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0145149827003479}, "created": {"value": false, "score": 0.00040394067764282227}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 53, "offsetEnd": 57}, "context": "The authors initialize the weights with the original BERT model and train on PubMed abstracts and full articles.", "mentionContextAttributes": {"used": {"value": false, "score": 0.19998162984848022}, "created": {"value": false, "score": 0.10226684808731079}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 54, "offsetEnd": 61}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313913106918335}, "created": {"value": false, "score": 2.9921531677246094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 56, "offsetEnd": 63}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "The same configuration was used for fine-tuning Sci-and BioBERT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9787676930427551}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 58, "offsetEnd": 62}, "context": "Therefore, the vocabulary is the same as for the original BERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.06315433979034424}, "created": {"value": false, "score": 0.001253366470336914}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 62, "offsetEnd": 69}, "context": "Comparing the specialized and general BERT model, the Bio-and SciBERT increase the performance by up to .06 ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002593398094177246}, "created": {"value": false, "score": 8.571147918701172e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RobotReviewer", "normalizedForm": "RobotReviewer", "offsetStart": 62, "offsetEnd": 79}, "context": "Another system facilitating the evidence gathering process is RobotReviewer [44], which summarizes the key information of a clinical trial. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.125999450683594e-05}, "created": {"value": false, "score": 0.0002810359001159668}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.125999450683594e-05}, "created": {"value": false, "score": 0.0002810359001159668}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 63, "offsetEnd": 70}, "context": "As it was the case for the original BERT, the uncased model of SciBERT performs slightly better for sentence classification tasks than the cased model.", "mentionContextAttributes": {"used": {"value": false, "score": 5.650520324707031e-05}, "created": {"value": false, "score": 1.3709068298339844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 64, "offsetEnd": 71}, "context": "Interestingly, comparing the two domain adapted models, Bio-and SciBERT, there were no regular errors, which allows any conclusion about the advantages or disadvantages of one model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989938139915466}, "created": {"value": false, "score": 2.300739288330078e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 66, "offsetEnd": 73}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Similar to the experiments on sequence tagging, BERT, SciBERT and BioBERT are used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07313913106918335}, "created": {"value": false, "score": 2.9921531677246094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 67, "offsetEnd": 74}, "context": "The outcome pipeline implementation was done with the same Python, PyTorch and transformer versions as the previous experiments. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998788833618164}, "created": {"value": false, "score": 0.0011253952980041504}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998788833618164}, "created": {"value": false, "score": 0.0011253952980041504}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 68, "offsetEnd": 72}, "context": "We employed a sequence tagging approach combining a domain specific BERT model with a GRU and CRF to identify and classify argument components.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979865550994873}, "created": {"value": false, "score": 0.004142105579376221}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 70, "offsetEnd": 77}, "context": "We speculate that parts of the web crawl data which was used to train RoBERTa contain PubMed articles, since they are freely available on the web.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9628366231918335}, "created": {"value": false, "score": 0.00019484758377075195}, "shared": {"value": false, "score": 0.09434634447097778}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 71, "offsetEnd": 74}, "context": "The shallow layer can be either a simple dense layer or one of the RNN CRF combinations for sequence modelling described above.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006957054138183594}, "created": {"value": false, "score": 5.364418029785156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 73, "offsetEnd": 81}, "context": "In this section, we first introduce the main achievements in the area of Argument Mining, and then we discuss the main results presented in the literature to apply the Argument Mining pipeline to different application scenarios, highlighting the main advantages of our approach and the peculiarity of the clinical trial scenario.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011917352676391602}, "created": {"value": true, "score": 0.929243266582489}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 74, "offsetEnd": 78}, "context": "The differences of the various shallow layers, which are required to make BERT suitable for sequence tagging, are shown exemplary in Table 4 for the uncased BERT base model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0101090669631958}, "created": {"value": false, "score": 1.8835067749023438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 74, "offsetEnd": 81}, "context": "This is notable in the slightly increased, but more stable performance of SciBERT on the glaucoma and mixed test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8445742726325989}, "created": {"value": false, "score": 9.47713851928711e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 74, "offsetEnd": 81}, "context": "Moreover, comparing the confusion matrices of the weighted and unweighted SciBERT model, shown below, indicates a reduced error rate for the support class.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9180510640144348}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 75, "offsetEnd": 78}, "context": "The same sequence tagging architecture with the LSTM in combination with a CRF was experimented for the outcome detection and classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999750852584839}, "created": {"value": false, "score": 0.0016967058181762695}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 76, "offsetEnd": 80}, "context": "Furthermore, RoBERTa [65] is employed, another new model, which outperforms BERT on the General Language Understanding Evaluation (GLUE) benchmark.", "mentionContextAttributes": {"used": {"value": false, "score": 8.738040924072266e-05}, "created": {"value": false, "score": 0.004420340061187744}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 83, "offsetEnd": 90}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 84, "offsetEnd": 87}, "context": "Interestingly, adding a uni-directional GRU or LSTM between the transformer and the CRF does not increase the overall results.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0019292235374450684}, "created": {"value": false, "score": 5.9604644775390625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 90, "offsetEnd": 93}, "context": "For the sequence tagging architecture, we experimented with the GRU in combination with a CRF, because it provided slightly better results than the LSTM for the argument component detection.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9941545128822327}, "created": {"value": false, "score": 0.016911327838897705}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 91, "offsetEnd": 95}, "context": "Similar to sequence tagging, one can see a notable increase in performance when applying a BERT model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014853477478027344}, "created": {"value": false, "score": 0.00019234418869018555}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 94, "offsetEnd": 97}, "context": "We employed a sequence tagging approach combining a domain specific BERT model with a GRU and CRF to identify and classify argument components.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9979865550994873}, "created": {"value": false, "score": 0.004142105579376221}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 96, "offsetEnd": 101}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 100, "offsetEnd": 103}, "context": "For sequence tagging, each of the embeddings were combined with either (i) a GRU, (ii) a GRU with a CRF, (iii) a LSTM, or (iv) a LSTM with a CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998973608016968}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 103, "offsetEnd": 111}, "context": "In this section, we present an extension of the dataset of Randomized Controlled Trials annotated with Argument Mining labels we firstly introduced in [16].", "mentionContextAttributes": {"used": {"value": false, "score": 0.005077540874481201}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 105, "offsetEnd": 108}, "context": "The idea is to reduce the number of invalid BI sequences not with a second (upper) RNN layer, but with a CRF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004731416702270508}, "created": {"value": false, "score": 0.00019592046737670898}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 106, "offsetEnd": 109}, "context": "As stated earlier, for this, the two best performing models were chosen, i.e., the SciBERT with BiGRU and CRF for the sequence tagging part and the SciB-ERT with the weighted cross entropy loss for the relation classification part.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996904134750366}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 109, "offsetEnd": 120}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008781552314758301}, "created": {"value": false, "score": 7.05718994140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 112, "offsetEnd": 120}, "context": "Analyzing argumentation from the computational linguistics point of view has recently led to a new field called Argument(ation) Mining (AM) [7,8,9,10] which deals with detecting, classifying and assessing the quality of argumentative structures in text.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001596212387084961}, "created": {"value": true, "score": 0.8506578207015991}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 114, "offsetEnd": 117}, "context": "Recently, Jin and Szolovits [43] proposed deep learning models to address PICO elements detection, such as BiLSTM CRF combinations, and methods to improve the generalization of these models.", "mentionContextAttributes": {"used": {"value": false, "score": 7.2479248046875e-05}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 114, "offsetEnd": 118}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9708001017570496}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 119, "offsetEnd": 126}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 119, "offsetEnd": 126}, "context": "Similarly to the relation classification results, we can observe an increase in performance on the specialized Bio-and SciBERT models compared to the general BERT model. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9763959050178528}, "created": {"value": false, "score": 1.9311904907226562e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 120, "offsetEnd": 127}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9708001017570496}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 123, "offsetEnd": 126}, "context": "We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of .87 for component detection and .68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of .80 for outcome classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6730459928512573}, "created": {"value": false, "score": 0.0003763437271118164}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BioBERT", "normalizedForm": "BioBERT", "offsetStart": 125, "offsetEnd": 132}, "version": {"rawForm": "1.1", "normalizedForm": "1.1"}, "context": "While SciBERT is trained on full papers from Semantic Scholar it also contains biomedical data, but to a smaller degree than BioBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033835768699645996}, "created": {"value": false, "score": 7.772445678710938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 126, "offsetEnd": 133}, "context": "Looking at the main difference in the results, finetuning transformers shows a significant improvement to other models, where SciBERT with .87 ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8662858605384827}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 132, "offsetEnd": 139}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9708001017570496}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 141, "offsetEnd": 144}, "context": "For sequence tagging, each of the embeddings were combined with either (i) a GRU, (ii) a GRU with a CRF, (iii) a LSTM, or (iv) a LSTM with a CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998973608016968}, "created": {"value": false, "score": 1.990795135498047e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 142, "offsetEnd": 147}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 152, "offsetEnd": 155}, "context": "To calculate the overall performance of our pipeline, we used the best performing component detection model, i.e., the SciBERT uncased with a BiGRU and CRF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 157, "offsetEnd": 161}, "context": "The differences of the various shallow layers, which are required to make BERT suitable for sequence tagging, are shown exemplary in Table 4 for the uncased BERT base model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0101090669631958}, "created": {"value": false, "score": 1.8835067749023438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 158, "offsetEnd": 162}, "context": "Similarly to the relation classification results, we can observe an increase in performance on the specialized Bio-and SciBERT models compared to the general BERT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9763959050178528}, "created": {"value": false, "score": 1.9311904907226562e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 168, "offsetEnd": 171}, "context": "Taking a look at the various options for the sequence modelling shallow layer on top of the transformer in Table 4, the most notable difference is achieved by adding a CRF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08863294124603271}, "created": {"value": false, "score": 2.014636993408203e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 168, "offsetEnd": 176}, "context": "In this section, we first introduce the main achievements in the area of Argument Mining, and then we discuss the main results presented in the literature to apply the Argument Mining pipeline to different application scenarios, highlighting the main advantages of our approach and the peculiarity of the clinical trial scenario.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011917471885681152}, "created": {"value": true, "score": 0.929243266582489}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 178, "offsetEnd": 185}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.0001232624053955078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "RoBERTa", "normalizedForm": "RoBERTa", "offsetStart": 183, "offsetEnd": 190}, "context": "Experiments are conducted with the same pre-trained transformer model types as for relation classification, i.e., BERT, BioBERT and SciBERT (cased and uncased), with the exception of RoBERTa. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9708001017570496}, "created": {"value": false, "score": 0.00011301040649414062}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9959926009178162}, "created": {"value": false, "score": 0.10356295108795166}, "shared": {"value": false, "score": 0.09434634447097778}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 196, "offsetEnd": 204}, "context": "Alas, despite its natural employment in healthcare applications, only few approaches have applied AM methods to this kind of text [15,16,17,18], and their contribution is limited to (part of) the Argument Mining pipeline, disregarding the combination of this argumentative information with other kind of clinical data that clinicians usually look at when searching for relevant evidence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015253424644470215}, "created": {"value": false, "score": 0.01345127820968628}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BERT", "normalizedForm": "BERT", "offsetStart": 204, "offsetEnd": 208}, "context": "Besides the original BERT, which is pre-trained on the BooksCorpus and English Wikipedia, we experiment with BioBERT [62], which is pre-trained on large-scale biomedical corpora outperforming the general BERT model in representative biomedical text mining tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008781552314758301}, "created": {"value": false, "score": 7.05718994140625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997738003730774}, "created": {"value": true, "score": 0.6450972557067871}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "references": [{"label": "[38]", "normalizedForm": "[38]", "refKey": 38}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BiGRU", "normalizedForm": "BiGRU", "offsetStart": 208, "offsetEnd": 213}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CRF", "normalizedForm": "CRF", "offsetStart": 218, "offsetEnd": 221}, "context": "As for the evaluation of the overall performance of the argument mining part of the pipeline, the best performing sequence tagging model on the gold standard was selected, i.e., SciBERT in a combination with BiGRU and CRF, and the results reported for the 50% and 100% threshold of the component detection. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999765157699585}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999903440475464}, "created": {"value": false, "score": 0.3388504981994629}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argument", "normalizedForm": "Argument", "offsetStart": 270, "offsetEnd": 278}, "context": "We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of .87 for component detection and .68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of .80 for outcome classification.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6730459928512573}, "created": {"value": false, "score": 0.0003763437271118164}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999884366989136}, "created": {"value": true, "score": 0.9996975660324097}, "shared": {"value": false, "score": 1.6689300537109375e-06}}}], "references": [{"refKey": 38, "tei": "<biblStruct xml:id=\"b38\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">BERT: Pre-training of deep bidirectional transformers for language understanding</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Devlin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ming-Wei</forename><surname>Chang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kristina</forename><surname>Toutanova</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of NAACL-HLT 2019</title>\n\t\t<meeting>NAACL-HLT 2019</meeting>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t\t<biblScope unit=\"page\">4186</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 17480, "id": "31d5c51011a4687cf1be3ead3b849d71fe3e2806", "metadata": {"id": "31d5c51011a4687cf1be3ead3b849d71fe3e2806"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03264761.grobid.tei.xml", "file_name": "hal-03264761.grobid.tei.xml"}