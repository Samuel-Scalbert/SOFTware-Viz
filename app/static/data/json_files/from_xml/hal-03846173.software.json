{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:47+0000", "md5": "D2165FEB0534350E3F8E1B8D80237DEB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "LibROSA", "normalizedForm": "LibROSA", "offsetStart": 0, "offsetEnd": 8}, "context": "LibROSA8 Python library was used for CQT and MFSC while PyWavelets9 was employed for CWT feature extraction in this work. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992610812187195}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 0.3061453104019165}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "library", "normalizedForm": "library", "offsetStart": 16, "offsetEnd": 23}, "language": {"rawForm": "Python", "normalizedForm": "Python", "wikidataId": "Q28865", "offsetStart": 97, "offsetEnd": 103}, "context": "LibROSA8 Python library was used for CQT and MFSC while PyWavelets9 was employed for CWT feature extraction in this work. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992610812187195}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9992610812187195}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyWavelets", "normalizedForm": "PyWavelets", "offsetStart": 19, "offsetEnd": 29}, "context": "https://github.com/PyWavelets/pywt", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016260147094726562}, "created": {"value": false, "score": 4.1484832763671875e-05}, "shared": {"value": true, "score": 0.9807175993919373}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 4.1484832763671875e-05}, "shared": {"value": true, "score": 0.9807175993919373}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyWavelets", "normalizedForm": "PyWavelets", "offsetStart": 56, "offsetEnd": 67}, "context": "LibROSA8 Python library was used for CQT and MFSC while PyWavelets9 was employed for CWT feature extraction in this work. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992610812187195}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 4.1484832763671875e-05}, "shared": {"value": true, "score": 0.9807175993919373}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibROSA", "normalizedForm": "LibROSA", "offsetStart": 67, "offsetEnd": 75}, "context": "In our experiments, we used the CQT implementation provided in the LibROSA2 toolbox which uses the above mentioned computational improvements. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9685807824134827}, "created": {"value": false, "score": 0.3061453104019165}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 0.3061453104019165}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechBrain", "normalizedForm": "SpeechBrain", "offsetStart": 67, "offsetEnd": 79}, "context": "In this work, we used the implementation of ECAPA-TDNN provided in SpeechBrain4 Python toolkit without any change in parameter configuration.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9693270921707153}, "created": {"value": true, "score": 0.9317538738250732}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9693270921707153}, "created": {"value": true, "score": 0.9317538738250732}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "offsetStart": 103, "offsetEnd": 108}, "context": "We calculated FLOPs during feature extraction using only one CPU core (Intel Xeon E5-2670 2.6 GHz) and Linux perf10 command. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999909400939941}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999909400939941}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Anger", "normalizedForm": "Anger", "offsetStart": 112, "offsetEnd": 117}, "context": "The improvement with constant-Q features is more than that for MFSC, especially on high-arousal emotions (Fear, Anger, Happy) because of the higher pitch resolution in the former.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007710754871368408}, "created": {"value": false, "score": 0.00014412403106689453}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5137006044387817}, "created": {"value": false, "score": 0.00014412403106689453}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Anger", "normalizedForm": "Anger", "offsetStart": 113, "offsetEnd": 118}, "context": "eNTERFACE is also an audio-visual database containing recording of six different emotions: Happy, Sad, Surprise, Anger and Fear, recorded from 44 different subjects [73].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010781288146972656}, "created": {"value": false, "score": 2.9325485229492188e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5137006044387817}, "created": {"value": false, "score": 0.00014412403106689453}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 127, "offsetEnd": 135}, "context": "For the above mentioned deep networks, we used Keras5 deep learning library for Conv2D, TDNN, and Conv2D-LSTM architecture and PyTorch6 deep learning library for the remaining selected state-of-the-art architectures.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985040426254272}, "created": {"value": false, "score": 0.0003846883773803711}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985040426254272}, "created": {"value": false, "score": 0.0003846883773803711}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Anger", "normalizedForm": "Anger", "offsetStart": 161, "offsetEnd": 166}, "context": "ing and windowing, the emotions less sensitive to high-frequency content and benefited from high-frequency averaging are emphasized by CWT. Figure 14 shows that Anger, which is known to have greater high frequency relevance [34,35], gains slightly from time-invariance (or averaging) applied at high frequency. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5137006044387817}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5137006044387817}, "created": {"value": false, "score": 0.00014412403106689453}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 181, "offsetEnd": 187}, "context": "To increase the size of available training data, we employed five-fold data augmentation using additive and re- verberation noises following x-vector extraction recipe [69] used in Kaldi7 toolkit. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996658563613892}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996658563613892}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibROSA", "normalizedForm": "LibROSA", "offsetStart": 181, "offsetEnd": 188}, "context": "The 3 in 2 k 3 corresponds to the voices per octave with number of octaves again fixed to 8. We chose default values for the remaining input parameters of CQT and MFSC functions in LibROSA and CWT in PyWavelets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 0.3061453104019165}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyWavelets", "normalizedForm": "PyWavelets", "offsetStart": 200, "offsetEnd": 210}, "context": "The 3 in 2 k 3 corresponds to the voices per octave with number of octaves again fixed to 8. We chose default values for the remaining input parameters of CQT and MFSC functions in LibROSA and CWT in PyWavelets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 4.5299530029296875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996312856674194}, "created": {"value": false, "score": 4.1484832763671875e-05}, "shared": {"value": true, "score": 0.9807175993919373}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Anger", "normalizedForm": "Anger", "offsetStart": 207, "offsetEnd": 212}, "context": "Authors in [23] reported that Neutral has better recognition rate around the first formant frequency F1 (200-1000 Hz) while around the second formant frequency F2 (1250-1270 Hz), the recognition accuracy of Anger is higher.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10485565662384033}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5137006044387817}, "created": {"value": false, "score": 0.00014412403106689453}, "shared": {"value": false, "score": 2.384185791015625e-07}}}], "references": [], "runtime": 13674, "id": "e98bd1c009f5738f821e3a3104e71cc52c2a7077", "metadata": {"id": "e98bd1c009f5738f821e3a3104e71cc52c2a7077"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03846173.grobid.tei.xml", "file_name": "hal-03846173.grobid.tei.xml"}