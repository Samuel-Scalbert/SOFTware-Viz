{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:37+0000", "md5": "C0BB7AB76D0CE5102F9C81245EC9C1DE", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 0, "offsetEnd": 4}, "context": "GAFF learns the intra-and inter-modality attention masks to adaptively enhance important areas and to identify reliable modalities, respectively. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004495978355407715}, "created": {"value": false, "score": 3.325939178466797e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 0, "offsetEnd": 4}, "context": "GAFF significantly improves the scene analysis performance in a two-stream teacher model.", "mentionContextAttributes": {"used": {"value": false, "score": 6.318092346191406e-05}, "created": {"value": false, "score": 4.2438507080078125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 23, "offsetEnd": 27}, "context": "Specifically, we adopt GAFF [27] as the feature-level fusion method.", "mentionContextAttributes": {"used": {"value": false, "score": 8.90493392944336e-05}, "created": {"value": true, "score": 0.7797316908836365}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27, "offsetStart": 20845, "offsetEnd": 20849}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 30, "offsetEnd": 37}, "version": {"rawForm": "1.20", "normalizedForm": "1.20", "offsetStart": 38, "offsetEnd": 42}, "context": "The whole project is coded in PyTorch 1.20. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.21952760219573975}, "created": {"value": false, "score": 0.0011814236640930176}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.21952760219573975}, "created": {"value": false, "score": 0.0011814236640930176}, "shared": {"value": false, "score": 1.5497207641601562e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 36, "offsetEnd": 40}, "context": "As illustrated in Fig. 1(A works, a GAFF [27] module for multispectral fusion and a task-specific network for pedestrian detection/semantic segmentation.", "mentionContextAttributes": {"used": {"value": false, "score": 3.063678741455078e-05}, "created": {"value": false, "score": 0.01314312219619751}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27, "offsetStart": 11348, "offsetEnd": 11352}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 43, "offsetEnd": 47}, "context": "We carefully follow the implementations of GAFF module from [27] for multispectral feature fusion in the teacher model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004640817642211914}, "created": {"value": false, "score": 0.03375738859176636}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 47, "offsetEnd": 51}, "context": "For the teacher model (Fig. 1(A) upper model), GAFF [27] is adopted for the attentive fusion of visible and thermal features.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005709528923034668}, "created": {"value": false, "score": 2.181529998779297e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27, "offsetStart": 19019, "offsetEnd": 19023}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 80, "offsetEnd": 84}, "context": "m intra and m inter are predicted intra-and inter-modality attention masks from GAFF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": false, "score": 1.9431114196777344e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 89, "offsetEnd": 93}, "context": "The former generates teacher attention maps (masks) via Guided Attentive Feature Fusion (GAFF) [27] from a two-stream teacher network.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018333196640014648}, "created": {"value": false, "score": 2.1576881408691406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27, "offsetStart": 10354, "offsetEnd": 10358}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GAFF", "normalizedForm": "GAFF", "offsetStart": 102, "offsetEnd": 106}, "context": "In the first stage, we train the teacher model and fix its weights, such that the fused features from GAFF module contain the rich semantics of high-resolution thermalvisible image pairs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021737217903137207}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.865479052066803}, "created": {"value": true, "score": 0.9353536367416382}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[27]", "normalizedForm": "[27]", "refKey": 27}]}], "references": [{"refKey": 27, "tei": "<biblStruct xml:id=\"b27\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Guided Attentive Feature Fusion for Multispectral Pedestrian Detection</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Heng</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Elisa</forename><surname>Fromont</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sebastien</forename><surname>Lefevre</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bruno</forename><surname>Avignon</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/wacv48630.2021.00012</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2021 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2021-01\">2021</date>\n\t\t\t<biblScope unit=\"page\">80</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 7641, "id": "51fd960313af5bdb1b43cbb04bee2b61098b4db8", "metadata": {"id": "51fd960313af5bdb1b43cbb04bee2b61098b4db8"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03491950.grobid.tei.xml", "file_name": "hal-03491950.grobid.tei.xml"}