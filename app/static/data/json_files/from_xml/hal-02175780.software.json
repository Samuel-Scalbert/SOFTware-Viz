{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:07+0000", "md5": "04D9F50C23DACB136035E115CD257286", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshape", "normalizedForm": "Blendshape", "offsetStart": 0, "offsetEnd": 10}, "context": "Blendshape decomposition is a animation technique allowing a mesh to deform from a base shape to numerous pre-defined shape (keyshapes) through linear morphing.", "mentionContextAttributes": {"used": {"value": false, "score": 6.961822509765625e-05}, "created": {"value": false, "score": 0.0001748204231262207}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 0, "offsetEnd": 11}, "context": "Autoencoder seems not to be as efficient as PCA and Blendshape's decomposition to speed up the training, but this difference may be explained by the depth of the architecture.", "mentionContextAttributes": {"used": {"value": false, "score": 7.426738739013672e-05}, "created": {"value": false, "score": 4.601478576660156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Adam", "normalizedForm": "Adam", "offsetStart": 8, "offsetEnd": 17}, "context": "We used Adam [36] and its recommended parameters to finally update the network's parameters. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999597072601318}, "created": {"value": false, "score": 2.7418136596679688e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999597072601318}, "created": {"value": false, "score": 2.7418136596679688e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshape", "normalizedForm": "Blendshape", "offsetStart": 52, "offsetEnd": 62}, "context": "Autoencoder seems not to be as efficient as PCA and Blendshape's decomposition to speed up the training, but this difference may be explained by the depth of the architecture.", "mentionContextAttributes": {"used": {"value": false, "score": 7.426738739013672e-05}, "created": {"value": false, "score": 4.601478576660156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshapes", "normalizedForm": "Blendshapes", "offsetStart": 71, "offsetEnd": 82}, "context": "A first insight that this figure provides is similar performances PCA, Blendshapes and Autoencoder architectures get when randomly initialized, they actually are all stuck into the plateau presented in section 4.3. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08089768886566162}, "created": {"value": false, "score": 6.330013275146484e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.08089768886566162}, "created": {"value": false, "score": 6.330013275146484e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshape", "normalizedForm": "Blendshape", "offsetStart": 82, "offsetEnd": 92}, "context": "Baseline has been trained for 150 epoches, architectures initialized with PCA and Blendshape 50 epoches, and architectures initialized with Autoencoder 100 epoches.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022463202476501465}, "created": {"value": false, "score": 0.0005884170532226562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 87, "offsetEnd": 98}, "context": "A first insight that this figure provides is similar performances PCA, Blendshapes and Autoencoder architectures get when randomly initialized, they actually are all stuck into the plateau presented in section 4.3.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08089768886566162}, "created": {"value": false, "score": 6.330013275146484e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshape", "normalizedForm": "Blendshape", "offsetStart": 121, "offsetEnd": 131}, "context": "We have compared two data-driven methods, principal component analysis and autoencoders, and a handcrafted method, i.e., Blendshape's decomposition.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 140, "offsetEnd": 151}, "context": "Baseline has been trained for 150 epoches, architectures initialized with PCA and Blendshape 50 epoches, and architectures initialized with Autoencoder 100 epoches.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022463202476501465}, "created": {"value": false, "score": 0.0005884170532226562}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Blendshape", "normalizedForm": "Blendshape", "offsetStart": 142, "offsetEnd": 152}, "context": "The number of epochs needed to reach the best validation loss is divided by about seven (about 70 epoches for the baseline, about 10 for PCA, Blendshape and Autoencoder), there is up to a 35% relative RMSE improvements with the same training time between networks using our initialization and the same architecture with random initialization.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9938098788261414}, "created": {"value": false, "score": 0.013620316982269287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 157, "offsetEnd": 168}, "context": "The number of epochs needed to reach the best validation loss is divided by about seven (about 70 epoches for the baseline, about 10 for PCA, Blendshape and Autoencoder), there is up to a 35% relative RMSE improvements with the same training time between networks using our initialization and the same architecture with random initialization.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 158, "offsetEnd": 169}, "context": "We suspect that these randomly initialized architectures could perform as well as the baseline with a longer training time, as this seems to be the case with Autoencoder.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004453539848327637}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Autoencoder", "normalizedForm": "Autoencoder", "offsetStart": 167, "offsetEnd": 178}, "context": "Surprisingly, performances using hand-crafted latent space (blendshape) are really close to performances using latent space computed with data-driven methods (PCA and Autoencoder).", "mentionContextAttributes": {"used": {"value": false, "score": 0.007115185260772705}, "created": {"value": false, "score": 5.328655242919922e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.6079137325286865}, "created": {"value": false, "score": 0.0016258955001831055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MOCHA-TIMIT", "normalizedForm": "MOCHA-TIMIT", "offsetStart": 218, "offsetEnd": 233}, "context": "Even though one hour of speech was sufficient to learn articulatory coarticulation, the number of output point is far greater for our visual corpora (6 or 7 2D points for classic articulatory corpus like MNGU0 [18] or MOCHA-TIMIT [19], versus 44 3D points for our in-house corpus). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976913928985596}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9976913928985596}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [], "runtime": 7996, "id": "b274f8ae500da0fd48d00222a7f47d954db828d3", "metadata": {"id": "b274f8ae500da0fd48d00222a7f47d954db828d3"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02175780.grobid.tei.xml", "file_name": "hal-02175780.grobid.tei.xml"}