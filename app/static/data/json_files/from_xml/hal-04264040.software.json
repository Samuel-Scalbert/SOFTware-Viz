{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:08+0000", "md5": "BC37C934F7980E83B99D62956F285798", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 0, "offsetEnd": 6}, "context": "HuBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.012256324291229248}, "created": {"value": false, "score": 0.0002225041389465332}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 0, "offsetEnd": 6}, "context": "HuBERT is used to extract speech features of audio frames, which are then grouped into k-means clusters. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9802820682525635}, "created": {"value": false, "score": 4.208087921142578e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "The HuBERT model quality is critical to speech-to-speech translation performance, as its extracted units are used by both speech-tounit model and vocoder.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016383528709411621}, "created": {"value": false, "score": 6.020069122314453e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "The HuBERT model consists of 7 convolutional layers and 12 Transformer encoder layers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025205016136169434}, "created": {"value": false, "score": 1.8358230590820312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 4, "offsetEnd": 13}, "context": "The VoxPopuli recordings have a rather long duration, e.g. one hour and a half on average for English.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007338285446166992}, "created": {"value": false, "score": 5.0067901611328125e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 4, "offsetEnd": 13}, "context": "For VoxPopuli, we extract a valid set of about 1000 samples by adding data from highly scored sessions which are not in the test set.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4666316509246826}, "created": {"value": false, "score": 0.00018841028213500977}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 4, "offsetEnd": 13}, "context": "(2) VoxPopuli (Wang et al., 2021a).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9434568881988525}, "created": {"value": false, "score": 1.8715858459472656e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0, "offsetStart": 19574, "offsetEnd": 19594}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 5, "offsetEnd": 14}, "context": "3(2) VoxPopuli (Wang et al., 2021a).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9914914965629578}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0, "offsetStart": 14929, "offsetEnd": 14949}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 8, "offsetEnd": 17}, "context": "We used VoxPopuli as our source of unlabeled unsegmented speech for 17 languages in focus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990676045417786}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 11, "offsetEnd": 23}, "context": "We present SpeechMatrix, a large-scale multilingual corpus of speech-to-speech translations (S2ST) mined from real speech of European Parliament recordings.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002550482749938965}, "created": {"value": true, "score": 0.9999103546142578}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 12, "offsetEnd": 18}, "context": "The optimal HuBERT layer and label size is selected if their corresponding vocoder achieves the lowest WER.", "mentionContextAttributes": {"used": {"value": false, "score": 0.30583280324935913}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 15, "offsetEnd": 24}, "context": "The release of VoxPopuli dataset provides the largest S2S translations in real speech so far (Wang et al., 2021a).", "mentionContextAttributes": {"used": {"value": false, "score": 0.001833498477935791}, "created": {"value": false, "score": 1.4662742614746094e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 18, "offsetEnd": 24}, "context": "We reuse the same HuBERT model and k-means clusters for English, Spanish and French as in (Lee et al., 2022b) for a fair comparison with existing results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9894472360610962}, "created": {"value": false, "score": 0.00010025501251220703}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 20, "offsetEnd": 32}, "context": "The mined resource, SpeechMatrix, will be released under CC0 license, and the trained speechto-speech translation models will be released under CC BY-NC 4.0.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005236804485321045}, "created": {"value": false, "score": 0.00023049116134643555}, "shared": {"value": true, "score": 0.7718017101287842}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 21, "offsetEnd": 27}, "context": "Layer 11 is the best HuBERT layer for feature extraction in all languages, and most languages have the best k-means size of 1000 except Italian (it) whose best label size is 800.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004631161689758301}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 21, "offsetEnd": 30}, "context": "S2S data, as part of VoxPopuli release, provides aligned source and target speech together with source transcriptions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0028707385063171387}, "created": {"value": false, "score": 5.733966827392578e-05}, "shared": {"value": false, "score": 5.424022674560547e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 21, "offsetEnd": 30}, "context": "We collect unlabeled VoxPopuli speech for all languages of the same family as the training data.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9342056512832642}, "created": {"value": false, "score": 0.006825745105743408}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 24, "offsetEnd": 30}, "context": "We train a multilingual HuBERT model for each family on the collection of speech in each component language as shown in Table 11.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023669004440307617}, "created": {"value": true, "score": 0.8707706928253174}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 25, "offsetEnd": 37}, "context": "In this work, we present SpeechMatrix, a largescale multilingual speech-to-speech corpus mined from VoxPopuli (Wang et al., 2021a).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010991096496582031}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 27, "offsetEnd": 33}, "context": "We also train multilingual HuBERT models to cover other languages in SpeechMatrix, and more HuBERT training details can be found in Appendix B.1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013494491577148438}, "created": {"value": false, "score": 0.21066313982009888}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 30, "offsetEnd": 42}, "context": "To the best of our knowledge, SpeechMatrix is by far the largest freely available speech-to-speech translation corpus, with 136 language directions and an average of 1,537 hours of source speech in each direction for a total of 418 thousand hours. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024896860122680664}, "created": {"value": false, "score": 0.002038121223449707}, "shared": {"value": false, "score": 1.728534698486328e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 34, "offsetEnd": 46}, "context": "Enabled by the multilinguality of SpeechMatrix, we also explore multilingual speech-to-speech translation, a topic which was addressed by few other works. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.404254913330078e-05}, "created": {"value": true, "score": 0.9771788120269775}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 36, "offsetEnd": 42}, "context": "Then we prepare vocoder labels with HuBERT models generating k-means cluster labels for each utterance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9679768085479736}, "created": {"value": false, "score": 0.015478193759918213}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 42, "offsetEnd": 48}, "context": "Other questions could be whether a larger HuBERT with more model capacity should be used and how we should deal with language imbalance in multilingual training.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004932284355163574}, "created": {"value": false, "score": 0.004723548889160156}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 43, "offsetEnd": 52}, "context": "Compared with 480-hour labeled speech from VoxPopuli, SpeechMatrix achieves an an average improvement of 5.4 BLEU, indicating the good quality and usefulness of the mined data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005353152751922607}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 43, "offsetEnd": 52}, "context": "The train sets are speech data from CSS10, VoxPopuli and Common Voice.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9939777851104736}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 44, "offsetEnd": 50}, "context": "As mentioned before, units are derived from HuBERT models for these speech.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971285462379456}, "created": {"value": false, "score": 0.0028284192085266113}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 47, "offsetEnd": 56}, "context": "Valid sets are prepared for S2S modeling using VoxPopuli and FLEURS data in a similar way as test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8922780752182007}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 49, "offsetEnd": 58}, "context": "Table 2: Similarity search error rates (in %) on VoxPopuli ASR test set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999808073043823}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 54, "offsetEnd": 66}, "context": "Compared with 480-hour labeled speech from VoxPopuli, SpeechMatrix achieves an an average improvement of 5.4 BLEU, indicating the good quality and usefulness of the mined data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005353152751922607}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 56, "offsetEnd": 65}, "context": "In order to keep as much mined data as possible, we use VoxPopuli test set only when a language direction is not covered by EPST considering their domain similarity.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9832540154457092}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 57, "offsetEnd": 66}, "context": "To choose high-quality data, we sort all sessions in the VoxPopuli S2S data in a decreasing order of the average similarity score of their samples.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976050853729248}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 58, "offsetEnd": 64}, "context": "We have not explored the optimal strategy of multilingual HuBERT training.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009329915046691895}, "created": {"value": true, "score": 0.9577603340148926}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 62, "offsetEnd": 71}, "context": "To ensure that there is no overlap between the mined data and VoxPopuli test sets, we need to remove speech from mined alignments which are from the same session as test samples.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2833314538002014}, "created": {"value": false, "score": 0.0002487301826477051}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 65, "offsetEnd": 74}, "context": "We applied a denoiser4  (Defossez et al., 2020) to the speech of VoxPopuli and Common Voice as the speech preprocessing to increase signal-to-noise ratio (SNR) given that they are noisier than CSS10 audios.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999576807022095}, "created": {"value": false, "score": 0.006368100643157959}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 65, "offsetEnd": 74}, "context": "Single-speaker vocoders are trained in CSS10, and languages from VoxPopuli and Common Voice have multi-speaker vocoders where speaker embeddings are learned.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005355954170227051}, "created": {"value": false, "score": 0.00010704994201660156}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 66, "offsetEnd": 78}, "context": "Table 4 shows the results of S2ST models which are trained on our SpeechMatrix mined data compared to VoxPopuli S2S data in each of four language directions: es-en, fr-en, en-es and enfr.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999014139175415}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 67, "offsetEnd": 76}, "context": "We evaluated similarity search of audios against transcriptions on VoxPopuli ASR test set in Table 2, which is our target domain as we plan to mine unlabeled speech from VoxPopuli (see subsection 3.3).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": false, "score": 3.981590270996094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 68, "offsetEnd": 77}, "context": "Moreover, similarity scores are provided to indicate the quality of VoxPopuli samples.", "mentionContextAttributes": {"used": {"value": false, "score": 0.044872820377349854}, "created": {"value": false, "score": 1.7523765563964844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 69, "offsetEnd": 78}, "context": "Supporting 102 languages, FLEURS has a larger language coverage than VoxPopuli, but it only contains around 12 hours of speech per language and it is intended to be used asN -way parallel test data.", "mentionContextAttributes": {"used": {"value": false, "score": 9.369850158691406e-05}, "created": {"value": false, "score": 3.1948089599609375e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 69, "offsetEnd": 81}, "context": "To evaluate the quality of the mined data, we trained S2ST models on SpeechMatrix data and report the translation performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": false, "score": 0.0041814446449279785}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 69, "offsetEnd": 81}, "context": "We also train multilingual HuBERT models to cover other languages in SpeechMatrix, and more HuBERT training details can be found in Appendix B.1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013494491577148438}, "created": {"value": false, "score": 0.21066313982009888}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 74, "offsetEnd": 83}, "context": "FLEURS texts are from English Wikipedia, which is a different domain from VoxPopuli and EPST.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9424428939819336}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 0.006145954132080078}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 78, "offsetEnd": 84}, "context": "To choose the optimal setup, we launch a resynthesis evaluation to select the HuBERT layer to extract speech features and the number of k-means clusters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8267657160758972}, "created": {"value": true, "score": 0.995337724685669}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 83, "offsetEnd": 89}, "context": "We are open-sourcing the mined data, speech encoders used for mining, multilingual HuBERT models in four language families for target unit generation, languagespecific vocoders for speech synthesis from discrete units, and S2S models trained and presented in this work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005599856376647949}, "created": {"value": true, "score": 0.9986875653266907}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 83, "offsetEnd": 89}, "context": "One research question is how to choose a group of languages so that a multilingual HuBERT model could be well trained.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015158414840698242}, "created": {"value": false, "score": 0.00215756893157959}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 87, "offsetEnd": 93}, "context": "Moreover, for reproducibility, we will release model components including multilingual HuBERT models in four language families for target unit generation, language-specific vocoders for speech synthesis from discrete units, and S2S models trained and presented in this work.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019425153732299805}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 87, "offsetEnd": 93}, "context": "In the second iteration, we extract speech features from the 6-th layer of the trained HuBERT model and apply k-means clustering to derive a set of 500 labels.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0468212366104126}, "created": {"value": false, "score": 0.0017769932746887207}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 90, "offsetEnd": 99}, "context": "In this paper, we introduce a large-scale multilingual speech-to-speech corpus mined from VoxPopuli.", "mentionContextAttributes": {"used": {"value": false, "score": 8.666515350341797e-05}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 92, "offsetEnd": 98}, "context": "We also train multilingual HuBERT models to cover other languages in SpeechMatrix, and more HuBERT training details can be found in Appendix B.1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013494491577148438}, "created": {"value": false, "score": 0.21066313982009888}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 94, "offsetEnd": 100}, "context": "For a given direction, we extract units for source and target speech with their corresponding HuBERT models (Hsu et al., 2021).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9822011590003967}, "created": {"value": false, "score": 0.021737217903137207}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Hsu et al., 2021)", "normalizedForm": "Hsu et al., 2021", "refKey": 17, "offsetStart": 20500, "offsetEnd": 20518}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 96, "offsetEnd": 108}, "context": "In this part, we discuss the bilingual S2S models trained in each of 272 language directions in SpeechMatrix.", "mentionContextAttributes": {"used": {"value": false, "score": 0.47299039363861084}, "created": {"value": true, "score": 0.6747273206710815}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 100, "offsetEnd": 109}, "context": "In this work, we present SpeechMatrix, a largescale multilingual speech-to-speech corpus mined from VoxPopuli (Wang et al., 2021a).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010991096496582031}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0, "offsetStart": 7064, "offsetEnd": 7084}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 102, "offsetEnd": 111}, "context": "Table 4 shows the results of S2ST models which are trained on our SpeechMatrix mined data compared to VoxPopuli S2S data in each of four language directions: es-en, fr-en, en-es and enfr.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999014139175415}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 111, "offsetEnd": 123}, "context": "We move forward to a larger-scale multilinguality by extending from Slavic language family to all languages in SpeechMatrix.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023025274276733398}, "created": {"value": true, "score": 0.9879249334335327}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 121, "offsetEnd": 130}, "context": "Another observation is the performance difference across test domains, and BLEU on FLEURS is lower than that on EPST and VoxPopuli data, likely because of the domain mismatch between train and test data.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5985177159309387}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 126, "offsetEnd": 132}, "context": "We borrow the idea of training speech-to-unit (S2U) model where units are pre-generated from target speech with a pre-trained HuBERT model (Lee et al., 2022a).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009346604347229004}, "created": {"value": false, "score": 0.4468708634376526}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0, "offsetStart": 17496, "offsetEnd": 17515}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 126, "offsetEnd": 132}, "context": "Lastly after these three iterations, we try feature extraction from different layers including layer 10, 11 and 12 of trained HuBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.42657536268234253}, "created": {"value": false, "score": 0.00023001432418823242}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 130, "offsetEnd": 154}, "context": "It is also shown useful to leverage knowledge transferred from pre-trained models (Lee et al., 2022b;Popuri et al., 2022) such as HuBERT (Hsu et al., 2021), wav2vec 2.0 (Baevski et al., 2020) and mBART (Liu et al., 2020).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004851818084716797}, "created": {"value": false, "score": 0.00010502338409423828}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 134, "offsetEnd": 143}, "context": "In this work, we trained speech encoders for 17 languages2 and mined speech-to-speech alignments for all possible language pairs from VoxPopuli (Wang et al., 2021a), a collection of European Parliament recordings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7180802226066589}, "created": {"value": true, "score": 0.9997296929359436}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0, "offsetStart": 2941, "offsetEnd": 2961}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 136, "offsetEnd": 148}, "context": "As a technology used for speech generation, the presented speech translation models or the translation models that will be trained with SpeechMatrix dataset might have systemic bias or produce inappropriate outputs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007829666137695312}, "created": {"value": false, "score": 0.0006535649299621582}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 153, "offsetEnd": 159}, "context": "Besides, we report the training data, vocoder WER of synthesized speech from vocoders, and here we include the vocoder results obtained from the optimal HuBERT layer and k-means cluster size.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": false, "score": 2.753734588623047e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998276233673096}, "created": {"value": true, "score": 0.9996702671051025}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Lee et al., 2022a)", "normalizedForm": "Lee et al., 2022a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 158, "offsetEnd": 167}, "context": "Table 8: BLEU of All-to-English multilingual models across FLEURS (FL) and EP/VP domains (for EP/VP column, underlined scores are on EPST data, and others on VoxPopuli data).", "mentionContextAttributes": {"used": {"value": false, "score": 0.32617348432540894}, "created": {"value": false, "score": 6.568431854248047e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 170, "offsetEnd": 179}, "context": "We evaluated similarity search of audios against transcriptions on VoxPopuli ASR test set in Table 2, which is our target domain as we plan to mine unlabeled speech from VoxPopuli (see subsection 3.3). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": false, "score": 3.981590270996094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SpeechMatrix", "normalizedForm": "SpeechMatrix", "offsetStart": 178, "offsetEnd": 190}, "context": "In this work, we focus on many-to-English translation, studying the translation from 6 Slavic languages to English in subsection 6.1 and the translation from all 16 languages in SpeechMatrix to English in subsection 6.2.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016927719116210938}, "created": {"value": true, "score": 0.9991605281829834}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999987006187439}, "created": {"value": true, "score": 0.9999109506607056}, "shared": {"value": true, "score": 0.7718017101287842}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 180, "offsetEnd": 189}, "context": "To evaluate the quality of this parallel speech, we train bilingual speech-to-speech translation models on mined data only and establish extensive baseline results on Europarl-ST, VoxPopuli and FLEURS test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.992371678352356}, "created": {"value": false, "score": 0.11809039115905762}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxPopuli", "normalizedForm": "VoxPopuli", "offsetStart": 300, "offsetEnd": 309}, "context": "We used various publicly available ASR data sets which cover our languages to train the speech encoders, including CoVoST 2 (Wang et al., 2020(Wang et al., , 2021b)), Common Voice (Ardila et al., 2020), Europarl (Ardila et al., 2020), mTedx (Salesky et al., 2021), Must-C (Di Gangi et al., 2019) and VoxPopuli (Wang et al., 2021a), as well as speech translation data from the foreign languages into English and from English into German.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998417854309082}, "created": {"value": false, "score": 1.8596649169921875e-05}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999862909317017}, "created": {"value": true, "score": 0.9999326467514038}, "shared": {"value": false, "score": 0.006145954132080078}}, "references": [{"label": "(Wang et al., 2021a)", "normalizedForm": "Wang et al., 2021a", "refKey": 0, "offsetStart": 8639, "offsetEnd": 8659}]}], "references": [{"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Paul-Ambroise</forename><surname>Duquenne</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hongyu</forename><surname>Gong</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ning</forename><surname>Dong</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jingfei</forename><surname>Du</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ann</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vedanuj</forename><surname>Goswami</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Changhan</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Juan</forename><surname>Pino</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Holger</forename><surname>Schwenk</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2023.acl-long.899</idno>\n\t\t<idno>9A2BD8BD9079FF60171E2C0E1A0E2178</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>\n\t\t<meeting>the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2023\" />\n\t\t\t<biblScope unit=\"page\" from=\"16251\" to=\"16269\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 17, "tei": "<biblStruct xml:id=\"b17\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wei-Ning</forename><surname>Hsu</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5546-5217</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Bolte</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yao-Hung Hubert</forename><surname>Tsai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kushal</forename><surname>Lakhotia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ruslan</forename><surname>Salakhutdinov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abdelrahman</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/taslp.2021.3122291</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>\n\t\t<title level=\"j\" type=\"abbrev\">IEEE/ACM Trans. Audio Speech Lang. Process.</title>\n\t\t<idno type=\"ISSN\">2329-9290</idno>\n\t\t<idno type=\"ISSNe\">2329-9304</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">29</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"3451\" to=\"3460\" />\n\t\t\t<date type=\"published\" when=\"2021\">2021</date>\n\t\t\t<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 12200, "id": "eaf0ed566f97bee0d3027f749b31733430c6fad0", "metadata": {"id": "eaf0ed566f97bee0d3027f749b31733430c6fad0"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04264040.grobid.tei.xml", "file_name": "hal-04264040.grobid.tei.xml"}