{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:50+0000", "md5": "F80817627D2D823688BCF3D453A7AAB0", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 0, "offsetEnd": 16}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Stable Diffusion v2.1 model card: https://huggingface.co/stabilityai/stable-diffusion-2-1", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002148747444152832}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": true, "score": 0.9624240398406982}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 16, "offsetEnd": 32}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Moreover, since Stable Diffusion has a limitation on the number of tokens allowed in the prompt sentence(s), we embed the prompt by utilising the encoder and tokenizer from Stable Diffusion, courtesy of the Compel library 8 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.6866087317466736}, "created": {"value": false, "score": 5.352497100830078e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 17, "offsetEnd": 33}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Our usage of the Stable Diffusion generative model means that our method is inheriting its biases as well.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00048470497131347656}, "created": {"value": false, "score": 0.010232865810394287}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 50, "offsetEnd": 66}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Possible future work includes finetuning the last Stable Diffusion model via a Lora adaptation [35], trying other text-to-image models that rely on different architectures, and modifying prompts to include the most significant triples by investigating which properties affect image quality the most.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001310110092163086}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 51, "offsetEnd": 67}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "We then generate images based on each prompt using Stable Diffusion, a generative text-to-image model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9942499399185181}, "created": {"value": false, "score": 0.006436586380004883}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 58, "offsetEnd": 74}, "version": {"rawForm": "2.1", "normalizedForm": "2.1", "offsetStart": 83, "offsetEnd": 88}, "context": "To ensure reproducibility in image generation, we utilise Stable Diffusion version 2.1 6 , an open-source text-to-image model developed by Stability AI limited to the English language. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5808947682380676}, "created": {"value": false, "score": 0.023998498916625977}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 64, "offsetEnd": 80}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "\u2022 A framework that generates prompts for a text-to-image model (Stable Diffusion v2.1 3 ) with different levels of structure and natural language text based on Wikidata triples.", "mentionContextAttributes": {"used": {"value": false, "score": 2.6345252990722656e-05}, "created": {"value": false, "score": 0.06246262788772583}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 95, "offsetEnd": 111}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "We use those natural text descriptions as prompts for a transformer-based text-to-image model, Stable Diffusion v2.1, to generate plausible candidate images for Wikidata image completion.", "mentionContextAttributes": {"used": {"value": false, "score": 0.14108294248580933}, "created": {"value": false, "score": 0.008226454257965088}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AlignDRAW", "normalizedForm": "AlignDRAW", "offsetStart": 107, "offsetEnd": 120}, "context": "A recent survey [8] shows that text-to-image applications specifically have been emerging since 2015, when AlignDRAW [9] pioneered the field by leveraging recurrent neural networks (RNNs) to encode textual captions and produce corresponding images. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004139542579650879}, "created": {"value": false, "score": 0.005525648593902588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004139542579650879}, "created": {"value": false, "score": 0.005525648593902588}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 107, "offsetEnd": 123}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Subsequently, these triples are used to form various types of prompts in English, functioning as inputs to Stable Diffusion [21], a text-to-image AI model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010235309600830078}, "created": {"value": false, "score": 9.560585021972656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[21]", "normalizedForm": "[21]", "refKey": 21, "offsetStart": 7311, "offsetEnd": 7315}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 113, "offsetEnd": 129}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "First, we are currently dealing only with English data due to the limitations of the verbalisation model and the Stable Diffusion model we used.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.05845612287521362}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 148, "offsetEnd": 164}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "This is done by (1) extracting triples from Wikidata entities, (2) creating English prompts to be fed into a generative text-to-image model such as Stable Diffusion [3], and (3) generating a representative image of the character that could potentially be used on Wikidata.", "mentionContextAttributes": {"used": {"value": false, "score": 0.21298092603683472}, "created": {"value": false, "score": 5.221366882324219e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3, "offsetStart": 3424, "offsetEnd": 3427}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 173, "offsetEnd": 189}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Moreover, since Stable Diffusion has a limitation on the number of tokens allowed in the prompt sentence(s), we embed the prompt by utilising the encoder and tokenizer from Stable Diffusion, courtesy of the Compel library 8 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.6866087317466736}, "created": {"value": false, "score": 5.352497100830078e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stable Diffusion", "normalizedForm": "Stable Diffusion", "offsetStart": 173, "offsetEnd": 189}, "version": {"rawForm": "2.1", "normalizedForm": "2.1"}, "context": "Although a majority of these fictional characters lack information in DBpedia because it is constructed using English Wikipedia, this is not a problem in our case since the Stable Diffusion model can only use English text as input.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04979538917541504}, "created": {"value": false, "score": 5.6862831115722656e-05}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9948278069496155}, "created": {"value": false, "score": 0.17259860038757324}, "shared": {"value": true, "score": 0.9624240398406982}}, "references": [{"label": "[3]", "normalizedForm": "[3]", "refKey": 3}]}], "references": [{"refKey": 3, "tei": "<biblStruct xml:id=\"b3\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">High-Resolution Image Synthesis with Latent Diffusion Models</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Robin</forename><surname>Rombach</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Andreas</forename><surname>Blattmann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dominik</forename><surname>Lorenz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Patrick</forename><surname>Esser</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bjorn</forename><surname>Ommer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/cvpr52688.2022.01042</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2022-06\">2022</date>\n\t\t\t<biblScope unit=\"page\">10695</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 21, "tei": "<biblStruct xml:id=\"b21\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">High-Resolution Image Synthesis with Latent Diffusion Models</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Robin</forename><surname>Rombach</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Andreas</forename><surname>Blattmann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dominik</forename><surname>Lorenz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Patrick</forename><surname>Esser</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bjorn</forename><surname>Ommer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/cvpr52688.2022.01042</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2022-06\">2022</date>\n\t\t\t<biblScope unit=\"page\">10695</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10089, "id": "28ffe128d8117a41ac2bd37470024686e86b1248", "metadata": {"id": "28ffe128d8117a41ac2bd37470024686e86b1248"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04262826.grobid.tei.xml", "file_name": "hal-04262826.grobid.tei.xml"}