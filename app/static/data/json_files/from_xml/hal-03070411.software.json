{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:41+0000", "md5": "5179C210F6102D67E9E6E553B7AE9190", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 4, "offsetEnd": 15}, "context": "For LibriSpeech, we construct two samples, one from the 100hclean subset and one from the 500h-other (LS80-clean, and LS80-other, resp.).", "mentionContextAttributes": {"used": {"value": false, "score": 0.39053696393966675}, "created": {"value": false, "score": 0.0010401010513305664}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LIbriSpeech", "normalizedForm": "LIbriSpeech", "offsetStart": 21, "offsetEnd": 32}, "context": "The WER resulting on LIbriSpeech dev and test is shown in Table 7. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9967898726463318}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9967898726463318}, "created": {"value": false, "score": 3.349781036376953e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 22, "offsetEnd": 33}, "context": "After filtering, both LibriSpeech-other and Libri-light are within 0.1% absolute of the performance of the clean dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8973238468170166}, "created": {"value": false, "score": 6.4373016357421875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 30, "offsetEnd": 41}, "context": "We construct 80h samples from LibriSpeech and Libri-light.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999962329864502}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 36, "offsetEnd": 47}, "context": "The \"clean\" and \"other\" sections of LibriSpeech were originally selected by using WER from a baseline system as a filter [36].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991449117660522}, "created": {"value": false, "score": 1.3113021850585938e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 37, "offsetEnd": 48}, "context": "LS80-other datasets are sampled from LibriSpeech-other500; LL80-e from Libri-light600, with similar speaker representation and VAD filtering. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989103078842163}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 53, "offsetEnd": 64}, "context": "We then used the perplexity of the models trained on LibriSpeech clean-100 to filter the LibriSpeech other-500 data down to 80hours; this was done on a file-by-file basis. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 8.702278137207031e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 62, "offsetEnd": 73}, "context": "Panayotov et al. [36] used the word error rate (WER) to split LibriSpeech in \"clean\" and \"other\" subsets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998537302017212}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 64, "offsetEnd": 75}, "context": "The LL80-e subset attempts to mimic the speaker distribution of LibriSpeech, equal amounts of speech per speaker, using a greedy sampling method (Algorithm 1). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04170352220535278}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 65, "offsetEnd": 76}, "context": "For each of the three tasks, we found out that data sampled from LibriSpeech-other have on average an higher perplexity score than those sampled from the clean subsets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": false, "score": 8.702278137207031e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "librispeech", "normalizedForm": "librispeech", "offsetStart": 85, "offsetEnd": 96}, "context": "As far the language model is concerned, we simply use the 4-gram model provided with librispeech. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8327094316482544}, "created": {"value": false, "score": 3.2901763916015625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8327094316482544}, "created": {"value": false, "score": 3.2901763916015625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 89, "offsetEnd": 100}, "context": "We then used the perplexity of the models trained on LibriSpeech clean-100 to filter the LibriSpeech other-500 data down to 80hours; this was done on a file-by-file basis.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999783039093018}, "created": {"value": false, "score": 8.702278137207031e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 95, "offsetEnd": 106}, "context": "To build the phone decoder, we simply plug a phone classifier on top of a CPC model trained on LibriSpeech clean-100. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8539485335350037}, "created": {"value": false, "score": 0.25974369049072266}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WavAugment", "normalizedForm": "WavAugment", "offsetStart": 108, "offsetEnd": 118}, "context": "Besides, in order to take full advantage of the labelled data, we perform some pitch augmentation using the WavAugment library as described in [40]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8400838971138}, "created": {"value": false, "score": 3.600120544433594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8400838971138}, "created": {"value": false, "score": 3.600120544433594e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 108, "offsetEnd": 119}, "context": "The unsupervised method using CPC however was less consistent, with a relative reduction of only 6% for the LibriSpeech dataset, and a decrement of (4.5%) for the Libri-light dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997902512550354}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wav2letter", "normalizedForm": "wav2letter", "offsetStart": 127, "offsetEnd": 137}, "context": "To do so we consider a rather simple setting: we simply plug our phonetic representations to the KenLM decoder provided by the wav2letter library [41]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.09072798490524292}, "created": {"value": false, "score": 0.0025897622108459473}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.09072798490524292}, "created": {"value": false, "score": 0.0025897622108459473}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[41]", "normalizedForm": "[41]", "refKey": 41, "offsetStart": 21034, "offsetEnd": 21038}]}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "scripts", "normalizedForm": "scripts", "offsetStart": 157, "offsetEnd": 164}, "context": "In the case of Libri-light, the files correspond not to entire chapters, but to automatically segmented files based on the VAD (less than 1min; segmentation scripts provided in the distribution). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.014508068561553955}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.014508068561553955}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 176, "offsetEnd": 187}, "context": "The two supervised techniques were the most successful, especially CTC which practically cancelled the detrimental effect of low quality speech with a relative gain of 11% for LibriSpeech (and only 2.5% in Libri-light) compared to no filtering. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989963173866272}, "created": {"value": false, "score": 2.8967857360839844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 186, "offsetEnd": 197}, "context": "We can also see that the LL80-e sample gives results intermediate between the clean and the other training set, which makes sense because Libri-light has actually been less curated than LibriSpeech, and may correspond to the base distribution from which the clean and other sets were originally sampled. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985995888710022}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": true, "score": 0.6268392205238342}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [{"refKey": 41, "tei": "<biblStruct xml:id=\"b41\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">wav2letter++: The fastest open-source speech recognition system</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Q</forename><forename type=\"middle\">X J C J K G S V L R C</forename><surname>Vineel Pratap</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Awni</forename><surname>Hannun</surname></persName>\n\t\t</author>\n\t\t<idno>abs/1812.07625</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">CoRR</title>\n\t\t<imprint>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10554, "id": "e3e09dc75f2dbfd4eaa60a93a14beb568a655ae3", "metadata": {"id": "e3e09dc75f2dbfd4eaa60a93a14beb568a655ae3"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03070411.grobid.tei.xml", "file_name": "hal-03070411.grobid.tei.xml"}