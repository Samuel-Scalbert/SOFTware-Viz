{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:05+0000", "md5": "B678C0CC8B8EC05E0EE7677946C5B166", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 8, "offsetEnd": 12}, "context": "BART+SO-STAC model correctly captures an arc of distance 13.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04540205001831055}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 23, "offsetEnd": 27}, "context": "The key statistics for STAC and DailyDialog can be found in Table 1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002977311611175537}, "created": {"value": false, "score": 8.344650268554688e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DailyDialog", "normalizedForm": "DailyDialog", "offsetStart": 23, "offsetEnd": 34}, "context": "We omit 5 documents in DailyDialog during training since the documents lengths exceed the token limit. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9713972806930542}, "created": {"value": false, "score": 0.00010144710540771484}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Li et al., 2017)", "normalizedForm": "Li et al., 2017", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 26, "offsetEnd": 30}, "context": "The experiments on corpus STAC took up to 1.2 hours for one language model, and we tested a dozen models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999755620956421}, "created": {"value": false, "score": 0.0002829432487487793}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 28, "offsetEnd": 32}, "context": "Experimental results on the STAC dataset reveal that our unsupervised and semi-supervised methods outperform the strong LAST baseline (F 1 56.8%,", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996287822723389}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialogLED", "normalizedForm": "DialogLED", "offsetStart": 29, "offsetEnd": 38}, "publisher": {"rawForm": "-alogLM", "normalizedForm": "-alogLM"}, "context": "Sentence ordering fine-tuned DialogLED model outperforms the original one, proving that our proposed SO task can help encoding the discourse information.", "mentionContextAttributes": {"used": {"value": false, "score": 7.963180541992188e-05}, "created": {"value": false, "score": 0.14971709251403809}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.14971709251403809}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DailyDialog", "normalizedForm": "DailyDialog", "offsetStart": 32, "offsetEnd": 43}, "context": "The key statistics for STAC and DailyDialog can be found in Table 1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002977311611175537}, "created": {"value": false, "score": 8.344650268554688e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Li et al., 2017)", "normalizedForm": "Li et al., 2017", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 41, "offsetEnd": 45}, "context": "Early approaches to discourse parsing on STAC used varied decoding strategies, such as Maximum Spanning Tree algorithm (Muller et al., 2012;Li et al., 2014;Afantenos et al., 2012) or Integer Linear Programming (Perret et al., 2016).", "mentionContextAttributes": {"used": {"value": false, "score": 0.05885666608810425}, "created": {"value": false, "score": 8.881092071533203e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Stanza Toolkit", "normalizedForm": "Stanza Toolkit", "offsetStart": 42, "offsetEnd": 73}, "context": "The treebanked data is obtained using the Stanza Toolkit (Qi et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984679818153381}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9984679818153381}, "created": {"value": false, "score": 2.7418136596679688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 43, "offsetEnd": 47}, "context": "The best model is still BART fine-tuned on STAC, followed by the inter-domain   fine-tuned +SO-DD and BART models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0033678412437438965}, "created": {"value": false, "score": 4.363059997558594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-aloGPT", "normalizedForm": "-aloGPT", "offsetStart": 43, "offsetEnd": 70}, "context": "We test with RoBERTa (Liu et al., 2019), Di-aloGPT (Zhang et al., 2020), and DialogLED (Di-alogLM with Longformer) (Zhong et al., 2022) to see how different language models encode discourse information. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.0019075274467468262}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.0019075274467468262}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 50, "offsetEnd": 54}, "context": "4), delivering substantial gains on the com-plete STAC dataset (F 1 59.3%, Sec.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": false, "score": 2.658367156982422e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 51, "offsetEnd": 55}, "context": "Results using our novel unsupervised DAS method on STAC are shown in In the last sub-table we show unsupervised scores from pre-trained and fine-tuned LMs on three auxiliary tasks: summarization, questionanswering and sentence ordering (SO) with the mixed shuffling strategy.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998649537563324}, "created": {"value": false, "score": 0.00023931264877319336}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 55, "offsetEnd": 59}, "context": "In comparison, the largest dialogue discourse dataset (STAC) only contains 10, 678 units.", "mentionContextAttributes": {"used": {"value": false, "score": 0.327045202255249}, "created": {"value": false, "score": 2.09808349609375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 57, "offsetEnd": 61}, "context": "Our proposals thereby achieve encouraging results on the STAC corpus, with F 1 scores of 57.2 and 59.3 for the unsupervised and semisupervised methods, respectively.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003992199897766113}, "created": {"value": false, "score": 0.02099466323852539}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Huggingface", "normalizedForm": "Huggingface", "offsetStart": 59, "offsetEnd": 70}, "context": "Table 13 shows the models and the sources we obtained from Huggingface library (Wolf et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995561242103577}, "created": {"value": false, "score": 0.00429987907409668}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995561242103577}, "created": {"value": false, "score": 0.00429987907409668}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Wolf et al., 2020)", "normalizedForm": "Wolf et al., 2020", "refKey": 56, "offsetStart": 35717, "offsetEnd": 35736}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 63, "offsetEnd": 67}, "context": "For indirect arcs (top in Figure 6), the best model is BART+SO-STAC (20% recall, 44% precision), closely followed by original BART (20% recall, 41% precision).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0780753493309021}, "created": {"value": false, "score": 1.9550323486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 65, "offsetEnd": 69}, "context": "For the novel sentence ordering task, we train BART model on the STAC corpus and the DailyDialog corpus (Li et al., 2017).", "mentionContextAttributes": {"used": {"value": false, "score": 0.16381502151489258}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 67, "offsetEnd": 71}, "context": "Figure 1 shows an example from the Strategic Conversations corpus (STAC) (Asher et al., 2016).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9392933249473572}, "created": {"value": false, "score": 1.1801719665527344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SAMSum", "normalizedForm": "SAMSum", "offsetStart": 67, "offsetEnd": 73}, "context": "Noticeably, models fine-tuned on the summarization task (\"+CNN\", \"+SAMSum\") and question-answering (\"+SQuAD2\") only add marginal improvements compared to BART. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00044971704483032227}, "created": {"value": false, "score": 4.76837158203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998334646224976}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 76, "offsetEnd": 80}, "context": "Another study by Liu and Chen (2021) focused on cross-domain transfer using STAC (conversation during online game) and Molweni (Ubuntu forum chat logs). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9974101185798645}, "created": {"value": false, "score": 6.711483001708984e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialogLED", "normalizedForm": "DialogLED", "offsetStart": 77, "offsetEnd": 86}, "publisher": {"rawForm": "-alogLM", "normalizedForm": "-alogLM", "offsetStart": 90, "offsetEnd": 97}, "context": "We test with RoBERTa (Liu et al., 2019), Di-aloGPT (Zhang et al., 2020), and DialogLED (Di-alogLM with Longformer) (Zhong et al., 2022) to see how different language models encode discourse information. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.0019075274467468262}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.14971709251403809}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 82, "offsetEnd": 86}, "context": "We decided to run our experiments on the only existing high quality corpus, i.e., STAC.", "mentionContextAttributes": {"used": {"value": false, "score": 0.304365336894989}, "created": {"value": true, "score": 0.9975536465644836}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DailyDialog", "normalizedForm": "DailyDialog", "offsetStart": 85, "offsetEnd": 96}, "context": "For the novel sentence ordering task, we train BART model on the STAC corpus and the DailyDialog corpus (Li et al., 2017).", "mentionContextAttributes": {"used": {"value": false, "score": 0.16381502151489258}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Li et al., 2017)", "normalizedForm": "Li et al., 2017", "refKey": 35, "offsetStart": 17607, "offsetEnd": 17624}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hugging-Face library", "normalizedForm": "Hugging-Face library", "offsetStart": 85, "offsetEnd": 131}, "context": "Implementation Details: We base our work on the transformer implementations from the Hugging-Face library (Wolf et al., 2020)   2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001905977725982666}, "created": {"value": true, "score": 0.9964556694030762}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001905977725982666}, "created": {"value": true, "score": 0.9964556694030762}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 86, "offsetEnd": 90}, "context": "The calculation for one discourse tree on one head was approximately 0.75 seconds (in STAC the averaged dialogue length is 11 EDUs), which quickly summed up to 4.5 hours with only 100 data points for 192 candidate trees in one LM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998661279678345}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 91, "offsetEnd": 95}, "context": "Datasets: We evaluate our approach on predicting discourse dependency structures using the STAC corpus (Asher et al., 2016), a multi-party dialogue dataset annotated in the SDRT framework.", "mentionContextAttributes": {"used": {"value": false, "score": 0.06086820363998413}, "created": {"value": false, "score": 0.001866757869720459}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Asher et al., 2016)", "normalizedForm": "Asher et al., 2016", "refKey": 4, "offsetStart": 17270, "offsetEnd": 17290}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 98, "offsetEnd": 102}, "context": "Further qualitative analysis of inferred structures is presented in Appendix D. Tellingly, on two STAC examples our model succeeds in predicting > 82% of projective arcs, some of which span across 4 EDUs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0062958598136901855}, "created": {"value": false, "score": 0.0006458163261413574}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DailyDialog", "normalizedForm": "DailyDialog", "offsetStart": 98, "offsetEnd": 109}, "context": "In particular, we report results on the vanilla BART model, as well as BART model fine-  tuned on DailyDialog (\"+SO-DD\") and STAC itself (\"+SO-STAC\").", "mentionContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": false, "score": 0.0001513957977294922}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Li et al., 2017)", "normalizedForm": "Li et al., 2017", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 108, "offsetEnd": 112}, "context": "We find that the BART+SO approach surpasses LAST when using local heads (57.1 and 57.2 for Daily-Dialog and STAC resp.).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8646206259727478}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 113, "offsetEnd": 117}, "context": "(  For documents with less than 23 EDUs, all fine-tuned models perform better than LAST, with BART fine-tuned on STAC reaching the best result.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01405942440032959}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialogLED", "normalizedForm": "DialogLED", "offsetStart": 114, "offsetEnd": 123}, "publisher": {"rawForm": "-alogLM", "normalizedForm": "-alogLM"}, "context": "As shown in Table 12, the most discourse-rich head in RoBERTa slightly under-   perform BART (-0.2%), so does the DialogLED (-0.4%) and DialoGPT (-1.4%). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08118540048599243}, "created": {"value": false, "score": 2.300739288330078e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8751183748245239}, "created": {"value": false, "score": 0.14971709251403809}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 125, "offsetEnd": 129}, "context": "In particular, we report results on the vanilla BART model, as well as BART model fine-  tuned on DailyDialog (\"+SO-DD\") and STAC itself (\"+SO-STAC\").", "mentionContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": false, "score": 0.0001513957977294922}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 133, "offsetEnd": 137}, "context": "Shi and Huang (2019) first proposed a neural architecture based on hierarchical Gated Recurrent Unit (GRU) and reported 73.2% F 1 on STAC for naked structures.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00032460689544677734}, "created": {"value": false, "score": 0.4312477111816406}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SAMSum", "normalizedForm": "SAMSum", "offsetStart": 136, "offsetEnd": 142}, "context": "(1) Summarization: we use BART fine-tuned on the popular CNN-DailyMail (CNN-DM) news corpus (Nallapati et al., 2016), as well as on the SAMSum dialogue corpus (Gliwa et al., 2019).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998334646224976}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998334646224976}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialoGPT", "normalizedForm": "DialoGPT", "offsetStart": 136, "offsetEnd": 144}, "context": "As shown in Table 12, the most discourse-rich head in RoBERTa slightly under-   perform BART (-0.2%), so does the DialogLED (-0.4%) and DialoGPT (-1.4%). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.08118551969528198}, "created": {"value": false, "score": 2.300739288330078e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.13330358266830444}, "created": {"value": false, "score": 0.0015091896057128906}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Zhang et al., 2020)", "normalizedForm": "Zhang et al., 2020", "refKey": 60}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 137, "offsetEnd": 141}, "context": "As a result, we see that longer documents (\u2265 23) are indeed more difficult to predict, with even the performance of our best model (BART+STAC) strongly decreasing.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12803179025650024}, "created": {"value": false, "score": 7.30752944946289e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 139, "offsetEnd": 143}, "context": "As commonly the case, the intra-domain training performs best, which is further strengthened in this case due to the special vocabulary in STAC.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004826784133911133}, "created": {"value": false, "score": 7.855892181396484e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 139, "offsetEnd": 143}, "context": "To perform EDU segmentation, we employ the DisCoDisCo model (Gessler et al., 2021), pretrained on a random sample of 50 dialogues from the STAC validation set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9977002739906311}, "created": {"value": false, "score": 9.965896606445312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 143, "offsetEnd": 147}, "context": "In particular, we report results on the vanilla BART model, as well as BART model fine-  tuned on DailyDialog (\"+SO-DD\") and STAC itself (\"+SO-STAC\").", "mentionContextAttributes": {"used": {"value": true, "score": 0.999954342842102}, "created": {"value": false, "score": 0.0001513957977294922}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 148, "offsetEnd": 152}, "context": "Given the fact that our method only extracts projective tree structures, we now conduct an additional analysis, exclusively examining the subset of STAC containing projective trees, on which our method could in theory achieve perfect accuracy.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008840739727020264}, "created": {"value": false, "score": 0.03729277849197388}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 162, "offsetEnd": 166}, "context": "Furthermore, using a small scale validation set (50 examples) to select the best attention head remarkably improves the F 1 score from 56.8% (LAST) to 59.3% (+SO-STAC).", "mentionContextAttributes": {"used": {"value": false, "score": 0.18351417779922485}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 169, "offsetEnd": 173}, "context": "Restricted to domain and size, the performance of supervised discourse parsers is still low, especially for dialogues, with at best 73.8% F 1 for the naked structure on STAC (Wang et al., 2021).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0020464658737182617}, "created": {"value": false, "score": 2.5272369384765625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55, "offsetStart": 3379, "offsetEnd": 3398}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 172, "offsetEnd": 176}, "context": "To compare the performance of the whole test set and tree-structured subset, we present the recall and  precision scores of BART (Fig. 7), BART+SO-DD (Fig. 8), and BART+SO-STAC (Fig. 9) separately.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999476671218872}, "created": {"value": false, "score": 7.510185241699219e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 181, "offsetEnd": 185}, "context": "They applied simple adaptation strategies (mainly lexical information) on a SOTA discourse parser and showed improvement compared to bare transfer: trained on Molweni and tested on STAC F 1 increased from 42.5% to 50.5%.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999748468399048}, "created": {"value": false, "score": 1.7642974853515625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Wang et al., 2021)", "normalizedForm": "Wang et al., 2021", "refKey": 55}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DialoGPT", "normalizedForm": "DialoGPT", "offsetStart": 234, "offsetEnd": 242}, "context": "Pre-Trained Models: We select BART (Lewis et al., 2020), not only because its encoder has been shown to effectively capture discourse information, but also because it dominated other alternatives in preliminary experiments, including DialoGPT (Zhang et al., 2020) and DialogLM (Zhong et al., 2022) -language models pre-trained with conversational data2 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.13330358266830444}, "created": {"value": false, "score": 0.0015091896057128906}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.13330358266830444}, "created": {"value": false, "score": 0.0015091896057128906}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "references": [{"label": "(Zhang et al., 2020)", "normalizedForm": "Zhang et al., 2020", "refKey": 60, "offsetStart": 11614, "offsetEnd": 11634}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STAC", "normalizedForm": "STAC", "offsetStart": 368, "offsetEnd": 372}, "context": "Discourse structures for complete documents have been mainly annotated within the Segmented Discourse Representation Theory (SDRT) (Asher et al., 2003) or the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988), with the latter leading to the largest corpora and many discourse parsers for monologues, while SDRT is the main theory for dialogue corpora, i.e., STAC (Asher et al., 2016) and Molweni (Li et al., 2020).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984789490699768}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999845027923584}, "created": {"value": true, "score": 0.9989776611328125}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "references": [{"label": "(Asher et al., 2016)", "normalizedForm": "Asher et al., 2016", "refKey": 4, "offsetStart": 6534, "offsetEnd": 6554}]}], "references": [{"refKey": 55, "tei": "<biblStruct xml:id=\"b55\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">A Structure Self-Aware Model for Discourse Parsing on Multi-Party Dialogues</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ante</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Linfeng</forename><surname>Song</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hui</forename><surname>Jiang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Shaopeng</forename><surname>Lai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Junfeng</forename><surname>Yao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Min</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jinsong</forename><surname>Su</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.24963/ijcai.2021/543</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence</title>\n\t\t<meeting>the Thirtieth International Joint Conference on Artificial Intelligence</meeting>\n\t\t<imprint>\n\t\t\t<publisher>International Joint Conferences on Artificial Intelligence Organization</publisher>\n\t\t\t<date type=\"published\" when=\"2021-08\">2021</date>\n\t\t\t<biblScope unit=\"page\" from=\"3943\" to=\"3949\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 35, "tei": "<biblStruct xml:id=\"b35\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">DailyDialog: A manually labelled multi-turn dialogue dataset</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yanran</forename><surname>Li</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hui</forename><surname>Su</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xiaoyu</forename><surname>Shen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wenjie</forename><surname>Li</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ziqiang</forename><surname>Cao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Shuzi</forename><surname>Niu</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>\n\t\t<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Asian Federation of Natural Language Processing</publisher>\n\t\t\t<date>2017</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">995</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 56, "tei": "<biblStruct xml:id=\"b56\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Transformers: State-of-the-Art Natural Language Processing</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Thomas</forename><surname>Wolf</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lysandre</forename><surname>Debut</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Victor</forename><surname>Sanh</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Julien</forename><surname>Chaumond</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Clement</forename><surname>Delangue</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Anthony</forename><surname>Moi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pierric</forename><surname>Cistac</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tim</forename><surname>Rault</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Remi</forename><surname>Louf</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Morgan</forename><surname>Funtowicz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Joe</forename><surname>Davison</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sam</forename><surname>Shleifer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Patrick</forename><surname>Von Platen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Clara</forename><surname>Ma</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yacine</forename><surname>Jernite</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Julien</forename><surname>Plu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Canwen</forename><surname>Xu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Teven</forename><surname>Le Scao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sylvain</forename><surname>Gugger</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mariama</forename><surname>Drame</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Quentin</forename><surname>Lhoest</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alexander</forename><surname>Rush</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2020.emnlp-demos.6</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>\n\t\t<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n\t\t\t<biblScope unit=\"page\">45</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 4, "tei": "<biblStruct xml:id=\"b4\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Discourse structure and dialogue acts in multiparty dialogue: the STAC corpus</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nicholas</forename><surname>Asher</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Julie</forename><surname>Hunter</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mathieu</forename><surname>Morey</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benamara</forename><surname>Farah</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Stergos</forename><surname>Afantenos</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>\n\t\t<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>European Language Resources Association (ELRA</publisher>\n\t\t\t<date>2016</date>\n\t\t\t<biblScope unit=\"page\">2727</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 60, "tei": "<biblStruct xml:id=\"b60\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yizhe</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Siqi</forename><surname>Sun</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Michel</forename><surname>Galley</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yen-Chun</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chris</forename><surname>Brockett</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xiang</forename><surname>Gao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jianfeng</forename><surname>Gao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jingjing</forename><surname>Liu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bill</forename><surname>Dolan</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2020.acl-demos.30</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>\n\t\t<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n\t\t\t<biblScope unit=\"page\">278</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10788, "id": "ca33b6c4d6231a82aa8b10af4ef4a5f06f03f612", "metadata": {"id": "ca33b6c4d6231a82aa8b10af4ef4a5f06f03f612"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04031267.grobid.tei.xml", "file_name": "hal-04031267.grobid.tei.xml"}