{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T17:08+0000", "md5": "2B43C329E433CF51B3A8B11F383A9DF0", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 2, "offsetEnd": 11}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "5 SnakeCLEF challenge: Automated snake species identification based on images and two-level geographic location data (continent and country).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5392011404037476}, "created": {"value": false, "score": 5.072355270385742e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 3, "offsetEnd": 11}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "2. BirdCLEF 2020: Bird species recognition in audio soundscapes.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002230703830718994}, "created": {"value": false, "score": 4.51207160949707e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 3, "offsetEnd": 12}, "version": {"rawForm": "2020", "normalizedForm": "2020", "offsetStart": 13, "offsetEnd": 17}, "context": "4. SnakeCLEF 2020: Automated snake species identification based on images and two level geographic location data -continent and country.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004321575164794922}, "created": {"value": false, "score": 1.817941665649414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 4, "offsetEnd": 12}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "The LifeCLEF campaign, presented in this paper, has been promoting and evaluating advances in this domain since 2011.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006004571914672852}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 4, "offsetEnd": 12}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "The LifeCLEF Bird Recognition Challenge (BirdCLEF) launched in 2014 and has since become the largest bird sound recognition challenge in terms of dataset size and species diversity with multiple tens of thousands of recordings covering up to 1,500 species [25], [40].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021165013313293457}, "created": {"value": false, "score": 0.0003730654716491699}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Gokuleloop", "normalizedForm": "Gokuleloop", "offsetStart": 4, "offsetEnd": 14}, "context": "The Gokuleloop team approaches were focused on the domain specific fine-tuning where this team tried different pre-trained weights.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999541640281677}, "created": {"value": false, "score": 0.00011819601058959961}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999541640281677}, "created": {"value": false, "score": 0.00011819601058959961}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 12, "offsetEnd": 20}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "Since 2014, LifeCLEF expanded the challenge by considering animals in addition to plants, and including audio and video content in addition to images [37,38,35,36,33,34]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002745389938354492}, "created": {"value": false, "score": 0.00011593103408813477}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 19, "offsetEnd": 28}, "context": "The results of the PlantCLEF challenge, in particular, revealed that the last advances in domain adaptation enable the use of herbarium data to facilitate the identification of rare tropical species for which no or very few other training images are available. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8720461130142212}, "created": {"value": false, "score": 0.0016720890998840332}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 25, "offsetEnd": 34}, "context": "In the continuity of the PlantCLEF challenges organized in previous years [23,24,22,28,26,17,18,19,20], this year's challenge was designed to evaluate to what extent automated plant species identification on tropical data deficient regions can be improved by the use of herbarium sheets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.030327141284942627}, "created": {"value": false, "score": 0.0004310011863708496}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 29, "offsetEnd": 37}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Xeno-canto data was used for BirdCLEF in all past editions to provide researchers with large and diverse datasets for training and testing. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.33717572689056396}, "created": {"value": false, "score": 9.173154830932617e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 32, "offsetEnd": 40}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The diversity of this data made BirdCLEF a demanding competition and required participating research groups to develop efficient processing and classification pipelines. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05390477180480957}, "created": {"value": false, "score": 0.0006279349327087402}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 32, "offsetEnd": 41}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Furthermore, the results of the SnakeCLEF challenge showed that both traditional approaches and deep convolutional neural networks can benefit from geographical information.", "mentionContextAttributes": {"used": {"value": true, "score": 0.932331919670105}, "created": {"value": false, "score": 0.00022530555725097656}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 33, "offsetEnd": 42}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Out of 8 registered teams in the SnakeCLEF 2020 challenge, only 2 teams managed to submit a working version of their recognition system. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.0002124309539794922}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 35, "offsetEnd": 43}, "version": {"rawForm": "2020", "normalizedForm": "2020", "offsetStart": 44, "offsetEnd": 48}, "context": "69 participants registered for the BirdCLEF 2020 challenge and downloaded the dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 1.5079975128173828e-05}, "shared": {"value": false, "score": 3.159046173095703e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 35, "offsetEnd": 44}, "context": "68 participants registered for the PlantCLEF challenge 2020 (PC20) and downloaded the data set, and 7 research groups succeeded in submitting runs, i.e. files containing the predictions of the system(s) they ran.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997696876525879}, "created": {"value": false, "score": 2.2351741790771484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 41, "offsetEnd": 49}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The LifeCLEF Bird Recognition Challenge (BirdCLEF) launched in 2014 and has since become the largest bird sound recognition challenge in terms of dataset size and species diversity with multiple tens of thousands of recordings covering up to 1,500 species [25], [40].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021165013313293457}, "created": {"value": false, "score": 0.0003730654716491699}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 45, "offsetEnd": 54}, "context": "This is the first time over all the years of PlantCLEF challenges that we clearly observe an important impact of the use of genus and family information to improve the species identification. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.007366299629211426}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 49, "offsetEnd": 57}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "Four challenges were evaluated in the context of LifeCLEF 2020 edition: 1. PlantCLEF 2020: Identifying plant pictures from herbarium sheets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9733882546424866}, "created": {"value": false, "score": 7.331371307373047e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Life-CLEF", "normalizedForm": "Life-CLEF", "offsetStart": 70, "offsetEnd": 82}, "context": "In order to measure progress in a sustainable and repeatable way, the Life-CLEF 15 research platform was created in 2014 as a continuation and extension of the plant identification task [27] that had been run within the ImageCLEF lab 16 since 2011 [23,24,22]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001412034034729004}, "created": {"value": false, "score": 0.004500091075897217}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001412034034729004}, "created": {"value": false, "score": 0.004500091075897217}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 75, "offsetEnd": 84}, "context": "Four challenges were evaluated in the context of LifeCLEF 2020 edition: 1. PlantCLEF 2020: Identifying plant pictures from herbarium sheets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9733882546424866}, "created": {"value": false, "score": 7.331371307373047e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Gokuleloop", "normalizedForm": "Gokuleloop", "offsetStart": 96, "offsetEnd": 106}, "context": "With the Imagenet-21k weights, ResNet50 architecture, and naive probability weighting approach, Gokuleloop team achieved top F1 score of 0.625 while having a Log Loss of 0.83.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993081092834473}, "created": {"value": false, "score": 2.1517276763916016e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999541640281677}, "created": {"value": false, "score": 0.00011819601058959961}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 109, "offsetEnd": 117}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "Such a distribution with small inter-class variance and high intra-class   Testing Dataset: Apart from other LifeCLEF challenges, the final testing set remains undisclosed as it is a composition of private images from individual reporters and natural history museums who have not put those images online in any form.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005673408508300781}, "created": {"value": false, "score": 5.942583084106445e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 114, "offsetEnd": 122}, "version": {"rawForm": "2020", "normalizedForm": "2020", "offsetStart": 98, "offsetEnd": 102}, "context": "In addition to the 2019 test data, soundscapes from three other recording sites were added in the 2020 edition of BirdCLEF. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99688321352005}, "created": {"value": false, "score": 6.93202018737793e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 119, "offsetEnd": 127}, "version": {"rawForm": "2020.", "normalizedForm": "2020", "offsetStart": 128, "offsetEnd": 133}, "context": "The mean across all classes is Fig. 5: Scores achieved by all systems evaluated within the bird identification task of LifeCLEF 2020. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": false, "score": 8.761882781982422e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LifeCLEF", "normalizedForm": "LifeCLEF", "offsetStart": 120, "offsetEnd": 128}, "version": {"rawForm": "2020.", "normalizedForm": "2020"}, "context": "In the following sections, we provide a synthesis of the methodology and main results of each of the four challenges of LifeCLEF2020.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03795051574707031}, "created": {"value": true, "score": 0.6706065535545349}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999392628669739}, "created": {"value": true, "score": 0.9553824663162231}, "shared": {"value": false, "score": 3.635883331298828e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 122, "offsetEnd": 131}, "context": "The 2020 edition proposes four data-oriented challenges related to the identification and prediction of biodiversity: (i) PlantCLEF: cross-domain plant identification based on herbarium sheets, (ii) BirdCLEF: bird species recognition in audio soundscapes, (iii) GeoLifeCLEF: location-based prediction of species based on environmental and occurrence data, and (iv) SnakeCLEF: snake identification based on image and geographic location.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006266236305236816}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.205371856689453e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q182496", "wikipediaExternalRef": 4325491, "lang": "en", "confidence": 0.566, "software-name": {"rawForm": "Bing", "normalizedForm": "Bing", "wikidataId": "Q182496", "wikipediaExternalRef": 4325491, "lang": "en", "confidence": 0.566, "offsetStart": 141, "offsetEnd": 145}, "context": "The species were chosen based on the most comprehensive estimates possible from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.00022077560424804688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.00022077560424804688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Gokuleloop", "normalizedForm": "Gokuleloop", "offsetStart": 191, "offsetEnd": 205}, "context": "Details of the methods and systems used in the runs are synthesized in the overview working note paper of the task [48] and further developed in the individual working notes (FHDO BCSG [2]], Gokuleloop [44]). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9972441792488098}, "created": {"value": false, "score": 2.9265880584716797e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999541640281677}, "created": {"value": false, "score": 0.00011819601058959961}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "BirdCLEF", "normalizedForm": "BirdCLEF", "offsetStart": 199, "offsetEnd": 207}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The 2020 edition proposes four data-oriented challenges related to the identification and prediction of biodiversity: (i) PlantCLEF: cross-domain plant identification based on herbarium sheets, (ii) BirdCLEF: bird species recognition in audio soundscapes, (iii) GeoLifeCLEF: location-based prediction of species based on environmental and occurrence data, and (iv) SnakeCLEF: snake identification based on image and geographic location.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006266236305236816}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.205371856689453e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9986202120780945}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 3.159046173095703e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PlantCLEF", "normalizedForm": "PlantCLEF", "offsetStart": 208, "offsetEnd": 217}, "context": "The species were chosen based on the most comprehensive estimates possible from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.00022077560424804688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.08127808570861816}, "shared": {"value": false, "score": 2.205371856689453e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ImageCLEF", "normalizedForm": "ImageCLEF", "offsetStart": 220, "offsetEnd": 229}, "context": "In order to measure progress in a sustainable and repeatable way, the Life-CLEF 15 research platform was created in 2014 as a continuation and extension of the plant identification task [27] that had been run within the ImageCLEF lab 16 since 2011 [23,24,22]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001412034034729004}, "created": {"value": false, "score": 0.004500091075897217}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.001412034034729004}, "created": {"value": false, "score": 0.004500091075897217}, "shared": {"value": false, "score": 7.748603820800781e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ExpertCLEF", "normalizedForm": "ExpertCLEF", "offsetStart": 222, "offsetEnd": 232}, "context": "The species were chosen based on the most comprehensive estimates possible from different data sources (IdigBio, GBIF, Encyclopedia of Life, Bing and Google Image search engines, previous datasets related to PlantCLEF and ExpertCLEF challenges). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.00022077560424804688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999209046363831}, "created": {"value": false, "score": 0.00022077560424804688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SnakeCLEF", "normalizedForm": "SnakeCLEF", "offsetStart": 365, "offsetEnd": 374}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The 2020 edition proposes four data-oriented challenges related to the identification and prediction of biodiversity: (i) PlantCLEF: cross-domain plant identification based on herbarium sheets, (ii) BirdCLEF: bird species recognition in audio soundscapes, (iii) GeoLifeCLEF: location-based prediction of species based on environmental and occurrence data, and (iv) SnakeCLEF: snake identification based on image and geographic location.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006266236305236816}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9730229377746582}, "created": {"value": false, "score": 0.035498082637786865}, "shared": {"value": false, "score": 2.1457672119140625e-06}}}], "references": [], "runtime": 43009, "id": "68ad5623aac25c53cd0f59bd880154b51f97064c", "metadata": {"id": "68ad5623aac25c53cd0f59bd880154b51f97064c"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-02945382.grobid.tei.xml", "file_name": "hal-02945382.grobid.tei.xml"}