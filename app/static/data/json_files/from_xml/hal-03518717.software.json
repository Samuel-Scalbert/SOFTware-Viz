{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:45+0000", "md5": "EF5BE45DEB4FD2843C343DE50C0F88DB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 20, "offsetEnd": 29}, "context": "Finally, we applied CamemBERT [17], a French Transformer Language Model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.00039964914321899414}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17, "offsetStart": 10990, "offsetEnd": 10994}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 31, "offsetEnd": 40}, "context": "Flair gets a similar Recall to CamemBERT but the Precision is lower.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005832910537719727}, "created": {"value": false, "score": 1.2993812561035156e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 41, "offsetEnd": 50}, "context": "The combination of Flair and Word2Vec or CamemBERT and Word2Vec increases the Precision but decreases the Recall.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12545132637023926}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 51, "offsetEnd": 60}, "context": "We can underline that the combination of Flair and CamemBERT increases the performance of the 3 metrics.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10058242082595825}, "created": {"value": false, "score": 0.0004627704620361328}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 53, "offsetEnd": 62}, "context": "Regarding BiLSTM+CRF models with a single embedding, CamemBERT achieves very good performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008450746536254883}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 62, "offsetEnd": 71}, "context": "Finally, the combination of the three representation (Flair + CamemBERT + Word2Vec) achieves the best results while the Welch's t-test does not show difference with Flair + CamemBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7769500017166138}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 72, "offsetEnd": 81}, "context": "Nevertheless, we decided not to fine-tune the French pre-trained model, CamemBERT, due to a lack of a huge training corpus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.11725550889968872}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XGBoost", "normalizedForm": "XGBoost", "offsetStart": 76, "offsetEnd": 83}, "context": "In Table 5, we present the best performance of each classification using an XGBoost model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6303998827934265}, "created": {"value": false, "score": 0.03732484579086304}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.03732484579086304}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XGBoost", "normalizedForm": "XGBoost", "offsetStart": 88, "offsetEnd": 95}, "context": "We tried different classification models such as Naive Bayes, Support Vector Machine or XGBoost, and quantified their performance with Accuracy defined as", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.00022393465042114258}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.03732484579086304}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 173, "offsetEnd": 182}, "context": "Finally, the combination of the three representation (Flair + CamemBERT + Word2Vec) achieves the best results while the Welch's t-test does not show difference with Flair + CamemBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7769500017166138}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201826095581}, "created": {"value": false, "score": 0.014745891094207764}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}], "references": [{"refKey": 17, "tei": "<biblStruct xml:id=\"b17\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">CamemBERT: a Tasty French Language Model</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Louis</forename><surname>Martin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Muller</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pedro</forename><forename type=\"middle\">Javier</forename><surname>Ortiz Su\u00e1rez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yoann</forename><surname>Dupont</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Laurent</forename><surname>Romary</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">\u00c9ric</forename><surname>De La Clergerie</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Djam\u00e9</forename><surname>Seddah</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2020.acl-main.645</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>\n\t\t<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n\t\t\t<biblScope unit=\"page\">7219</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 11898, "id": "ba39c6b42618e45db566b974b8184b3b44341f26", "metadata": {"id": "ba39c6b42618e45db566b974b8184b3b44341f26"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03518717.grobid.tei.xml", "file_name": "hal-03518717.grobid.tei.xml"}