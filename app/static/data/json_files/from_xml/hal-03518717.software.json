{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T15:40+0000", "md5": "552662DDCFC072BFEC4EC0390DFB893F", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 20, "offsetEnd": 29}, "context": "Finally, we applied CamemBERT [17], a French Transformer Language Model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.00039964914321899414}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17, "offsetStart": 10990, "offsetEnd": 10994}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 31, "offsetEnd": 40}, "context": "Flair gets a similar Recall to CamemBERT but the Precision is lower.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005832910537719727}, "created": {"value": false, "score": 1.3053417205810547e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 41, "offsetEnd": 50}, "context": "The combination of Flair and Word2Vec or CamemBERT and Word2Vec increases the Precision but decreases the Recall.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12545204162597656}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 51, "offsetEnd": 60}, "context": "We can underline that the combination of Flair and CamemBERT increases the performance of the 3 metrics.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1005820631980896}, "created": {"value": false, "score": 0.0004628300666809082}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 53, "offsetEnd": 62}, "context": "Regarding BiLSTM+CRF models with a single embedding, CamemBERT achieves very good performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008451342582702637}, "created": {"value": false, "score": 6.258487701416016e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 62, "offsetEnd": 71}, "context": "Finally, the combination of the three representation (Flair + CamemBERT + Word2Vec) achieves the best results while the Welch's t-test does not show difference with Flair + CamemBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7769501805305481}, "created": {"value": false, "score": 5.543231964111328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 72, "offsetEnd": 81}, "context": "Nevertheless, we decided not to fine-tune the French pre-trained model, CamemBERT, due to a lack of a huge training corpus.", "mentionContextAttributes": {"used": {"value": false, "score": 0.11725574731826782}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XGBoost", "normalizedForm": "XGBoost", "offsetStart": 76, "offsetEnd": 83}, "context": "In Table 5, we present the best performance of each classification using an XGBoost model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6304019093513489}, "created": {"value": false, "score": 0.03732597827911377}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.03732597827911377}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XGBoost", "normalizedForm": "XGBoost", "offsetStart": 88, "offsetEnd": 95}, "context": "We tried different classification models such as Naive Bayes, Support Vector Machine or XGBoost, and quantified their performance with Accuracy defined as", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.00022393465042114258}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997078776359558}, "created": {"value": false, "score": 0.03732597827911377}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 173, "offsetEnd": 182}, "context": "Finally, the combination of the three representation (Flair + CamemBERT + Word2Vec) achieves the best results while the Welch's t-test does not show difference with Flair + CamemBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7769502401351929}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995201230049133}, "created": {"value": false, "score": 0.014745831489562988}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "references": [{"label": "[17]", "normalizedForm": "[17]", "refKey": 17}]}], "references": [{"refKey": 17, "tei": "<biblStruct xml:id=\"b17\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">CamemBERT: a Tasty French Language Model</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Louis</forename><surname>Martin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Muller</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pedro</forename><forename type=\"middle\">Javier</forename><surname>Ortiz Su\u00e1rez</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yoann</forename><surname>Dupont</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Laurent</forename><surname>Romary</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">\u00c9ric</forename><surname>De La Clergerie</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Djam\u00e9</forename><surname>Seddah</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Beno\u00eet</forename><surname>Sagot</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/2020.acl-main.645</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>\n\t\t<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020</date>\n\t\t\t<biblScope unit=\"page\">7219</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 54624, "id": "45c686f861a2c8632b7f3195dda5282d464365d4", "metadata": {"id": "45c686f861a2c8632b7f3195dda5282d464365d4"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-03518717.grobid.tei.xml", "file_name": "hal-03518717.grobid.tei.xml"}