{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:02+0000", "md5": "339CD9EAE7ECD7ED6B9C45F1E124F490", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveCycleGAN2", "normalizedForm": "WaveCycleGAN2", "offsetStart": 0, "offsetEnd": 13}, "context": "WaveCycleGAN2 was trained using the GAN criterion with four discriminators (waveform, Mel-spectrum, MCC, and phase spectrum discriminators). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9987346529960632}, "created": {"value": false, "score": 1.633167266845703e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9987346529960632}, "created": {"value": false, "score": 4.0411949157714844e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 4, "offsetEnd": 9}, "context": "The Kaldi implementation of PLDA [63] is used for scoring.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010491371154785156}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 4, "offsetEnd": 11}, "context": "The WaveNet vocoder followed the recipe in [19] but uses a Gaussian distribution to directly model continuousvalued raw waveforms.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9659499526023865}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "environment", "software-name": {"rawForm": "MATLAB", "normalizedForm": "MATLAB", "offsetStart": 5, "offsetEnd": 11}, "context": "zip (MATLAB) https://www.asvspoof.org/asvspoof2019/tDCF_ ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0071204304695129395}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": true, "score": 0.9826279282569885}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0071204304695129395}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": true, "score": 0.9826279282569885}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 6, "offsetEnd": 13}, "context": "These WaveNet vocoders (\u00b5-law companding and 10-bit quantization) were trained by pre-training them using an in-house multi-speaker corpus and fine-tuning it using the speech of target speakers [38].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999139308929443}, "created": {"value": false, "score": 9.5367431640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "environment", "software-name": {"rawForm": "SPSS", "normalizedForm": "SPSS", "offsetStart": 12, "offsetEnd": 16}, "context": "An NN-based SPSS TTS system [30]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004195570945739746}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008987486362457275}, "created": {"value": false, "score": 8.046627044677734e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 13, "offsetEnd": 18}, "context": "The original Kaldi recipe was modified to include PLDA adaptation using disjoint, bona fide, in-domain data.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8210493922233582}, "created": {"value": false, "score": 4.100799560546875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 13, "offsetEnd": 20}, "context": "Finally, the WaveNet vocoder is used to convert the MCCs and F0 into a waveform. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9525846242904663}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Tacotron", "normalizedForm": "Tacotron", "offsetStart": 13, "offsetEnd": 21}, "context": "A10 uses the Tacotron acoustic model with WaveRNN for waveform generation, whereas A13 and A17 employ an acoustic model based on the moment matching neural network and VAE, respectively, with waveform filtering for waveform generation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04893016815185547}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Tacotron", "normalizedForm": "Tacotron", "offsetStart": 17, "offsetEnd": 25}, "context": "The base system, Tacotron 2, is composed of two components: a sequence-to-sequence model that generates Melspectrograms on the basis of the input text or phoneme sequences and a neural vocoder for converting Mel-spectrograms to a waveform. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027865171432495117}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveRNN", "normalizedForm": "WaveRNN", "offsetStart": 24, "offsetEnd": 36}, "context": "For the neural vocoder, WaveRNN [34] was used.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999058246612549}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999058246612549}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Roomsimove", "normalizedForm": "Roomsimove", "offsetStart": 28, "offsetEnd": 44}, "context": "Simulations were done using Roomsimove9  [56], which takes into account the entire acoustic environment, including room size, reverberation, and varying source/receiver positions, which includes source directivity. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999775886535645}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 5.054473876953125e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STRAIGHT", "normalizedForm": "STRAIGHT", "offsetStart": 33, "offsetEnd": 41}, "context": "For waveform reconstruction, the STRAIGHT vocoder was used.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999841451644897}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999841451644897}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Roomsimove", "normalizedForm": "Roomsimove", "offsetStart": 35, "offsetEnd": 45}, "context": "All simulations were made with the Roomsimove default microphone and talker heights of 1.1m. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 5.841255187988281e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 5.054473876953125e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 36, "offsetEnd": 43}, "context": "A neural TTS system based on the AR WaveNet [10].", "mentionContextAttributes": {"used": {"value": false, "score": 4.9591064453125e-05}, "created": {"value": false, "score": 2.288818359375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10, "offsetStart": 29905, "offsetEnd": 29909}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 36, "offsetEnd": 43}, "context": "However, A15 uses speaker-dependent WaveNet vocoders rather than the STRAIGHT vocoder to generate waveforms.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004690229892730713}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Roomsimove", "normalizedForm": "Roomsimove", "offsetStart": 38, "offsetEnd": 48}, "context": "The height of each room is set to the Roomsimove default of 2.7 m.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8224440217018127}, "created": {"value": false, "score": 5.054473876953125e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999881982803345}, "created": {"value": false, "score": 5.054473876953125e-05}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveRNN", "normalizedForm": "WaveRNN", "offsetStart": 42, "offsetEnd": 49}, "context": "A10 uses the Tacotron acoustic model with WaveRNN for waveform generation, whereas A13 and A17 employ an acoustic model based on the moment matching neural network and VAE, respectively, with waveform filtering for waveform generation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04893016815185547}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999058246612549}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoiceText Web-API", "normalizedForm": "VoiceText Web-API", "offsetStart": 42, "offsetEnd": 59}, "context": "The TTS system in A13 is a product called VoiceText Web-API, which is publicly available for non-commercial uses 5 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008702874183654785}, "created": {"value": false, "score": 0.0008578300476074219}, "shared": {"value": true, "score": 0.5999991297721863}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008702874183654785}, "created": {"value": false, "score": 0.0008578300476074219}, "shared": {"value": true, "score": 0.5999991297721863}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveCycleGAN2", "normalizedForm": "WaveCycleGAN2", "offsetStart": 45, "offsetEnd": 58}, "context": "In other words, both the input and output of WaveCycleGAN2 are raw waveforms. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.01890021562576294}, "created": {"value": false, "score": 3.62396240234375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9987346529960632}, "created": {"value": false, "score": 4.0411949157714844e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Voice Cloning Toolkit", "normalizedForm": "Voice Cloning Toolkit", "offsetStart": 45, "offsetEnd": 66}, "context": "The ASVspoof 2019 database is based upon the Voice Cloning Toolkit (VCTK) corpus [11], a multi-speaker English speech database recorded in a hemi-anechoic chamber at a sampling rate of 96 kHz. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9827629327774048}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9827629327774048}, "created": {"value": false, "score": 1.3828277587890625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STRAIGHT", "normalizedForm": "STRAIGHT", "offsetStart": 50, "offsetEnd": 58}, "context": "The spoofing method A14, which uses LSTM with the STRAIGHT vocoder, also caused a comparable degradation in EER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9521361589431763}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999841451644897}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Vocaine", "normalizedForm": "Vocaine", "offsetStart": 53, "offsetEnd": 60}, "context": "However, the LSTM-based acoustic model that uses the Vocaine vocoder (i.e., A09) for waveform generation did not degrade the ASV performance like the other LSTM-based models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8982976675033569}, "created": {"value": false, "score": 8.428096771240234e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9841199517250061}, "created": {"value": false, "score": 0.00019103288650512695}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[31]", "normalizedForm": "[31]", "refKey": 31}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Merlin", "normalizedForm": "Merlin", "offsetStart": 57, "offsetEnd": 63}, "context": "The alignment for model training was extracted using the Merlin toolkit [21].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": false, "score": 0.0002484917640686035}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "references": [{"label": "[21]", "normalizedForm": "[21]", "refKey": 21, "offsetStart": 26859, "offsetEnd": 26863}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 59, "offsetEnd": 66}, "context": "Attackers may use A01 to attack ASV/CM systems because the WaveNet vocoder can produce high-quality speech that fools CMs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008869767189025879}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveCycleGAN2", "normalizedForm": "WaveCycleGAN2", "offsetStart": 59, "offsetEnd": 76}, "context": "After the waveform is synthesized using the WORLD vocoder, WaveCycleGAN2 [28], a time-domain neural postfilter, is used to transform the output waveform of the WORLD vocoder into a natural-sounding waveform. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9983708262443542}, "created": {"value": false, "score": 4.0411949157714844e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9987346529960632}, "created": {"value": false, "score": 4.0411949157714844e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Vocaine", "normalizedForm": "Vocaine", "offsetStart": 61, "offsetEnd": 68}, "context": "A09 uses two LSTM-based acoustic models and a vocoder called Vocaine [31].", "mentionContextAttributes": {"used": {"value": false, "score": 0.02490973472595215}, "created": {"value": false, "score": 7.987022399902344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9841199517250061}, "created": {"value": false, "score": 0.00019103288650512695}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[31]", "normalizedForm": "[31]", "refKey": 31, "offsetStart": 27978, "offsetEnd": 27982}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 65, "offsetEnd": 70}, "context": "The within-class and betweenclass covariances were adapted using Kaldi's domain adaptation technique (Algorithm 1 of [62]) with scaling factors of \u03b1 w = 0.25 and \u03b1 b = 0 for LA and \u03b1 w = 0.90 and \u03b1 b = 0 for PA.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999971866607666}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 66, "offsetEnd": 71}, "context": "The neural-network-based x-vector extractor was trained using the Kaldi toolkit and the VoxCeleb recipe 6 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.00014984607696533203}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STRAIGHT", "normalizedForm": "STRAIGHT", "offsetStart": 69, "offsetEnd": 77}, "context": "However, A15 uses speaker-dependent WaveNet vocoders rather than the STRAIGHT vocoder to generate waveforms. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004690229892730713}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999841451644897}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 75, "offsetEnd": 85}, "context": "The x-vector extractor is a pretrained 11 neural network available for the Kaldi [60] toolkit. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05574345588684082}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0002892613410949707}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "environment", "software-name": {"rawForm": "SPSS", "normalizedForm": "SPSS", "offsetStart": 83, "offsetEnd": 87}, "context": "This system follows the standard NN-based statistical parametric speech synthesis (SPSS) framework [14] and uses a powerful neural waveform generator called WaveNet [10]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008987486362457275}, "created": {"value": false, "score": 8.046627044677734e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.008987486362457275}, "created": {"value": false, "score": 8.046627044677734e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 85, "offsetEnd": 92}, "context": "An NN-based TTS system similar to A01 except that the WORLD vocoder [20] rather than WaveNet is used to generate waveforms.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003674030303955078}, "created": {"value": false, "score": 1.0728836059570312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 86, "offsetEnd": 93}, "context": "While the front-end is off-the-shelf, the duration model, the acoustic model, and the WaveNet vocoder were trained using the data for spoofing systems (#1 in Figure 2). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 88, "offsetEnd": 95}, "context": "However, A08 uses a neural-source-filter waveform model [29], which is much faster than WaveNet.", "mentionContextAttributes": {"used": {"value": false, "score": 0.002076268196105957}, "created": {"value": false, "score": 1.33514404296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxCeleb", "normalizedForm": "VoxCeleb", "offsetStart": 88, "offsetEnd": 96}, "context": "The neural-network-based x-vector extractor was trained using the Kaldi toolkit and the VoxCeleb recipe 6 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.00014984607696533203}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0018913745880126953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 90, "offsetEnd": 97}, "context": "Attackers may use A02 rather than A01 if they cannot collect sufficient data to train the WaveNet vocoder.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017444491386413574}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Vocaine", "normalizedForm": "Vocaine", "offsetStart": 90, "offsetEnd": 97}, "context": "It turns out that the waveform generation methods based on the neural sourcefilter model, Vocaine, and Griffin-Lim were not able to produce audio that shows more similarity to genuine speech under the current settings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9841199517250061}, "created": {"value": false, "score": 0.00019103288650512695}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9841199517250061}, "created": {"value": false, "score": 0.00019103288650512695}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[31]", "normalizedForm": "[31]", "refKey": 31}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VoxCeleb", "normalizedForm": "VoxCeleb", "offsetStart": 95, "offsetEnd": 103}, "context": "The network is trained with MFCC features extracted from audio data from 7,325 speakers of the VoxCeleb1 and Vox-Celeb2 [61] databases.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9753780364990234}, "created": {"value": false, "score": 0.0018913745880126953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.0018913745880126953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "STRAIGHT", "normalizedForm": "STRAIGHT", "offsetStart": 114, "offsetEnd": 126}, "context": "The acoustic features used are 41-dimensional MCCs, F0, and 5-dimensional BAPs, all of which were extracted using STRAIGHT [39]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999595880508423}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999841451644897}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 119, "offsetEnd": 126}, "context": "Phone duration and F0 were first predicted by the above TTS system A09; they were then used as input features to an AR WaveNet with a conditioning stack to receive the linguistic features.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999401569366455}, "created": {"value": false, "score": 2.9802322387695312e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Merlin", "normalizedForm": "Merlin", "offsetStart": 120, "offsetEnd": 130}, "context": "Attackers may use A03 because it can be easily built from scratch by using recipes in an open-source TTS toolkit called Merlin [21].", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023990869522094727}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": false, "score": 0.0002484917640686035}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "references": [{"label": "[21]", "normalizedForm": "[21]", "refKey": 21}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Tacotron", "normalizedForm": "Tacotron", "offsetStart": 126, "offsetEnd": 134}, "context": "An end-to-end NN-based TTS system [32] that applies transfer learning from speaker verification to a neural TTS system called Tacotron 2 [9]. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.8504600524902344e-05}, "created": {"value": false, "score": 2.193450927734375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9, "offsetStart": 28845, "offsetEnd": 28848}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveRNN", "normalizedForm": "WaveRNN", "offsetStart": 149, "offsetEnd": 156}, "context": "Attackers may consider A11 instead of A10 because the Griffin-Lim algorithm requires no model training and is faster in waveform generation than the WaveRNN in A10.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0016176700592041016}, "created": {"value": false, "score": 1.5735626220703125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999058246612549}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Vocaine", "normalizedForm": "Vocaine", "offsetStart": 153, "offsetEnd": 160}, "context": "Given the predicted number of acoustic frames and a very similar linguistic input, the second LSTM model predicts the acoustic features that are used by Vocaine to generate waveforms. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.05953967571258545}, "created": {"value": false, "score": 1.9550323486328125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9841199517250061}, "created": {"value": false, "score": 0.00019103288650512695}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[31]", "normalizedForm": "[31]", "refKey": 31}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 157, "offsetEnd": 168}, "context": "This system follows the standard NN-based statistical parametric speech synthesis (SPSS) framework [14] and uses a powerful neural waveform generator called WaveNet [10]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.008987605571746826}, "created": {"value": false, "score": 8.046627044677734e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Merlin", "normalizedForm": "Merlin", "offsetStart": 159, "offsetEnd": 165}, "context": "The first LSTM model is a duration model that takes as input a vector describing the linguistic characteristics for each phoneme in a similar way to the above Merlin toolkit and predicts the number of acoustic frames required for that phone. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013434886932373047}, "created": {"value": false, "score": 0.0002484917640686035}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999902248382568}, "created": {"value": false, "score": 0.0002484917640686035}, "shared": {"value": false, "score": 2.6226043701171875e-06}}, "references": [{"label": "[21]", "normalizedForm": "[21]", "refKey": 21}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Tacotron", "normalizedForm": "Tacotron", "offsetStart": 194, "offsetEnd": 202}, "context": "The ASVspoof 2019 database of bona fide and spoofed speech signals includes synthetic speech and converted voice signals generated with the very latest, state-of-the-art technologies, including Tacotron2 [9] and WaveNet [10].", "mentionContextAttributes": {"used": {"value": false, "score": 0.008141100406646729}, "created": {"value": false, "score": 5.269050598144531e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9, "offsetStart": 4864, "offsetEnd": 4867}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveRNN", "normalizedForm": "WaveRNN", "offsetStart": 202, "offsetEnd": 209}, "context": "We can also see that the spoofed data from A11 was much more easily detected in the human assessment, even though A11 used the same TTS architecture as A10, except that A11 and A10 used Griffin-Lim and WaveRNN for waveform generation, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990884065628052}, "created": {"value": false, "score": 1.2159347534179688e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999058246612549}, "created": {"value": false, "score": 4.4226646423339844e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WaveNet", "normalizedForm": "WaveNet", "offsetStart": 212, "offsetEnd": 219}, "context": "The ASVspoof 2019 database of bona fide and spoofed speech signals includes synthetic speech and converted voice signals generated with the very latest, state-of-the-art technologies, including Tacotron2 [9] and WaveNet [10].", "mentionContextAttributes": {"used": {"value": false, "score": 0.008141100406646729}, "created": {"value": false, "score": 5.269050598144531e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999643564224243}, "created": {"value": false, "score": 0.0002568364143371582}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[10]", "normalizedForm": "[10]", "refKey": 10, "offsetStart": 4880, "offsetEnd": 4884}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Tacotron", "normalizedForm": "Tacotron", "offsetStart": 246, "offsetEnd": 254}, "context": "On top of that, a speaker encoder separately trained for a speaker verification task [33] is used for encoding a few seconds of audio clips for a target speaker into a fixed dimensional speaker embedding, which is used as a condition in the base Tacotron 2 model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 3.24249267578125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.45921218395233154}, "created": {"value": false, "score": 0.0027503371238708496}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[9]", "normalizedForm": "[9]", "refKey": 9}]}], "references": [{"refKey": 10, "tei": "<biblStruct xml:id=\"b10\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">V D</forename><surname>Oord</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">S</forename><surname>Dieleman</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">H</forename><surname>Zen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename><surname>Simonyan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">O</forename><surname>Vinyals</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Graves</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">N</forename><surname>Kalchbrenner</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Senior</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">K</forename><surname>Kavukcuoglu</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:1609.03499</idno>\n\t\t<title level=\"m\">Wavenet: A generative model for raw audio</title>\n\t\t<imprint/>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 9, "tei": "<biblStruct xml:id=\"b9\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jonathan</forename><surname>Shen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ruoming</forename><surname>Pang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ron</forename><forename type=\"middle\">J</forename><surname>Weiss</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mike</forename><surname>Schuster</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Navdeep</forename><surname>Jaitly</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zongheng</forename><surname>Yang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zhifeng</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yu</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yuxuan</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rj</forename><surname>Skerrv-Ryan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rif</forename><forename type=\"middle\">A</forename><surname>Saurous</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yannis</forename><surname>Agiomvrgiannakis</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yonghui</forename><surname>Wu</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2018.8461368</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2018-04\">2018</date>\n\t\t\t<biblScope unit=\"page\">4783</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 31, "tei": "<biblStruct xml:id=\"b31\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Vocaine the vocoder and applications in speech synthesis</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yannis</forename><surname>Agiomyrgiannakis</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2015.7178768</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2015-04\">2015. 2015</date>\n\t\t\t<biblScope unit=\"volume\">6</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"4230\" to=\"4234\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 21, "tei": "<biblStruct xml:id=\"b21\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Merlin: An Open Source Neural Network Speech Synthesis System</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zhizheng</forename><surname>Wu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Oliver</forename><surname>Watts</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simon</forename><surname>King</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.21437/ssw.2016-33</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">9th ISCA Workshop on Speech Synthesis Workshop (SSW 9)</title>\n\t\t<imprint>\n\t\t\t<publisher>ISCA</publisher>\n\t\t\t<date type=\"published\" when=\"2016-09-13\">2016</date>\n\t\t\t<biblScope unit=\"page\" from=\"202\" to=\"207\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 15909, "id": "8ec6f61a4c0316312cd56acc47fef00dee97d06e", "metadata": {"id": "8ec6f61a4c0316312cd56acc47fef00dee97d06e"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02945493.grobid.tei.xml", "file_name": "hal-02945493.grobid.tei.xml"}