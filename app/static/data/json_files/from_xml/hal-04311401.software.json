{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:39+0000", "md5": "A180DAFAAA7E589C438CA0F33376195F", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 0, "offsetEnd": 7}, "context": "ChatGPT: Certainly!", "mentionContextAttributes": {"used": {"value": false, "score": 0.05185294151306152}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 18, "offsetEnd": 25}, "context": "Overall, we asked ChatGPT to provide 3000 additional lines of code-comment data split equally between Useful and Not Useful.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9872952103614807}, "created": {"value": false, "score": 0.0020003914833068848}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 23, "offsetEnd": 31}, "context": "Additionally, we asked ChatGPT1 to label each code-comment pair with the corresponding class (Useful or Not Useful). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996951818466187}, "created": {"value": false, "score": 0.0015478134155273438}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 29, "offsetEnd": 36}, "context": "In our experiments, we chose ChatGPT as our LLM and prompted it to generate data that aligns with the criteria of the given dataset, i.e., the generated code snippets should be written in the C programming language and the corresponding comments should be a mixture of useful and not useful. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.19775724411010742}, "created": {"value": false, "score": 0.3704036474227905}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "component", "software-name": {"rawForm": "scikit-learn", "normalizedForm": "scikit-learn", "offsetStart": 37, "offsetEnd": 50}, "language": {"rawForm": "Python", "normalizedForm": "Python", "wikidataId": "Q28865", "offsetStart": 62, "offsetEnd": 68}, "context": "All models are implemented using the scikit-learn2 package in Python.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0631590485572815}, "created": {"value": false, "score": 0.06674998998641968}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0631590485572815}, "created": {"value": false, "score": 0.06674998998641968}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 48, "offsetEnd": 55}, "context": "Additionally, we've attempted to retro-engineer ChatGPT to explain the process of its generated data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0037650465965270996}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 50, "offsetEnd": 57}, "context": "In the seed + LLM data run, the data generated by ChatGPT is added to the seed data and the resulting augmented dataset is used as the input for our models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.40202903747558594}, "created": {"value": false, "score": 7.081031799316406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 53, "offsetEnd": 60}, "context": "This section presents the ablation study done on the ChatGPT prompt to understand its inherent data generation mechanisms.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6561113595962524}, "created": {"value": false, "score": 0.316222608089447}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hugging Face", "normalizedForm": "Hugging Face", "offsetStart": 93, "offsetEnd": 105}, "context": "We use the flax-sentence-embeddings/st-codesearch-distilroberta-base3 model trained with the Hugging Face sentence-transformers4 library on the CodeSearchNet5 dataset compiled from code and documentation strings in the Go, Java, Javascript, PHP, Python and Ruby programming languages [23]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9838841557502747}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9838841557502747}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GeForce", "normalizedForm": "GeForce", "offsetStart": 114, "offsetEnd": 121}, "context": "All experiments are performed on a Dell G15 Special Edition 5521 hardware with 14 CPU Cores, 32 GB RAM and NVIDIA GeForce RTX 3070 Ti GPU.", "mentionContextAttributes": {"used": {"value": true, "score": 0.992195725440979}, "created": {"value": false, "score": 5.447864532470703e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.992195725440979}, "created": {"value": false, "score": 5.447864532470703e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CodeBERT", "normalizedForm": "CodeBERT", "offsetStart": 131, "offsetEnd": 139}, "context": "Das and Chatterjee [17] studied the performance of deep learning models by proposing a fusion transformer system based on BERT and CodeBERT. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011183619499206543}, "created": {"value": false, "score": 0.0016636252403259277}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.011183619499206543}, "created": {"value": false, "score": 0.0016636252403259277}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 136, "offsetEnd": 143}, "context": "Using this method, we were able to generate 421 new code-comment pairs with 411 being labeled as Useful and 10 labeled as Not Useful by ChatGPT. Figure 2 shows an example output from ChatGPT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": false, "score": 3.695487976074219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CodeSearchNet", "normalizedForm": "CodeSearchNet", "offsetStart": 144, "offsetEnd": 158}, "context": "We use the flax-sentence-embeddings/st-codesearch-distilroberta-base3 model trained with the Hugging Face sentence-transformers4 library on the CodeSearchNet5 dataset compiled from code and documentation strings in the Go, Java, Javascript, PHP, Python and Ruby programming languages [23]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9838841557502747}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9838841557502747}, "created": {"value": false, "score": 6.794929504394531e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 146, "offsetEnd": 153}, "context": "Having balanced both classes in our experiments allows us to have a better baseline when measuring the impact of the additional data generated by ChatGPT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9947214126586914}, "created": {"value": false, "score": 0.007822930812835693}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChatGPT", "normalizedForm": "ChatGPT", "offsetStart": 183, "offsetEnd": 190}, "context": "Using this method, we were able to generate 421 new code-comment pairs with 411 being labeled as Useful and 10 labeled as Not Useful by ChatGPT. Figure 2 shows an example output from ChatGPT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": false, "score": 3.695487976074219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998910427093506}, "created": {"value": true, "score": 0.9996905326843262}, "shared": {"value": false, "score": 7.152557373046875e-07}}}], "references": [], "runtime": 2740, "id": "6e51f5e153dac90407da740f04a6a25aa2d841fe", "metadata": {"id": "6e51f5e153dac90407da740f04a6a25aa2d841fe"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04311401.grobid.tei.xml", "file_name": "hal-04311401.grobid.tei.xml"}