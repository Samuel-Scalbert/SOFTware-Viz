{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:56+0000", "md5": "A4A69AC45186A016BD99DF3E131AB2C1", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "ElectraForTokenClassification", "normalizedForm": "ElectraForTokenClassification", "offsetStart": 0, "offsetEnd": 29}, "context": "ElectraForTokenClassification relies on a novel pre-training method called \"discriminative pre-training,\" where a generator and a discriminator are trained to enhance the quality of the learned representations. ", "mentionContextAttributes": {"used": {"value": false, "score": 5.7220458984375e-05}, "created": {"value": false, "score": 0.0006188154220581055}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.7220458984375e-05}, "created": {"value": false, "score": 0.0006188154220581055}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Py-Torch", "normalizedForm": "Py-Torch", "offsetStart": 7, "offsetEnd": 15}, "version": {"rawForm": "1.7.0", "normalizedForm": "1.7.0", "offsetStart": 16, "offsetEnd": 21}, "context": "and on Py-Torch 1.7.0. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998185038566589}, "created": {"value": false, "score": 1.7523765563964844e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998185038566589}, "created": {"value": false, "score": 1.7523765563964844e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Adam", "normalizedForm": "Adam", "offsetStart": 16, "offsetEnd": 20}, "context": "All models used Adam optimizer with default PyTorch parameters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954575300216675}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9954575300216675}, "created": {"value": false, "score": 1.0609626770019531e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Adam", "normalizedForm": "Adam", "offsetStart": 23, "offsetEnd": 27}, "context": "All models utilize the Adam optimizer, with a gradient clipping set to 10, a dropout of 0.1, a learning rate of 4e-05 and a training batch size of 8 and a test batch size of 4. The training process consists of 4 epochs, during which the models are fine-tuned and optimized.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3928471803665161}, "created": {"value": false, "score": 1.0609626770019531e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9954575300216675}, "created": {"value": false, "score": 1.0609626770019531e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuggingFace 6", "normalizedForm": "HuggingFace 6", "offsetStart": 32, "offsetEnd": 45}, "version": {"rawForm": "4.30.", "normalizedForm": "4.30", "offsetStart": 54, "offsetEnd": 59}, "context": "The implementation was based on HuggingFace 6 version 4.30. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.998625636100769}, "created": {"value": false, "score": 7.18832015991211e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.998625636100769}, "created": {"value": false, "score": 7.18832015991211e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "spaCy  library", "normalizedForm": "spaCy library", "offsetStart": 37, "offsetEnd": 51}, "context": "The PoS tags were obtained using the spaCy8 library. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999920129776001}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 44, "offsetEnd": 51}, "context": "All models used Adam optimizer with default PyTorch parameters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9954575300216675}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9954575300216675}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argotario", "normalizedForm": "Argotario", "offsetStart": 112, "offsetEnd": 121}, "context": "The results obtained using their T5-large model yielded F1 scores of 41% for Propaganda, 62% for Logic, 59% for Argotario, 26% for Covid-19, and 17% for Climate, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999847412109375}, "created": {"value": false, "score": 1.4901161193847656e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999847412109375}, "created": {"value": false, "score": 0.49546492099761963}, "shared": {"value": false, "score": 0.004216670989990234}}, "references": [{"label": "(Habernal et al., 2017)", "normalizedForm": "Habernal et al., 2017", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argotario", "normalizedForm": "Argotario", "offsetStart": 122, "offsetEnd": 131}, "context": "For instance, Habernal et al. (2017) aimed to improve fallacy detection by creating a publicly available software called \"Argotario\". ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016963481903076172}, "created": {"value": false, "score": 0.49546492099761963}, "shared": {"value": false, "score": 0.004216670989990234}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999847412109375}, "created": {"value": false, "score": 0.49546492099761963}, "shared": {"value": false, "score": 0.004216670989990234}}, "references": [{"label": "(Habernal et al., 2017)", "normalizedForm": "Habernal et al., 2017", "refKey": 10}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Argotario", "normalizedForm": "Argotario", "offsetStart": 149, "offsetEnd": 158}, "context": "This methodology involved leveraging multiple fallacy-based datasets, including Propaganda (Da San Martino et al., 2019b), Logic (Jin et al., 2022), Argotario (Habernal et al., 2017), Covid-19 (Musi et al., 2022), and Climate (Jin et al., 2022).", "mentionContextAttributes": {"used": {"value": true, "score": 0.922663152217865}, "created": {"value": false, "score": 0.0003948807716369629}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999847412109375}, "created": {"value": false, "score": 0.49546492099761963}, "shared": {"value": false, "score": 0.004216670989990234}}, "references": [{"label": "(Habernal et al., 2017)", "normalizedForm": "Habernal et al., 2017", "refKey": 10, "offsetStart": 9012, "offsetEnd": 9035}]}], "references": [{"refKey": 10, "tei": "<biblStruct xml:id=\"b10\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Argotario: Computational Argumentation Meets Serious Games</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ivan</forename><surname>Habernal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Raffael</forename><surname>Hannemann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christian</forename><surname>Pollak</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><surname>Klamm</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Patrick</forename><surname>Pauli</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Iryna</forename><surname>Gurevych</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/d17-2002</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>\n\t\t<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n\t\t\t<biblScope unit=\"page\" from=\"7\" to=\"12\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10181, "id": "aeb486188b8d0243664fb952d5352b7dff48da49", "metadata": {"id": "aeb486188b8d0243664fb952d5352b7dff48da49"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04260221.grobid.tei.xml", "file_name": "hal-04260221.grobid.tei.xml"}