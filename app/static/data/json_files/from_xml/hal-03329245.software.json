{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:05+0000", "md5": "E0E1248C80A85D08B55CC6F3524779E5", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 0, "offsetEnd": 6}, "context": "HuBERT with 50 units reaches the best MUSHRA score while its bitrate is only 365bps, which is significantly lower than the baseline methods.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006544172763824463}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MUSHRA", "normalizedForm": "MUSHRA", "offsetStart": 3, "offsetEnd": 9}, "context": "In MUSHRA evaluations, listeners are presented with a labeled uncompressed signal for reference, a set of test samples to rate, a copy of the uncompressed reference, and a low-quality anchor.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010861456394195557}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 3, "offsetEnd": 12}, "context": "In HuBERT [4], the model is trained with a masked prediction task similar to BERT [14] but with masked continuous audio signals.", "mentionContextAttributes": {"used": {"value": false, "score": 0.015780866146087646}, "created": {"value": false, "score": 4.017353057861328e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 4, "offsetEnd": 10}, "context": "For HuBERT we used a BASE 12 transformerlayer model trained for two iterations [4] on 960 hours of Lib-riSpeech corpus [46].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999009370803833}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MUSHRA", "normalizedForm": "MUSHRA", "offsetStart": 10, "offsetEnd": 16}, "context": "Figure 2: MUSHRA subjective quality results as a function of bitrate per second. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998557567596436}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 12, "offsetEnd": 18}, "context": "For CPC and HuBERT, the k-means algorithm is trained on LibriSpeech clean-100h [46] dataset to convert continuous frames to discrete codes.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7175366282463074}, "created": {"value": false, "score": 5.459785461425781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiFiGAN", "normalizedForm": "HiFiGAN", "offsetStart": 17, "offsetEnd": 24}, "context": "Finally, we used HiFiGAN (architecture and objective) as the decoder instead of a simple convolutional decoder, as it improved the overall audio quality. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9978072047233582}, "created": {"value": false, "score": 0.0004603862762451172}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9978072047233582}, "created": {"value": false, "score": 0.0004603862762451172}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MUSHRA", "normalizedForm": "MUSHRA", "offsetStart": 20, "offsetEnd": 26}, "context": "We use a subjective MUSHRA-type listening test [51] to measure the perceived quality of the proposed speech codec with regard to its bitrate constraints.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 7.3909759521484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 21, "offsetEnd": 27}, "context": "For this experiment, HuBERT models with 50, 100, and 200 units were trained as described in Sec. 4. For comparison, we included other speech codecs in our evaluation: Opus [36] wideband at 9 kbps VBR, Codec2 [52] at 2.4 kbps and LPC-Net [32] operating at 1.6 kbps.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 2.1457672119140625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 22, "offsetEnd": 28}, "context": "Finally, we adapt the HuBERT speech representation as an ultra lightweight speech codec, providing superior subjective results than the baselines with lower bitrate.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00035858154296875}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HiFiGAN", "normalizedForm": "HiFiGAN", "offsetStart": 29, "offsetEnd": 36}, "context": "The VQ-VAE model employs the HiFiGAN decoder trained on the LibriLight dataset to match the amount of data reported in [34]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07278949022293091}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9978072047233582}, "created": {"value": false, "score": 0.0004603862762451172}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Speex", "normalizedForm": "Speex", "offsetStart": 37, "offsetEnd": 47}, "context": "We compressed the anchor sample with Speex [53] at 4 kbps as a low anchor. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MUSHRA", "normalizedForm": "MUSHRA", "offsetStart": 38, "offsetEnd": 44}, "context": "HuBERT with 50 units reaches the best MUSHRA score while its bitrate is only 365bps, which is significantly lower than the baseline methods.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006544172763824463}, "created": {"value": false, "score": 5.364418029785156e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 45, "offsetEnd": 51}, "context": "Since the representations learned by CPC and HuBERT are continuous, a k-means algorithm is applied over the models' outputs to generate discrete units, denoted as zc = (z1, . . .", "mentionContextAttributes": {"used": {"value": true, "score": 0.994607150554657}, "created": {"value": false, "score": 1.8835067749023438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 54, "offsetEnd": 60}, "context": "Leading to a bitrate of 700bps for CPC and 350bps for HuBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998979568481445}, "created": {"value": false, "score": 9.298324584960938e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 56, "offsetEnd": 62}, "context": "Unlike resynthesis results, on voice conversion CPC and HuBERT outperform VQ-VAE on both LJ and VCTK datasets, indicating VQ-VAE contains more information about the speaker in the encoded units, hence producing more artifacts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1680760383605957}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 65, "offsetEnd": 71}, "context": "When considering the intelligibility of the reconstructed signal HuBERT reaches the lowest PER and WER scores across all models, where both CPC and HuBERT are superior to VQ-VAE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0112837553024292}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 68, "offsetEnd": 74}, "context": "However, when considering F0 reconstruction VQ-VAE outperforms both HuBERT and CPC by a significant margin.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021857023239135742}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 148, "offsetEnd": 154}, "context": "For example, learning speech recognition with only 10 minutes of transcribed speech and 53K hours of untranscribed speech as in wav2vec 2.0 [3] and HuBERT [4].", "mentionContextAttributes": {"used": {"value": false, "score": 0.12068748474121094}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4, "offsetStart": 1714, "offsetEnd": 1717}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 148, "offsetEnd": 154}, "context": "When considering the intelligibility of the reconstructed signal HuBERT reaches the lowest PER and WER scores across all models, where both CPC and HuBERT are superior to VQ-VAE.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0112837553024292}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 169, "offsetEnd": 175}, "context": "Notice VQ-VAE can still reconstruct the F0 almost at the same level as when using the original F0 as conditioning (5.2 vs 7.03, and 5.59 vs 7.8), in contrast to CPC and HuBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007829666137695312}, "created": {"value": false, "score": 2.110004425048828e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 222, "offsetEnd": 232}, "context": "Specifically, we experimented with: (i) CPC [1] which attempts to predict the future states of the encoder based on the past and optimizes a contrastive loss comparing the actual future from that of random sequences; (ii) HuBERT [4] which was trained with a masked prediction task similar to BERT [14] on masked continuous audio signals as inputs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9022477865219116}, "created": {"value": false, "score": 1.5854835510253906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999219179153442}, "created": {"value": false, "score": 0.3636000156402588}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "[4]", "normalizedForm": "[4]", "refKey": 4}]}], "references": [{"refKey": 4, "tei": "<biblStruct xml:id=\"b4\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Hubert: How Much Can a Bad Teacher Benefit ASR Pre-Training?</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Wei-Ning</forename><surname>Hsu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yao-Hung Hubert</forename><surname>Tsai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Benjamin</forename><surname>Bolte</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ruslan</forename><surname>Salakhutdinov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Abdelrahman</forename><surname>Mohamed</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp39728.2021.9414460</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2021-06-06\">2020</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 8469, "id": "c5590ae4c7541d8c25cd619b4606c1315332fba7", "metadata": {"id": "c5590ae4c7541d8c25cd619b4606c1315332fba7"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03329245.grobid.tei.xml", "file_name": "hal-03329245.grobid.tei.xml"}