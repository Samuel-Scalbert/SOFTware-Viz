{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:36+0000", "md5": "D9E8562594FEDEB01D66CB2C8624785F", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 7, "offsetEnd": 36}, "context": "We use PyTorch (Paszke et al., 2019) and the pre-trained BERT model (Devlin et al., 2019;Wolf et al., 2020). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9909543395042419}, "created": {"value": false, "score": 0.0001537799835205078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909543395042419}, "created": {"value": false, "score": 0.0001537799835205078}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mechanical Turk", "normalizedForm": "Mechanical Turk", "offsetStart": 15, "offsetEnd": 30}, "publisher": {"rawForm": "Amazon", "normalizedForm": "Amazon", "offsetStart": 8, "offsetEnd": 14}, "context": "We used Amazon Mechanical Turk to create our annotated dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99968421459198}, "created": {"value": false, "score": 0.017875313758850098}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99968421459198}, "created": {"value": false, "score": 0.017875313758850098}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}], "references": [], "runtime": 4072, "id": "b6799bb00ade389e4d8f043bbb23fbc5ecc2a277", "metadata": {"id": "b6799bb00ade389e4d8f043bbb23fbc5ecc2a277"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03351649.grobid.tei.xml", "file_name": "hal-03351649.grobid.tei.xml"}