{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:49+0000", "md5": "780D243B486B7C626C5347EE161C1D30", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo in particular uses a biLM consisting of LSTM layers, that is, it concatenates both a forward and a backward language model generating a contextualized bi-directional representation of each token in a given sentence.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00040727853775024414}, "created": {"value": false, "score": 2.4557113647460938e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo CBT shows a very interesting pattern of results. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005202889442443848}, "created": {"value": false, "score": 1.3589859008789062e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo CaBeRnet and ELMo OSCAR+CaBeRnet set new state-of-the art results that are superior than those obtained with a 30 times larger corpus, respectively on POS-tagging and NER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.996921956539154}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo OSCAR+CaBeRnet (see Results Table 7).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8882221579551697}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo CaBeRnet : Spoken a test for balance ELMo CaBeRnet offers representation that are not only competitive but sometimes better than Wikipedia especially considering that the majority of evaluation tree-banks are built on Wikipedia data.", "mentionContextAttributes": {"used": {"value": false, "score": 4.863739013671875e-05}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo CaBeRnet shows a clear effect of balance when tested upon a purely spoken test-set like the Spoken tree-bank.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015838146209716797}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 0, "offsetEnd": 4}, "context": "ELMo CBT also features oral dialogues in youth literature but does not show the same results because of the lack of variety of genres, thus demonstrating again the advantage of a comprehensive coverage of language use.", "mentionContextAttributes": {"used": {"value": false, "score": 9.500980377197266e-05}, "created": {"value": false, "score": 4.112720489501953e-05}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 0, "offsetEnd": 8}, "context": "CaBeRnet corpus is meant to parallel COCA corpus2 , which contains more than 560 million words of text (20 million words each year 1990-2017) and is equally divided among spoken, fiction, popular magazines, newspapers, and academic texts (Davies, 2008).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0025136470794677734}, "created": {"value": false, "score": 8.130073547363281e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 0, "offsetEnd": 8}, "context": "CaBeRnet was obtained by compiling both existing datasets and web text from different sources (see Metadata -Lists), evenly divided (\u223c120 million words each) into spoken, fiction, magazine, newspaper, academic to achieve genre-balanced between oral and written modality in newspapers or popular written style, technical reports and Wikipedia entries, fiction, literature or academic written production).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996241331100464}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe Future", "normalizedForm": "UDPipe Future", "offsetStart": 0, "offsetEnd": 13}, "context": "UDPipe Future provides us a strong baseline that does not make use of any pre-trained contextual embedding.", "mentionContextAttributes": {"used": {"value": false, "score": 4.100799560546875e-05}, "created": {"value": false, "score": 0.0003567934036254883}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9856025576591492}, "created": {"value": false, "score": 0.12486428022384644}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 4, "offsetEnd": 10}, "context": "The UDPipe Future architecture is a multi-task model that predicts POS tags, lemmas and dependency trees jointly. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.470348358154297e-05}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": true, "score": 0.972320556640625}}, "references": [{"label": "(Straka, 2018)", "normalizedForm": "Straka, 2018", "refKey": 50}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 5, "offsetEnd": 13}, "context": "ELMo CaBeRnet and ELMo OSCAR+CaBeRnet set new state-of-the art results that are superior than those obtained with a 30 times larger corpus, respectively on POS-tagging and NER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.996921956539154}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 5, "offsetEnd": 13}, "context": "ELMo CaBeRnet : Spoken a test for balance ELMo CaBeRnet offers representation that are not only competitive but sometimes better than Wikipedia especially considering that the majority of evaluation tree-banks are built on Wikipedia data.", "mentionContextAttributes": {"used": {"value": false, "score": 4.863739013671875e-05}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 5, "offsetEnd": 13}, "context": "ELMo CaBeRnet shows a clear effect of balance when tested upon a purely spoken test-set like the Spoken tree-bank.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0015838146209716797}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "+CaBeRnet", "normalizedForm": "+CaBeRnet", "offsetStart": 10, "offsetEnd": 19}, "context": "ELMo OSCAR+CaBeRnet (see Results Table 7).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8882221579551697}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 11, "offsetEnd": 15}, "context": "For Spoken ELMo CaBeRnet is reaching state-of-the-are results in POS-tagging on this oral specialized tree-bank (see dark gray highlight on Table 7.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022769570350646973}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 13, "offsetEnd": 19}, "context": "By adding to UDPipe Future 5 differently trained ELMo language model that were pre-trained on qualitatively and quantitatively different corpora, our French Balanced Reference Corpus CaBeRnet shows on three different downstream tasks for French (POS-tagging, dependency parsing, named-entity recognition), achieves to improve the stateof-the-art for POS-tagging over previous monolingual and multilingual approaches.", "mentionContextAttributes": {"used": {"value": true, "score": 0.880810558795929}, "created": {"value": false, "score": 0.00012969970703125}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": true, "score": 0.972320556640625}}, "references": [{"label": "(Straka, 2018)", "normalizedForm": "Straka, 2018", "refKey": 50}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeTagger", "normalizedForm": "TreeTagger", "offsetStart": 14, "offsetEnd": 24}, "context": "\u02dcschmid/tools/TreeTagger/ data/french-tagset.html", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002689957618713379}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 0.013355672359466553}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999933242797852}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 0.013355672359466553}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 16, "offsetEnd": 24}, "context": "For Spoken ELMo CaBeRnet is reaching state-of-the-are results in POS-tagging on this oral specialized tree-bank (see dark gray highlight on Table 7.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022769570350646973}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 17, "offsetEnd": 25}, "context": "Fine-tuning with CaBeRnet has a second effect on recall, we understand this slight drop as possibly due to unlearning of the wide spectrum of vocabulary that is in OSCAR and not in CaBeRnet. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.18198031187057495}, "created": {"value": false, "score": 1.9431114196777344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 18, "offsetEnd": 22}, "context": "ELMo CaBeRnet and ELMo OSCAR+CaBeRnet set new state-of-the art results that are superior than those obtained with a 30 times larger corpus, respectively on POS-tagging and NER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.996921956539154}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 24, "offsetEnd": 33}, "context": "It performs better than CamemBERT which was the previous the state of the art on Spoken.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0029668807983398438}, "created": {"value": false, "score": 3.3974647521972656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 25, "offsetEnd": 29}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7538247108459473}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe Future", "normalizedForm": "UDPipe Future", "offsetStart": 25, "offsetEnd": 38}, "context": "In other words we add to UDPipe Future, five differently trained ELMo language model pre-trained on the qualitatively and quantitatively different corpora under comparison. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9856025576591492}, "created": {"value": false, "score": 0.12486428022384644}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9856025576591492}, "created": {"value": false, "score": 0.12486428022384644}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 26, "offsetEnd": 30}, "context": "These results demonstrate ELMo CBT contribution in generating representations that are useful to UDPipe model to achieve better results in POS-tagging and dependency parsing tasks on the ParTUT treebank. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 1.3947486877441406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 26, "offsetEnd": 35}, "context": "(CRF and Bi-LSTM+CRF) and CamemBERT, which is currently stateof-the-art. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002310037612915039}, "created": {"value": false, "score": 0.0006978511810302734}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 27, "offsetEnd": 35}, "context": "All in all, we showed that CaBeRnet corpus can reliably be used as a basis for training neural language models that perform in down-stream tasks, as well as suited for the creation of balanced lexical frequency-based dictionary entries, grammar studies, other language reference materials.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003292560577392578}, "created": {"value": true, "score": 0.7819876074790955}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 29, "offsetEnd": 37}, "context": "ELMo CaBeRnet and ELMo OSCAR+CaBeRnet set new state-of-the art results that are superior than those obtained with a 30 times larger corpus, respectively on POS-tagging and NER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.996921956539154}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TreeTagger", "normalizedForm": "TreeTagger", "offsetStart": 29, "offsetEnd": 39}, "context": "For this purpose we used the TreeTagger.7 .", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999933242797852}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999933242797852}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 0.013355672359466553}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 32, "offsetEnd": 40}, "context": "At the time being, this part of CaBeRnet corpus is still subject to Licence restrictions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0037322640419006348}, "created": {"value": false, "score": 0.00024014711380004883}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 33, "offsetEnd": 37}, "context": "Embeddings from Language Models (ELMo) (Peters et al., 2018) is a neurla Language Model, that is, a model that given a sequence of N input tokens, (t 1 , t 2 , ..., t N ), computes the probability of the sequence by modeling the probability of token t k given the history (t 1 , ..., t k-1 ):", "mentionContextAttributes": {"used": {"value": false, "score": 0.008340299129486084}, "created": {"value": false, "score": 1.609325408935547e-05}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018", "normalizedForm": "(Peters et al., 2018", "refKey": 36, "offsetStart": 12566, "offsetEnd": 12586}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 33, "offsetEnd": 39}, "context": "Finally, we compare our model to UDPipe Future (Straka, 2018), a model ranked 3rd in dependency parsing and 6th in POS-tagging during the CoNLL 2018 shared task (Seker et al., 2018). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8687434196472168}, "created": {"value": false, "score": 0.0008932948112487793}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": true, "score": 0.972320556640625}}, "references": [{"label": "(Straka, 2018)", "normalizedForm": "Straka, 2018", "refKey": 50, "offsetStart": 17961, "offsetEnd": 17975}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 33, "offsetEnd": 39}, "context": "https://github.com/CoNLL-UD-2018/UDPipe-Future", "mentionContextAttributes": {"used": {"value": false, "score": 0.00028318166732788086}, "created": {"value": false, "score": 4.684925079345703e-05}, "shared": {"value": true, "score": 0.972320556640625}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": true, "score": 0.972320556640625}}, "references": [{"label": "(Straka, 2018)", "normalizedForm": "Straka, 2018", "refKey": 50}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 34, "offsetEnd": 42}, "context": "The characteristics of CBT-fr and CaBeRnet are compared to the other corpora under analysis (OSCAR-fr, Wiki-fr) are to be found in this section.", "mentionContextAttributes": {"used": {"value": true, "score": 0.988129198551178}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 35, "offsetEnd": 39}, "context": "Importantly, LSTM-CRF + FastText + ELMo CaBeRnet reaches better results in finding entity mentions, than Wikipedia which is a highly specialized corpus in terms of vocabulary variety and size, as can be seen in the overwhelming total number of forms reported in Table 5.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023537874221801758}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 36, "offsetEnd": 44}, "context": "We see that for GSD and Sequoia the CaBeRnet finetuned version ELMo OSCAR+CaBeRnet compared to the pure Oscar pre-trained ELMo OSCAR is achieving higher scores. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3809664249420166}, "created": {"value": false, "score": 2.9206275939941406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 38, "offsetEnd": 46}, "context": "We can conclude that fine-tuning with CaBeRnet on ELMo OSCAR generates better word-embedding representations than Wikipedia in this task. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018590688705444336}, "created": {"value": false, "score": 6.437301635742188e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 38, "offsetEnd": 47}, "context": "It is relevant to compare our results CamemBERT on those tasks because compared to UDify is the work that pushed the furthest the performance in fine-tuning endto-end a BERT-based model on downstream POS-tagging and dependency parsing.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961212277412415}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 39, "offsetEnd": 47}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7538247108459473}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 40, "offsetEnd": 44}, "context": "As is was done for the original English ELMo (Peters et al., 2018).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5368555188179016}, "created": {"value": false, "score": 0.0022501349449157715}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36, "offsetStart": 13169, "offsetEnd": 13190}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 40, "offsetEnd": 48}, "context": "Importantly, LSTM-CRF + FastText + ELMo CaBeRnet reaches better results in finding entity mentions, than Wikipedia which is a highly specialized corpus in terms of vocabulary variety and size, as can be seen in the overwhelming total number of forms reported in Table 5. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023537874221801758}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 41, "offsetEnd": 49}, "context": "The achievement of linguistic balance in CaBeRnet is detailed in section 2.1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004834175109863281}, "created": {"value": false, "score": 4.696846008300781e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 42, "offsetEnd": 46}, "context": "It is namely for this reason, we selected ELMo which not only performs generally better on sequence tagging than other architectures, but is also better suited to pre-train on small corpora because of its inferior rage of parameter (93.6 million) compared to RoBERTa-base architecture used for CamBERT (BERTbase, 12,110 million -Transformer).", "mentionContextAttributes": {"used": {"value": false, "score": 0.18113571405410767}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 42, "offsetEnd": 46}, "context": "ELMo CaBeRnet : Spoken a test for balance ELMo CaBeRnet offers representation that are not only competitive but sometimes better than Wikipedia especially considering that the majority of evaluation tree-banks are built on Wikipedia data.", "mentionContextAttributes": {"used": {"value": false, "score": 4.863739013671875e-05}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 45, "offsetEnd": 53}, "context": "Additionally, we also test the impact of the CaBeRnet Corpus on ELMo fine-tuning.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999363362789154}, "created": {"value": false, "score": 0.03333151340484619}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 47, "offsetEnd": 55}, "context": "ELMo CaBeRnet : Spoken a test for balance ELMo CaBeRnet offers representation that are not only competitive but sometimes better than Wikipedia especially considering that the majority of evaluation tree-banks are built on Wikipedia data.", "mentionContextAttributes": {"used": {"value": false, "score": 4.863739013671875e-05}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 49, "offsetEnd": 53}, "context": "For POS-tagging in GSD and ParTUT the results of ELMo OSCAR and ELMo OSCAR+CaBeRnet are in second place position compared to ELMo Wikipedia, but are still ex-tremely close. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 49, "offsetEnd": 53}, "context": "By adding to UDPipe Future 5 differently trained ELMo language model that were pre-trained on qualitatively and quantitatively different corpora, our French Balanced Reference Corpus CaBeRnet shows on three different downstream tasks for French (POS-tagging, dependency parsing, named-entity recognition), achieves to improve the stateof-the-art for POS-tagging over previous monolingual and multilingual approaches.", "mentionContextAttributes": {"used": {"value": true, "score": 0.880810558795929}, "created": {"value": false, "score": 0.00012969970703125}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 50, "offsetEnd": 54}, "context": "We can conclude that fine-tuning with CaBeRnet on ELMo OSCAR generates better word-embedding representations than Wikipedia in this task.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018590688705444336}, "created": {"value": false, "score": 6.437301635742188e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 51, "offsetEnd": 59}, "context": "It goes without saying that a balanced corpus like CaBeRnet will be useful to calculate stable lexical frequency measures, like association measures and grant their comparability cross-linguistic comparability with English. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.993511199951172e-05}, "created": {"value": false, "score": 0.0001888871192932129}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 51, "offsetEnd": 60}, "context": "Overall, NER scores shows improvements compared to CamemBERT. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 54, "offsetEnd": 58}, "context": "Corpus balance shows to be a significant predictor of ELMo's accuracy on Spoken test data-set and for NER tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3546938896179199}, "created": {"value": false, "score": 3.6835670471191406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo OSCAR+CaBeRnet", "normalizedForm": "ELMo OSCAR+CaBeRnet", "offsetStart": 63, "offsetEnd": 82}, "context": "We see that for GSD and Sequoia the CaBeRnet finetuned version ELMo OSCAR+CaBeRnet compared to the pure Oscar pre-trained ELMo OSCAR is achieving higher scores. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3809664249420166}, "created": {"value": false, "score": 2.9206275939941406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.3809664249420166}, "created": {"value": false, "score": 2.9206275939941406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 64, "offsetEnd": 68}, "context": "For POS-tagging in GSD and ParTUT the results of ELMo OSCAR and ELMo OSCAR+CaBeRnet are in second place position compared to ELMo Wikipedia, but are still ex-tremely close. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 64, "offsetEnd": 68}, "context": "In our effort to evaluate the impact of corpora pre-training on ELMo-based contextualized word-embedding, we introduce here our two terms of comparison, namely the crawled corpus OSCAR-fr and the Wikipedia-fr one.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003609657287597656}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 64, "offsetEnd": 68}, "context": "Additionally, we also test the impact of the CaBeRnet Corpus on ELMo fine-tuning.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999363362789154}, "created": {"value": false, "score": 0.03333151340484619}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FrELMo", "normalizedForm": "FrELMo", "offsetStart": 64, "offsetEnd": 70}, "context": "Resources associated to this paper encompass1 : five version of FrELMo trained on the four corpora presented in this paper and two newly brewed corpora, including a French version of the balanced Corpus of Contemporary American English COCA (Davies, 2008) and one of the Children Book Test CBT (Hill et al., 2015).", "mentionContextAttributes": {"used": {"value": true, "score": 0.5782995223999023}, "created": {"value": false, "score": 5.221366882324219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5782995223999023}, "created": {"value": true, "score": 0.9887887835502625}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 65, "offsetEnd": 69}, "context": "In other words we add to UDPipe Future, five differently trained ELMo language model pre-trained on the qualitatively and quantitatively different corpora under comparison.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9856025576591492}, "created": {"value": false, "score": 0.12486428022384644}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 66, "offsetEnd": 70}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 67, "offsetEnd": 75}, "context": "Table 4 summarises the lexical variety of the five sub-portions of CaBeRnet, respectively taken as representative of Oral, Popular, Fiction, News, and Academic genres.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4976693391799927}, "created": {"value": false, "score": 1.6689300537109375e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 67, "offsetEnd": 75}, "context": "We understand this result as a direct consequence of the fact that CaBeRnet contains a balanced amount of oral language use, which shows to pay off in POS-tagging.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9004718065261841}, "created": {"value": false, "score": 6.330013275146484e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 68, "offsetEnd": 76}, "context": "The construction process of our two newly brewed corpora CBT-fr and CaBeRnet is presented thoroughly in this section that summarises information details that can be found in corpus metadata.", "mentionContextAttributes": {"used": {"value": false, "score": 0.006291031837463379}, "created": {"value": true, "score": 0.9881749153137207}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ElMo", "normalizedForm": "ElMo", "offsetStart": 70, "offsetEnd": 74}, "context": "All in all, our evaluation results confirm the effectiveness of large ElMo-based language models fine-tuned or pre-trained with a balanced and linguistically representative corpus, like CaBeRnetFRanc as opposed to domainspecific ones and extra-large and noisy ones.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9712962508201599}, "created": {"value": false, "score": 0.006760120391845703}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 0.006760120391845703}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 70, "offsetEnd": 74}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7538247108459473}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 70, "offsetEnd": 74}, "context": "The paper investigates the relevance of different types of corpora on ELMo pre-training and fine-tuning, and confirms the effectiveness of pre-trained language models with a balanced and linguistically representative corpus, like CaBeRnetFRanc, on several downstream tasks.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00024074316024780273}, "created": {"value": true, "score": 0.9004117846488953}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 72, "offsetEnd": 80}, "context": "For instance the whole french Wikipedia is included in OSCAR and not in CaBeRnet. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07465386390686035}, "created": {"value": false, "score": 8.845329284667969e-05}, "shared": {"value": false, "score": 3.4809112548828125e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 74, "offsetEnd": 78}, "context": "For named entity recognition, our experiments show that LSTM-CRF+FastText+ELMo OSCAR+CaBeRnet achieves a better precision than the traditional CRF-based SEM architectures described above in Section 4.2.2.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03273063898086548}, "created": {"value": true, "score": 0.7516316771507263}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "+CaBeRnet", "normalizedForm": "+CaBeRnet", "offsetStart": 74, "offsetEnd": 83}, "context": "For POS-tagging in GSD and ParTUT the results of ELMo OSCAR and ELMo OSCAR+CaBeRnet are in second place position compared to ELMo Wikipedia, but are still ex-tremely close. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 80, "offsetEnd": 84}, "context": "This opens a perspective for languages that have a smaller training thesaurus : ELMo could a better suited language model for those languages than it is for others having larger size resources.", "mentionContextAttributes": {"used": {"value": false, "score": 9.226799011230469e-05}, "created": {"value": false, "score": 0.00011551380157470703}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 81, "offsetEnd": 89}, "context": "Importantly, this effect is difficultly explainable by the size of oral style in CaBeRnet, because oral sub-part is only one fifth of the total.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012509822845458984}, "created": {"value": false, "score": 1.919269561767578e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 85, "offsetEnd": 89}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7538247108459473}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 85, "offsetEnd": 93}, "context": "For named entity recognition, our experiments show that LSTM-CRF+FastText+ELMo OSCAR+CaBeRnet achieves a better precision than the traditional CRF-based SEM architectures described above in Section 4.2.2. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03273063898086548}, "created": {"value": true, "score": 0.7516316771507263}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 87, "offsetEnd": 95}, "context": "7, we discover that not only balance, but also the broad and diverse genre converge of CaBeRnet may play a role in its POS-tagging success.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015151500701904297}, "created": {"value": false, "score": 0.17467451095581055}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 88, "offsetEnd": 96}, "context": "We conclude by broadening the discussion with a series of future developments to enrich CaBeRnet and further investigate the benefits of smaller and noiseless corpora in neural NLP research.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002563595771789551}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 93, "offsetEnd": 97}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "+CaBeRnet", "normalizedForm": "+CaBeRnet", "offsetStart": 95, "offsetEnd": 104}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7538247108459473}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "UDPipe", "normalizedForm": "UDPipe", "offsetStart": 97, "offsetEnd": 103}, "context": "These results demonstrate ELMo CBT contribution in generating representations that are useful to UDPipe model to achieve better results in POS-tagging and dependency parsing tasks on the ParTUT treebank.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 1.3947486877441406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": false, "score": 0.24265700578689575}, "shared": {"value": true, "score": 0.972320556640625}}, "references": [{"label": "(Straka, 2018)", "normalizedForm": "Straka, 2018", "refKey": 50}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 98, "offsetEnd": 102}, "context": "The computational experiments conducted here, namely, show that pre-training language models like ELMo on a very small sample like the French Children Book Test corpus (6 million words), or on a relatively small corpus like CaBeRnet yields unexpected results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8893773555755615}, "created": {"value": false, "score": 0.00013899803161621094}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 103, "offsetEnd": 111}, "context": "Comparison of proportion of Forms in 3 millions words samples from the different register represent by CaBeRnet partition into Oral, Popular, News, Fiction and Academic.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993423819541931}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "frWIKI", "normalizedForm": "frWIKI", "offsetStart": 107, "offsetEnd": 113}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 112, "offsetEnd": 116}, "context": "This configuration can be explained if we understand this pattern as due to the reinforcement and unlearning of ELMo OSCAR of some of its representations during the process of fine-tuning.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08934062719345093}, "created": {"value": false, "score": 0.00014793872833251953}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WikiExtractor.py", "normalizedForm": "WikiExtractor.py", "offsetStart": 113, "offsetEnd": 129}, "context": "The whole sub-portion of Fiction & Literature was compiled from march 2019's Wikisource dump and extracted using WikiExtractor.py, a script that extracts and cleans text from a Wikipedia database dumps, by performing template expansion and preprocessing of template definitions (https://github.com/attardi/ ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976286292076111}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 1.3232231140136719e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9976286292076111}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 1.3232231140136719e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 115, "offsetEnd": 119}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamemBERT", "normalizedForm": "CamemBERT", "offsetStart": 116, "offsetEnd": 125}, "context": "And additional term of comparison was identified in a recently released state-of-the-art language model for French, CamemBERT, based on the RoBERTa architecture pretrained on the French sub-corpus of the newly available multilingual corpus OSCAR ( (Martin et al., 2019)).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00028771162033081055}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9985069632530212}, "created": {"value": false, "score": 0.01024395227432251}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 119, "offsetEnd": 123}, "context": "In the same line, an additional perspective to this work is to better understand why we observe better NER scores with ELMo architecture than we do with BERT-base language model.", "mentionContextAttributes": {"used": {"value": false, "score": 9.262561798095703e-05}, "created": {"value": true, "score": 0.9985185265541077}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 122, "offsetEnd": 126}, "context": "We see that for GSD and Sequoia the CaBeRnet finetuned version ELMo OSCAR+CaBeRnet compared to the pure Oscar pre-trained ELMo OSCAR is achieving higher scores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3809664249420166}, "created": {"value": false, "score": 2.9206275939941406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 123, "offsetEnd": 131}, "context": "Specifically, we can observe that parsing scores are better on treebaks that share the kind of language use represented in CaBeRnet, while they are worst on corpora that are closer in language sample to OSCAR corpus like Spoken and Par-TuT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6223363280296326}, "created": {"value": false, "score": 4.684925079345703e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 125, "offsetEnd": 129}, "context": "For POS-tagging in GSD and ParTUT the results of ELMo OSCAR and ELMo OSCAR+CaBeRnet are in second place position compared to ELMo Wikipedia, but are still ex-tremely close. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9736605882644653}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "script", "normalizedForm": "script", "offsetStart": 133, "offsetEnd": 139}, "context": "The whole sub-portion of Fiction & Literature was compiled from march 2019's Wikisource dump and extracted using WikiExtractor.py, a script that extracts and cleans text from a Wikipedia database dumps, by performing template expansion and preprocessing of template definitions (https://github.com/attardi/ ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976286292076111}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 1.3232231140136719e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9976286292076111}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 1.3232231140136719e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 133, "offsetEnd": 141}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 143, "offsetEnd": 147}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 145, "offsetEnd": 149}, "context": "This section reports the experiments designed to better understand the computational impact of the quality and linguistic balance versus size of ELMo's (Peters et al., 2018) training corpora with the pre-training method ( \u00a74.1.)", "mentionContextAttributes": {"used": {"value": true, "score": 0.6497669219970703}, "created": {"value": false, "score": 0.06683981418609619}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36, "offsetStart": 11764, "offsetEnd": 11785}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 147, "offsetEnd": 155}, "context": "A sixth sub-part could be included to cover technical domains like legal and medical ones, and thereby enlarge the specialized lexical coverage of CaBeRnet.", "mentionContextAttributes": {"used": {"value": false, "score": 0.090789794921875}, "created": {"value": false, "score": 0.0001887679100036621}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 148, "offsetEnd": 156}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 167, "offsetEnd": 171}, "context": "This paper provides an evaluation-based investigation of how a linguistically balanced corpus can yield improvements in the performance of neural language models like ELMo (Peters et al., 2018) in a given language.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016486644744873047}, "created": {"value": true, "score": 0.9898499250411987}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36, "offsetStart": 2276, "offsetEnd": 2297}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMo", "normalizedForm": "ELMo", "offsetStart": 171, "offsetEnd": 175}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999944806098938}, "created": {"value": true, "score": 0.9996429681777954}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "references": [{"label": "(Peters et al., 2018)", "normalizedForm": "Peters et al., 2018", "refKey": 36}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Attardi", "normalizedForm": "Attardi", "offsetStart": 174, "offsetEnd": 181}, "context": "This corpus collects a selection of pages from Wikipediafr from a dump executed in April 2019 where HTML tags and tables were removed, together with template expansion using Attardi's tool (WikiExtractor -GitHub, see 2.1.3.). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1643880009651184}, "created": {"value": false, "score": 6.818771362304688e-05}, "shared": {"value": false, "score": 8.821487426757812e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1643880009651184}, "created": {"value": false, "score": 6.818771362304688e-05}, "shared": {"value": false, "score": 8.821487426757812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 181, "offsetEnd": 189}, "context": "Fine-tuning with CaBeRnet has a second effect on recall, we understand this slight drop as possibly due to unlearning of the wide spectrum of vocabulary that is in OSCAR and not in CaBeRnet. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.18198084831237793}, "created": {"value": false, "score": 1.9431114196777344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 183, "offsetEnd": 191}, "context": "By adding to UDPipe Future 5 differently trained ELMo language model that were pre-trained on qualitatively and quantitatively different corpora, our French Balanced Reference Corpus CaBeRnet shows on three different downstream tasks for French (POS-tagging, dependency parsing, named-entity recognition), achieves to improve the stateof-the-art for POS-tagging over previous monolingual and multilingual approaches.", "mentionContextAttributes": {"used": {"value": true, "score": 0.880807101726532}, "created": {"value": false, "score": 0.00012969970703125}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 189, "offsetEnd": 197}, "context": "The effect of balance on ELMo OSCAR of CaBeRnet Fine-tuning Comparing ELMo OSCAR and ELMo OSCAR+CaBeRnet we can observe that for GSD and Sequoia fine-tuning OSCAR pretrained emdedding with CaBeRnet yields better representations, especially on UAS and LAS results. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.75382399559021}, "created": {"value": false, "score": 2.384185791015625e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 189, "offsetEnd": 197}, "context": "One purposed to be maximally representative of French language to yield good generalizations from, including a full range of language use variability, the French Balanced Reference Corpus -CaBeRnet.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1330890655517578}, "created": {"value": false, "score": 0.0002529025077819824}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WikiExtractor -GitHub", "normalizedForm": "WikiExtractor -GitHub", "offsetStart": 190, "offsetEnd": 211}, "context": "This corpus collects a selection of pages from Wikipediafr from a dump executed in April 2019 where HTML tags and tables were removed, together with template expansion using Attardi's tool (WikiExtractor -GitHub, see 2.1.3.). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1643880009651184}, "created": {"value": false, "score": 6.818771362304688e-05}, "shared": {"value": false, "score": 8.821487426757812e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.1643880009651184}, "created": {"value": false, "score": 6.818771362304688e-05}, "shared": {"value": false, "score": 8.821487426757812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ElMo", "normalizedForm": "ElMo", "offsetStart": 206, "offsetEnd": 210}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 0.006760120391845703}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FrELMo", "normalizedForm": "FrELMo", "offsetStart": 210, "offsetEnd": 216}, "context": "In sum, this paper offers three main contributions: (1) two newly built corpora one French Balanced Reference Corpus and a second domain-specific corpus having both oral and written style, (2) five versions of FrELMo, and (3) a whole array of computational results that deepen our understanding on the effects of balance and register in NLP evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014650821685791016}, "created": {"value": true, "score": 0.9887887835502625}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.5782995223999023}, "created": {"value": true, "score": 0.9887887835502625}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 224, "offsetEnd": 232}, "context": "The computational experiments conducted here, namely, show that pre-training language models like ELMo on a very small sample like the French Children Book Test corpus (6 million words), or on a relatively small corpus like CaBeRnet yields unexpected results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8893765807151794}, "created": {"value": false, "score": 0.00013899803161621094}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 239, "offsetEnd": 247}, "context": "To test for the effect of corpus size, we further compare to wide ranging corpora characterized by a variety of linguistic phenomena crawled from internet by ortizsuarez ortizsuarez, versus our newly built French Balanced Reference Corpus CaBeRnet, that features a wide and balanced coverage of cross-genre language use, including oral.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000732123851776123}, "created": {"value": false, "score": 0.007754862308502197}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CoMeRe", "normalizedForm": "CoMeRe", "offsetStart": 249, "offsetEnd": 255}, "context": "Further development of this resource would additionally consider a further extension to cover user-generated content, ranging from well written blogs, tweets to more variable written productions like newspaper's comment or forums, as present in the CoMeRe corpus. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015687942504882812}, "created": {"value": true, "score": 0.9748287200927734}, "shared": {"value": false, "score": 0.00030994415283203125}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00015687942504882812}, "created": {"value": true, "score": 0.9748287200927734}, "shared": {"value": false, "score": 0.00030994415283203125}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 251, "offsetEnd": 259}, "context": "We distinguish three main evaluation tasks that were performed by ELMo pre-trained on OSCAR (ELMo OSCAR ), frWIKI (ELMo Wikipedia ), CaBeRnet (ELMo CaBeRnet ) and CBT-fr (ELMo CBT ) and comparing them with ElMo pretrained on OSCAR and fine-tuned with CaBeRnet, i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998984336853027}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CamBERT", "normalizedForm": "CamBERT", "offsetStart": 294, "offsetEnd": 301}, "context": "It is namely for this reason, we selected ELMo which not only performs generally better on sequence tagging than other architectures, but is also better suited to pre-train on small corpora because of its inferior rage of parameter (93.6 million) compared to RoBERTa-base architecture used for CamBERT (BERTbase, 12,110 million -Transformer).", "mentionContextAttributes": {"used": {"value": false, "score": 0.18113428354263306}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.18113428354263306}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ELMos", "normalizedForm": "ELMos", "offsetStart": 318, "offsetEnd": 323}, "context": "It consists of an embedding step containing: character level word-embeddings that are trained along the rest of the network, pre-trained word-embeddings11 , a randomly initialized word embeddings that are trained along the rest of the network, and contextualized word-embeddings for which we plug our customly trained ELMos. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.006184935569763184}, "created": {"value": false, "score": 0.002914130687713623}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.006184935569763184}, "created": {"value": false, "score": 0.002914130687713623}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CaBeRnet", "normalizedForm": "CaBeRnet", "offsetStart": 533, "offsetEnd": 541}, "context": "The stability and representativeness probed through our experimental approach are key aspects that allow measures like Pointwise Mutual Information or DICE's Coefficient to be tested against psycho-linguistic and neuro-linguistic data as show in previous neuro-imaging studies (Fabre et al., 2018;Fabre et al., 2019;Fabre et al., 2020) The results obtained for the parsing tasks on ParTUT open a new perspective for the development of the French Balanced Reference Corpus, involving the enhancement of the terminological coverage of CaBeRnet.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": false, "score": 2.3603439331054688e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.9980200529098511}, "shared": {"value": false, "score": 3.4809112548828125e-05}}}], "references": [{"refKey": 36, "tei": "<biblStruct xml:id=\"b36\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Deep Contextualized Word Representations</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthew</forename><surname>Peters</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mark</forename><surname>Neumann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mohit</forename><surname>Iyyer</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matt</forename><surname>Gardner</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><surname>Clark</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Luke</forename><surname>Zettlemoyer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/n18-1202</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</title>\n\t\t<editor>\n\t\t\t<persName><forename type=\"first\">Marilyn</forename><forename type=\"middle\">A</forename><surname>Walker</surname></persName>\n\t\t</editor>\n\t\t<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2018\">2018. June 1-6, 2018</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">2237</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 50, "tei": "<biblStruct xml:id=\"b50\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Milan</forename><surname>Straka</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jana</forename><surname>Strakov\u00e1</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/k17-3009</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>\n\t\t<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2017\">2018. October</date>\n\t\t\t<biblScope unit=\"page\">207</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 12599, "id": "16e2756f6b61156bf68f9339465177bb709cfcc9", "metadata": {"id": "16e2756f6b61156bf68f9339465177bb709cfcc9"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02678358.grobid.tei.xml", "file_name": "hal-02678358.grobid.tei.xml"}