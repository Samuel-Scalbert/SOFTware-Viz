{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:58+0000", "md5": "816E9E6E5BA312BEEC5782B270FE2DBB", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 0, "offsetEnd": 5}, "context": "mBERT is trained on only Wikipedia data, particularly the entire Wikipedia dump for each language, excluding user and talk pages.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014062464237213135}, "created": {"value": false, "score": 0.0003287792205810547}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 6, "offsetEnd": 11}, "context": "Using mBERT and Beto, a monolingual Spanish Bert-based language model, as the basis of our transfer learning architecture, our results indicate that hate speech detection models for a given Spanish variant are affected when different variations of such language are not considered.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995540976524353}, "created": {"value": false, "score": 0.0005846023559570312}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 9, "offsetEnd": 14}, "context": "However, mBERT might not help to detect hate speech against women or immigrants when language-specific variants appear.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012040138244628906}, "created": {"value": false, "score": 4.9948692321777344e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 18, "offsetEnd": 23}, "context": "women immigration mBERT 74.4 (\u00b1 7.0) 69.6 (\u00b1 2.8) BETO 84.9 (\u00b1 0.3) 73.1 (\u00b1 0.8) Table 2: Models' average macro-F1 scores obtained on the test split over five runs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 21, "offsetEnd": 26}, "context": "To do so, we compare mBERT with a Spanish version of BERT, named BETO (Canete et al., 2020), for binary classification in two different hate speech domains using various datasets on xenophobia and misogyny.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1923564076423645}, "created": {"value": false, "score": 0.005493819713592529}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wordsegment", "normalizedForm": "wordsegment", "offsetStart": 25, "offsetEnd": 36}, "context": "https://pypi.org/project/wordsegment/", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019210577011108398}, "created": {"value": false, "score": 4.172325134277344e-05}, "shared": {"value": true, "score": 0.9780444502830505}}, "documentContextAttributes": {"used": {"value": false, "score": 0.029127418994903564}, "created": {"value": false, "score": 0.004509985446929932}, "shared": {"value": true, "score": 0.9780444502830505}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 33, "offsetEnd": 38}, "context": "High standard deviations in both mBERT models compared to BETO suggests that BETO shows more stable and consistent performance across different runs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1141083836555481}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 43, "offsetEnd": 48}, "context": "We aim to evaluate the differences between mBERT and BETO to detect hate speech in Twitter posts written in Spanish.", "mentionContextAttributes": {"used": {"value": true, "score": 0.816799521446228}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 44, "offsetEnd": 49}, "context": "For the multilingual language model, we use mBERT (Devlin et al., 2019), the multilingual version of BERT, trained on Wikipedia data from 104 languages.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8422937393188477}, "created": {"value": false, "score": 1.537799835205078e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2019)", "normalizedForm": "Devlin et al., 2019", "refKey": 12, "offsetStart": 17283, "offsetEnd": 17304}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 45, "offsetEnd": 50}, "context": "Results obtained from the comparison between mBERT and BETO over the whole corpora are shown in Table 2. Results suggest that BETO outperforms mBERT in both hate speech domains.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999638795852661}, "created": {"value": false, "score": 1.430511474609375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 59, "offsetEnd": 64}, "context": "Specifically, BETO macro-F1 score is 11 points higher than mBERT on misogyny detection, whereas 4 points higher on xenophobia-related tweets classification.", "mentionContextAttributes": {"used": {"value": false, "score": 0.25664007663726807}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wordsegment", "normalizedForm": "wordsegment", "offsetStart": 63, "offsetEnd": 76}, "context": "To develop such hashtags segmentation, we use Python's package wordsegment10 . ", "mentionContextAttributes": {"used": {"value": false, "score": 0.029127418994903564}, "created": {"value": false, "score": 0.004509985446929932}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.029127418994903564}, "created": {"value": false, "score": 0.004509985446929932}, "shared": {"value": true, "score": 0.9780444502830505}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 77, "offsetEnd": 82}, "context": "She investigated the limitations of zero-shot cross-lingual approaches using mBERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.993854820728302}, "created": {"value": false, "score": 0.0006514191627502441}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CrowdFlower", "normalizedForm": "CrowdFlower", "offsetStart": 84, "offsetEnd": 95}, "context": "Next, the rest of the tweets were labeled through a majority voting approach on the CrowdFlower 7 platform based on the standard defined in the first step.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999215602874756}, "created": {"value": false, "score": 9.822845458984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999215602874756}, "created": {"value": false, "score": 9.822845458984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 89, "offsetEnd": 94}, "context": "We use all the data described in Section 3 to compare the performance of the two models, mBERT and BETO.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999337196350098}, "created": {"value": false, "score": 6.103515625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 103, "offsetEnd": 108}, "context": "Current state-of-the-art pre-trained language models (LM), such as the \"multilingual\" version of BERT (mBERT) (Devlin et al., 2018;Pires et al., 2019), are widely used in several NLP tasks and achieve impressive results.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013196468353271484}, "created": {"value": false, "score": 0.008968353271484375}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11, "offsetStart": 4633, "offsetEnd": 4654}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35, "offsetStart": 4654, "offsetEnd": 4673}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 111, "offsetEnd": 116}, "context": "This does not mean that Multilingual BERT is not useful since findings in (Wu and Dredze, 2020) suggested that mBERT is remarkably useful on low-resource language tasks, in contrast to monolingual BERT implementations that use a significant amount of data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000152587890625}, "created": {"value": false, "score": 7.390975952148438e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 143, "offsetEnd": 148}, "context": "Results obtained from the comparison between mBERT and BETO over the whole corpora are shown in Table 2. Results suggest that BETO outperforms mBERT in both hate speech domains.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999638795852661}, "created": {"value": false, "score": 1.430511474609375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 145, "offsetEnd": 150}, "context": "Results obtained in (Plaza-del Arco et al., 2021) showed that BETO, a monolingual LM outperforms multilingual pre-trained models such as XLM and mBERT as well as the rest of the models they evaluated for hate speech detection in Spanish.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8217681646347046}, "created": {"value": false, "score": 1.5854835510253906e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "mBERT", "normalizedForm": "mBERT", "offsetStart": 206, "offsetEnd": 211}, "context": "Others models for Spanish exist and are posterior to BETO (Guti\u00e9rrez-Fandi\u00f1o et al., 2021;la Rosa et al., 2022), we decided to focus on BETO because of its pretraining data that makes it more comparable to mBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004220366477966309}, "created": {"value": false, "score": 0.001183152198791504}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999685287475586}, "created": {"value": true, "score": 0.9058103561401367}, "shared": {"value": false, "score": 4.0531158447265625e-06}}, "references": [{"label": "(Devlin et al., 2018;", "normalizedForm": "(Devlin et al., 2018", "refKey": 11}, {"label": "Pires et al., 2019)", "normalizedForm": "Pires et al., 2019)", "refKey": 35}]}], "references": [{"refKey": 11, "tei": "<biblStruct xml:id=\"b11\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Devlin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ming-Wei</forename><surname>Chang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kristina</forename><surname>Toutanova</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:1810.04805</idno>\n\t\t<title level=\"m\">Bert: Pre-training of deep bidirectional transformers for language understanding</title>\n\t\t<imprint>\n\t\t\t<date>2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 35, "tei": "<biblStruct xml:id=\"b35\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Telmo</forename><surname>Pires</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eva</forename><surname>Schlinger</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dan</forename><surname>Garrette</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:1906.01502</idno>\n\t\t<title level=\"m\">How multilingual is multilingual bert?</title>\n\t\t<imprint>\n\t\t\t<date>2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 12, "tei": "<biblStruct xml:id=\"b12\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\"></title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Devlin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ming-Wei</forename><surname>Chang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kenton</forename><surname>Lee</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kristina</forename><surname>Toutanova</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/n19-1423</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2019 Conference of the North</title>\n\t\t<meeting>the 2019 Conference of the North</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">4186</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 9035, "id": "bf8ddd961f8fb3d3df198dbee6b74a1a6a36b1de", "metadata": {"id": "bf8ddd961f8fb3d3df198dbee6b74a1a6a36b1de"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04243810.grobid.tei.xml", "file_name": "hal-04243810.grobid.tei.xml"}