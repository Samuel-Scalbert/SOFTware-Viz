{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:59+0000", "md5": "812B77964D5D4981CE4F0F851E0E769C", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Large OpenSubtitles", "normalizedForm": "Large OpenSubtitles", "offsetStart": 15, "offsetEnd": 34}, "context": "Comparing both Large OpenSubtitles with BPE tokenization 16K and 32K, BLEU scores reveal that PBSMT has considerably lower performance as the vocabulary size doubles.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6820297241210938}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.01442575454711914}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XNMT", "normalizedForm": "XNMT", "offsetStart": 18, "offsetEnd": 22}, "context": "We decided to use XNMT, instead of OpenNMT in our experiments in order to compare our results to the ones ofMichel and Neubig (2018).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": false, "score": 0.0018138289451599121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999958872795105}, "created": {"value": false, "score": 0.0018138289451599121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "(Neubig et al., 2018)", "normalizedForm": "Neubig et al., 2018", "refKey": 33}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ADAM", "normalizedForm": "ADAM", "offsetStart": 25, "offsetEnd": 29}, "context": "It was trained using the ADAM optimizer with OpenNMT default parameters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": false, "score": 2.956390380859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": false, "score": 2.956390380859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ADAM", "normalizedForm": "ADAM", "offsetStart": 32, "offsetEnd": 36}, "context": "The model was trained using the ADAM optimizer (Kingma and Ba, 2015) with vanilla parameters (\u03b1 = 0.02, \u03b2 = 0.998). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999981164932251}, "created": {"value": false, "score": 2.4318695068359375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": false, "score": 2.956390380859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenNMT", "normalizedForm": "OpenNMT", "offsetStart": 35, "offsetEnd": 42}, "context": "We decided to use XNMT, instead of OpenNMT in our experiments in order to compare our results to the ones ofMichel and Neubig (2018).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": false, "score": 0.0018138289451599121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": true, "score": 0.9231156706809998}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Large OpenSubtitles", "normalizedForm": "Large OpenSubtitles", "offsetStart": 38, "offsetEnd": 57}, "context": "These predictions were produced using Large OpenSubtitles, trained with 16K fixed size vocabulary. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 2.86102294921875e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.01442575454711914}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XNMT", "normalizedForm": "XNMT", "offsetStart": 40, "offsetEnd": 44}, "context": "The seq2seq model was trained using the XNMT toolkit (Neubig et al., 2018).5", "mentionContextAttributes": {"used": {"value": true, "score": 0.999958872795105}, "created": {"value": false, "score": 1.5854835510253906e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999958872795105}, "created": {"value": false, "score": 0.0018138289451599121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "(Neubig et al., 2018)", "normalizedForm": "Neubig et al., 2018", "refKey": 33, "offsetStart": 10913, "offsetEnd": 10934}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenNMT", "normalizedForm": "OpenNMT", "offsetStart": 45, "offsetEnd": 52}, "context": "It was trained using the ADAM optimizer with OpenNMT default parameters.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": false, "score": 2.956390380859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": true, "score": 0.9231156706809998}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "XNMT", "normalizedForm": "XNMT", "offsetStart": 49, "offsetEnd": 53}, "context": "At the time we conducted the MT experiments, the XNMT toolkit (Neubig et al., 2018) has no straightforward possibilities of re-placing unknown tokens present in the test set. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9749955534934998}, "created": {"value": false, "score": 0.00077056884765625}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999958872795105}, "created": {"value": false, "score": 0.0018138289451599121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "(Neubig et al., 2018)", "normalizedForm": "Neubig et al., 2018", "refKey": 33, "offsetStart": 13616, "offsetEnd": 13637}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SubsTest", "normalizedForm": "SubsTest", "offsetStart": 64, "offsetEnd": 72}, "context": "It is worth noting that performances of the in-domain test Open-SubsTest are kept almost invariable for PBSMT both and NMT models.As expected, these performance gaps between PBSMT and NMT models are 7 All BLEU scores evaluation are computed with Sacre-BLEU (Post, 2018). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9810153245925903}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9810153245925903}, "created": {"value": false, "score": 1.049041748046875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 66, "offsetEnd": 79}, "context": "To enable a fair comparison between systems trained on WMT and on OpenSubtitles, we consider a small version of the OpenSubtitles that has nearly the same number of tokens as the WMT training set and a large version that contains all OpenSubtitles parallel data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012113809585571289}, "created": {"value": false, "score": 0.00025206804275512695}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 83, "offsetEnd": 96}, "context": "We also consider, as a second training set, the French-English parallel portion of OpenSubtitles'18 (Lison et al., 2018), a collection of crowd-sourced peer-reviewed subtitles for movies.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022214651107788086}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27, "offsetStart": 7049, "offsetEnd": 7069}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenNMT", "normalizedForm": "OpenNMT", "offsetStart": 92, "offsetEnd": 99}, "context": "This is done in the Moses toolkit (using the alignments produced during translation) and in OpenNMT (that uses the soft-alignments to copy the source token with the highest attention weight at every decoding step when necessary). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1896517276763916}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": true, "score": 0.9231156706809998}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenNMT", "normalizedForm": "OpenNMT", "offsetStart": 104, "offsetEnd": 111}, "context": "We consider a vanilla Transformer model (Vaswani et al., 2017) using the implementation proposed in the OpenNMT framework (Klein et al., 2018). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00034296512603759766}, "created": {"value": true, "score": 0.9231156706809998}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999839067459106}, "created": {"value": true, "score": 0.9231156706809998}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 108, "offsetEnd": 121}, "context": "Additionally, the PBSMT results for the Large 32K system are considerably lower than for any of the other 2 OpenSubtitles configurations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8448687195777893}, "created": {"value": false, "score": 1.0967254638671875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 111, "offsetEnd": 124}, "context": "We assume that, because it is made of informal dialogs, such as those found in popular sitcoms, sentences from OpenSubtitles will be much more similar to UGC data than WMT data, in part because most of it originates from social media and consists in streams of conversation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005246996879577637}, "created": {"value": false, "score": 0.00027066469192504883}, "shared": {"value": false, "score": 7.867813110351562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 116, "offsetEnd": 129}, "context": "To enable a fair comparison between systems trained on WMT and on OpenSubtitles, we consider a small version of the OpenSubtitles that has nearly the same number of tokens as the WMT training set and a large version that contains all OpenSubtitles parallel data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012113809585571289}, "created": {"value": false, "score": 0.00025206804275512695}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Large OpenSubtitles", "normalizedForm": "Large OpenSubtitles", "offsetStart": 117, "offsetEnd": 136}, "context": "Table 4 reports the noise-level of our test sets introduced in Section 3.1 with respect to our largest training set, Large OpenSubtitles.", "mentionContextAttributes": {"used": {"value": true, "score": 0.856211245059967}, "created": {"value": false, "score": 0.01442575454711914}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.01442575454711914}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 122, "offsetEnd": 135}, "context": "To evaluate our system on in-domain data, we use the newstest'14 as a test set as well as 11,000 sentences extracted from OpenSubtitles.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 3.9458274841308594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 133, "offsetEnd": 146}, "context": "We notice that the gap between PBSMT and NMT architectures (about 0.3) is much larger when training on WMT than when training in our OpenSubtitles (about 0.1). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0165555477142334}, "created": {"value": false, "score": 7.927417755126953e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Large OpenSubtitles", "normalizedForm": "Large OpenSubtitles", "offsetStart": 133, "offsetEnd": 152}, "context": "To further investigate whether this observation results from a badly chosen number of BPE operations, we have also trained using the Large OpenSubtitles corpus tokenized with a 32K operation BPE.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999150037765503}, "created": {"value": false, "score": 0.0006848573684692383}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999924898147583}, "created": {"value": false, "score": 0.01442575454711914}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 168, "offsetEnd": 181}, "context": "It even appears that the quality of the translation of phrase-based system increases with the noiselevel (as measured by the metrics introduced in \u00a74): when trained on OpenSubtitles, its score for the Cr#pbank is surprisingly better than for in-domain data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0030248165130615234}, "created": {"value": false, "score": 3.504753112792969e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 234, "offsetEnd": 247}, "context": "To enable a fair comparison between systems trained on WMT and on OpenSubtitles, we consider a small version of the OpenSubtitles that has nearly the same number of tokens as the WMT training set and a large version that contains all OpenSubtitles parallel data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.012113809585571289}, "created": {"value": false, "score": 0.00025206804275512695}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999964714050293}, "created": {"value": false, "score": 0.206157386302948}, "shared": {"value": false, "score": 1.9550323486328125e-05}}, "references": [{"label": "(Lison et al., 2018)", "normalizedForm": "Lison et al., 2018", "refKey": 27}]}], "references": [{"refKey": 33, "tei": "<biblStruct xml:id=\"b33\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">XNMT: the extensible neural machine translation toolkit</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Graham</forename><surname>Neubig</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthias</forename><surname>Sperber</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xinyi</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthieu</forename><surname>Felix</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Austin</forename><surname>Matthews</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sarguna</forename><surname>Padmanabhan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ye</forename><surname>Qi</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Devendra</forename><surname>Singh Sachan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Philip</forename><surname>Arthur</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pierre</forename><surname>Godard</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">John</forename><surname>Hewitt</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rachid</forename><surname>Riad</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Liming</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 13th Conference of the Association for Machine Translation in the Americas, AMTA 2018</title>\n\t\t<meeting>the 13th Conference of the Association for Machine Translation in the Americas, AMTA 2018</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Research Papers</publisher>\n\t\t\t<date>2018. March 17-21, 2018</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">192</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 27, "tei": "<biblStruct xml:id=\"b27\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Opensubtitles2018: Statistical rescoring of sentence alignments in large, noisy parallel corpora</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Pierre</forename><surname>Lison</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">J\u00f6rg</forename><surname>Tiedemann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Milen</forename><surname>Kouylekov</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</title>\n\t\t<meeting>the Eleventh International Conference on Language Resources and Evaluation, LREC 2018</meeting>\n\t\t<imprint>\n\t\t\t<date>2018. May 7-12, 2018</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 34583, "id": "86b3b6917e36c7e822ec13c51cb662676f22f35e", "metadata": {"id": "86b3b6917e36c7e822ec13c51cb662676f22f35e"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02270524.grobid.tei.xml", "file_name": "hal-02270524.grobid.tei.xml"}