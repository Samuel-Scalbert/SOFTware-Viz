{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T15:42+0000", "md5": "4D27E129D66E51E7BA7010E265F589F4", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET either uses a hardware-based approach or a software solution when the hardware-based solution is not accessible. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00026679039001464844}, "created": {"value": false, "score": 0.0001964569091796875}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Ozone", "normalizedForm": "Ozone", "offsetStart": 0, "offsetEnd": 5}, "context": "Ozone generates execution traces that provide the value of the cycle counter, the instruction's address, opcode, and operands, as well as the corresponding assembly code for each instruction. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001983642578125}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.523331344127655}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET identifies the longest execution path using static techniques, whereas the worst-case execution time (WCET) of basic blocks is predicted using an advanced language processing technique called Transformer-XL.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003718554973602295}, "created": {"value": false, "score": 1.4007091522216797e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET consists of two main stages: training and deployment (or estimation).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00048047304153442383}, "created": {"value": false, "score": 6.479024887084961e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET is easy to deploy, as the training has to be done only once.", "mentionContextAttributes": {"used": {"value": false, "score": 7.647275924682617e-05}, "created": {"value": false, "score": 0.0001926422119140625}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET is evaluated on processors of varied complexity, including the basic pipelineonly cortex-M4, the more advanced cortex-M7 that features a cache, and the even more sophisticated cortex-A53.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1946495771408081}, "created": {"value": false, "score": 0.0002276897430419922}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET is a hybrid context-aware WCET estimation technique that predicts an in-context WCET of individual basic blocks and then uses the predictions to calculate the overall program's WCET.", "mentionContextAttributes": {"used": {"value": false, "score": 6.645917892456055e-05}, "created": {"value": false, "score": 0.0004902482032775879}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET consists of two main stages: training and deployment (or estimation).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00048047304153442383}, "created": {"value": false, "score": 6.479024887084961e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET relies on Transformers-XL, originally used in natural language processing, for their ability to learn long-term dependencies between words.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006470084190368652}, "created": {"value": false, "score": 0.00017309188842773438}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET predicts the WCET of BBs by considering their execution context.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0031870007514953613}, "created": {"value": false, "score": 2.8312206268310547e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET training consists of two steps: (self-supervised) pre-training and fine-tuning.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00042372941970825195}, "created": {"value": false, "score": 7.683038711547852e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET is evaluated by comparing it to two context-agnostic WCET predictors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9684818387031555}, "created": {"value": false, "score": 2.8014183044433594e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 0, "offsetEnd": 5}, "context": "CAWET is compared to WE-HML for the Cortex A53 processor only, a processor for which the results of WE-HML were available.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9968031048774719}, "created": {"value": false, "score": 2.6047229766845703e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CodeNet", "normalizedForm": "CodeNet", "offsetStart": 0, "offsetEnd": 7}, "context": "CodeNet is a collection of solutions submitted by the public to competitive programming websites. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00034606456756591797}, "created": {"value": false, "score": 0.02566242218017578}, "shared": {"value": false, "score": 1.138448715209961e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997190237045288}, "created": {"value": false, "score": 0.02566242218017578}, "shared": {"value": false, "score": 1.138448715209961e-05}}}, {"type": "software", "software-type": "software", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "wikidataId": "Q47509047", "wikipediaExternalRef": 54022970, "lang": "en", "confidence": 0.7826, "offsetStart": 0, "offsetEnd": 7}, "context": "PyTorch was used to implement the learning models, which were then trained on a Tesla V100. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998907446861267}, "created": {"value": false, "score": 0.0022559165954589844}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998907446861267}, "created": {"value": false, "score": 0.0022559165954589844}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 3, "offsetEnd": 8}, "context": "In CAWET, the language under study is a sequence of BBs, each composed of a sequence of assembly instructions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018835067749023438}, "created": {"value": false, "score": 0.00047582387924194336}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "J-Trace Pro", "normalizedForm": "J-Trace Pro", "offsetStart": 4, "offsetEnd": 15}, "context": "The J-Trace Pro trace solution from Segger [31] is used to connect to the JTAG interface of the target processor (in our case Cortex-M4 and Cortex-M7), in conjunction with Ozone [14], a cross-platform debugger and performance analyzer. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.523331344127655}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.523331344127655}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 7, "offsetEnd": 12}, "context": "Unlike CAWET, this approach uses static features and is thus not able to accurately predict pipeline effects.", "mentionContextAttributes": {"used": {"value": false, "score": 4.583597183227539e-05}, "created": {"value": false, "score": 0.0029435157775878906}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 9, "offsetEnd": 14}, "context": "Finally, CAWET is evaluated in Subsection 4.4 on a more complex processor, the Cortex-A53, using a software measurement method and an operating system, allowing us to compare the WCET predictions of CAWET with those of WE-HML [2].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993802905082703}, "created": {"value": false, "score": 3.606081008911133e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 9, "offsetEnd": 14}, "context": "However, CAWET takes a different approach by incorporating the execution context to predict WCETs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012373924255371094}, "created": {"value": false, "score": 4.392862319946289e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CATREEN", "normalizedForm": "CATREEN", "offsetStart": 11, "offsetEnd": 22}, "context": "Similarly, CATREEN [1] uses stacked LSTMs to forecast the average execution time of basic blocks in a contextualized manner, but it differs from CAWET in its focus on average execution time rather than worst-case execution time.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004032254219055176}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0004032254219055176}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 13, "offsetEnd": 18}, "context": "In contrast, CAWET operates on the flow of instructions using state-of-the-art ML techniques (Transformers-XL).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00039690732955932617}, "created": {"value": false, "score": 0.0003559589385986328}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 13, "offsetEnd": 18}, "context": "To fine-tune CAWET on basic blocks with their context, we have used a diverse and publicly available set of programs:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9905971884727478}, "created": {"value": false, "score": 0.0011180639266967773}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 17, "offsetEnd": 22}, "context": "The results from CAWET can then be used by a static WCET estimation tool.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9129290580749512}, "created": {"value": false, "score": 3.045797348022461e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 17, "offsetEnd": 22}, "context": "We thus modified CAWET to add a cache miss penalty to the WCET of a BB when the static cache analysis of Heptane cannot guarantee a cache hit.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9621524810791016}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MiBench", "normalizedForm": "MiBench", "offsetStart": 18, "offsetEnd": 30}, "context": "The Algorithms5 , MiBench [15] and Polybench [37]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999740719795227}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999740719795227}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 19, "offsetEnd": 24}, "context": "The other baseline CAWET is compared with is WE-HML, a hybrid ML-based WCET estimation technique presented in [2].", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001595020294189453}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Heptane", "normalizedForm": "Heptane", "offsetStart": 19, "offsetEnd": 26}, "context": "Finally, we employ Heptane's IPET to determine the overall WCET of the program.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": false, "score": 0.011534631252288818}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}, {"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 20, "offsetEnd": 25}, "context": "This paper presents CAWET, a hybrid worst-case program timing estimation technique.", "mentionContextAttributes": {"used": {"value": false, "score": 4.5359134674072266e-05}, "created": {"value": true, "score": 0.9998326301574707}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 20, "offsetEnd": 25}, "context": "This is achieved in CAWET using (virtual) unrolling: the context of a loop is composed of several iterations of the loop body (from zero to the loop's maximum number of iterations).", "mentionContextAttributes": {"used": {"value": false, "score": 0.012196898460388184}, "created": {"value": false, "score": 1.4126300811767578e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 20, "offsetEnd": 25}, "context": "We have pre-trained CAWET on a large number of BBs in order for the Transformer to learn the assembly language under study, using CodeNet [28].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997190237045288}, "created": {"value": false, "score": 0.0039601922035217285}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 22, "offsetEnd": 27}, "context": "Our results show that CAWET produces better estimates than its competitors on more diverse architectures.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9618402719497681}, "created": {"value": false, "score": 0.0006066560745239258}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 22, "offsetEnd": 27}, "context": "The results show that CAWET is twice less pessimistic than the NN baseline on average, using the Mean Absolute Error 6 on the RPE (i.e., Error = RPE).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992713928222656}, "created": {"value": false, "score": 2.0325183868408203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 23, "offsetEnd": 28}, "context": "Section 2 presents the CAWET HT-ML technique.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010967552661895752}, "created": {"value": false, "score": 0.00011283159255981445}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 23, "offsetEnd": 28}, "context": "The two main phases of CAWET: training (using Transformers-XL) and prediction (i.e., deployment), are then respectively presented in Sections 2.2 and 2.3.", "mentionContextAttributes": {"used": {"value": false, "score": 0.1630217432975769}, "created": {"value": false, "score": 5.4895877838134766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TacleBench", "normalizedForm": "TacleBench", "offsetStart": 23, "offsetEnd": 33}, "context": "Note that the selected TacleBench programs were not used during any of the two steps of the training phase.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993250966072083}, "created": {"value": false, "score": 6.335973739624023e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 0.02690976858139038}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 25, "offsetEnd": 30}, "context": "A high-level overview of CAWET is given in Section 2.1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0024511218070983887}, "created": {"value": false, "score": 4.8100948333740234e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 25, "offsetEnd": 30}, "context": "The overall structure of CAWET is depicted in Figure 1.", "mentionContextAttributes": {"used": {"value": false, "score": 0.004118561744689941}, "created": {"value": false, "score": 0.0011078119277954102}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 25, "offsetEnd": 30}, "context": "To limit the complexity, CAWET performs an exhaustive path exploration only for the SESE regions that are simple enough (based on their Cyclomatic Complexity, CC) to allow a full path exploration.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002982616424560547}, "created": {"value": false, "score": 1.710653305053711e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 26, "offsetEnd": 31}, "context": "Since the context size in CAWET is limited, the reuse of code/data (with instruction/data caches) may not be fully taken into account by the model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003409385681152344}, "created": {"value": false, "score": 0.00015592575073242188}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 27, "offsetEnd": 32}, "context": "The programs used to train CAWET and evaluate the quality of predictions are first described in Section 3.1.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9670171141624451}, "created": {"value": false, "score": 0.000495612621307373}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 28, "offsetEnd": 33}, "context": "In this paper, we presented CAWET: a hybrid approach that estimates the worst-case program timing for individual basic blocks in a program. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.45246696472168e-05}, "created": {"value": true, "score": 0.9999194741249084}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 29, "offsetEnd": 34}, "context": "We use a TXL architecture in CAWET because it improves the ability of the transformer to handle long-term dependencies, which is necessary for handling long sequences of code.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01813328266143799}, "created": {"value": false, "score": 0.007658243179321289}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 29, "offsetEnd": 34}, "context": "We also observe that neither CAWET nor the NN baseline underestimates the WCET since all RPE are positive.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9321156144142151}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 31, "offsetEnd": 36}, "context": "The context-agnostic baselines CAWET is compared to are presented in Section 3.2, followed by an introduction to the software and hardware environments in Section 3.3.", "mentionContextAttributes": {"used": {"value": false, "score": 0.28423011302948}, "created": {"value": false, "score": 6.139278411865234e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "wikidataId": "Q3491191", "wikipediaExternalRef": 4464255, "lang": "en", "confidence": 0.6913, "software-name": {"rawForm": "objdump", "normalizedForm": "objdump", "wikidataId": "Q3491191", "wikipediaExternalRef": 4464255, "lang": "en", "confidence": 0.6913, "offsetStart": 31, "offsetEnd": 38}, "context": "The textual format produced by objdump, after some basic parsing (e.g., extraction of addresses, separation of BBs) allows the creation of a large pre-training set. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.526708602905273e-05}, "created": {"value": false, "score": 8.946657180786133e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02897655963897705}, "created": {"value": false, "score": 8.946657180786133e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 32, "offsetEnd": 37}, "context": "By employing Transformers-XL in CAWET, the execution context formed by previously executed basic blocks is taken into account, allowing for consideration of the microarchitecture of the processor pipeline without explicit modeling.", "mentionContextAttributes": {"used": {"value": false, "score": 0.02434217929840088}, "created": {"value": false, "score": 0.00028967857360839844}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 35, "offsetEnd": 40}, "context": "The concepts and notations used in CAWET are standard concepts used in compilers.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0013625025749206543}, "created": {"value": false, "score": 0.001220703125}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Polybench", "normalizedForm": "Polybench", "offsetStart": 35, "offsetEnd": 48}, "context": "The Algorithms5 , MiBench [15] and Polybench [37]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999740719795227}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999740719795227}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 37, "offsetEnd": 42}, "context": "On all benchmarks but one (matrix1), CAWET is much less pessimistic than WE-HML (even for the modified CAWET). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.10080409049987793}, "created": {"value": false, "score": 1.8298625946044922e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TacleBench", "normalizedForm": "TacleBench", "offsetStart": 39, "offsetEnd": 49}, "context": "Through a series of experiments on the TacleBench benchmarks, using different target processors (Arm Cortex M4, M7, and A53), our method is demonstrated to never underestimate WCETs and is shown to be less pessimistic than its competitors.", "mentionContextAttributes": {"used": {"value": false, "score": 0.44109541177749634}, "created": {"value": false, "score": 0.02690976858139038}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 0.02690976858139038}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 40, "offsetEnd": 45}, "context": "The effect of the different features of CAWET on the quality of the predictions is studied in Section 4.3.", "mentionContextAttributes": {"used": {"value": false, "score": 0.17070084810256958}, "created": {"value": false, "score": 2.1398067474365234e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 42, "offsetEnd": 47}, "context": "The quality of WCET estimates produced by CAWET is compared to those produced by WE-HML, the HT-ML technique closest to CAWET [2], on 13 programs from the TACLeBench benchmark suite [13].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9981773495674133}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 44, "offsetEnd": 49}, "context": "Then, we predict the WCET for each BB using CAWET.", "mentionContextAttributes": {"used": {"value": true, "score": 0.999064028263092}, "created": {"value": false, "score": 6.020069122314453e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 47, "offsetEnd": 52}, "context": "Each setting (processor) required two days for CAWET training: 1,5 days for pre-training and 0,5 days to fine-tune the model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996614456176758}, "created": {"value": false, "score": 3.045797348022461e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 47, "offsetEnd": 52}, "context": "Table 6 evaluates WCET predictions produced by CAWET and the baseline NN for the Cortex M7, using a context size of 6 for CAWET.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9660333395004272}, "created": {"value": false, "score": 2.086162567138672e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 47, "offsetEnd": 52}, "context": "The integration of cache analysis results into CAWET and NN leads to more pessimistic WCETs for both techniques.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005034804344177246}, "created": {"value": false, "score": 1.0788440704345703e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 50, "offsetEnd": 55}, "context": "Section 2.3.1 presents the concepts and notations CAWET relies on.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003446340560913086}, "created": {"value": false, "score": 4.988908767700195e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 53, "offsetEnd": 58}, "context": "The setups for the learning and prediction phases of CAWET are presented respectively in Section 3.4 and 3.5.", "mentionContextAttributes": {"used": {"value": false, "score": 0.21663051843643188}, "created": {"value": false, "score": 0.00017523765563964844}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 53, "offsetEnd": 58}, "context": "The research works presented in [17,2], similarly to CAWET, propose to extract features from the binary code and to use ML techniques to predict the WCET of individual basic However, contrary to [18,17,2], CAWET takes a more fine-grained approach, considering the context surrounding each basic block, and the dependencies between instructions within it to better consider hardware components such as the pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007881522178649902}, "created": {"value": false, "score": 0.0014840364456176758}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 55, "offsetEnd": 60}, "context": "It should also be noted that the average MAE, both for CAWET and NN, is, as one would expect, higher for the more complex Cortex M7 than for the very simple Cortex M4, showing that the tight timing analysis of complex processors is harder to achieve than the analysis of simpler ones.", "mentionContextAttributes": {"used": {"value": false, "score": 0.06322228908538818}, "created": {"value": false, "score": 4.416704177856445e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 55, "offsetEnd": 60}, "context": "It may also happen when pWCET is less pessimistic than CAWET.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004290938377380371}, "created": {"value": false, "score": 1.2576580047607422e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 60, "offsetEnd": 65}, "context": "To validate the quality of the WCET predictions provided by CAWET, we use a subset of the codes from the TacleBench benchmark suite [13] whose characteristics are given in Table 2.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 7.212162017822266e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Heptane", "normalizedForm": "Heptane", "offsetStart": 62, "offsetEnd": 69}, "context": "The CFG, the SESE tree, and the loop tree is generated by the Heptane WCET estimation tool [16].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9850257635116577}, "created": {"value": false, "score": 2.8431415557861328e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}, {"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 64, "offsetEnd": 69}, "context": "The results show that even with no explicit support for caches, CAWET never underestimates compared to the Maximum observed execution time (the max of 1000 executions) and is again more precise than the NN baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9908136129379272}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 64, "offsetEnd": 69}, "context": "In this section, we analyze the effect of different features of CAWET on the Relative Percentage Error (RPE): context accounting, peek-on mechanism, loop management, and using Heptane's cache analysis.", "mentionContextAttributes": {"used": {"value": false, "score": 0.41604191064834595}, "created": {"value": false, "score": 0.0005985498428344727}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 65, "offsetEnd": 70}, "context": "Unlike other HT-ML methods, which only consider static features, CAWET considers the internal dependencies within each BB and the context surrounding it when estimating its WCET.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001277923583984375}, "created": {"value": false, "score": 3.153085708618164e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 73, "offsetEnd": 78}, "context": "In this paper, we propose a novel HT-ML WCET estimation technique called CAWET, for Context-Aware Worst-case execution time Estimation using Transformers.", "mentionContextAttributes": {"used": {"value": false, "score": 4.89354133605957e-05}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 78, "offsetEnd": 83}, "context": "The maximum measured BB execution time is used alongside its context to train CAWET. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992964267730713}, "created": {"value": false, "score": 1.4960765838623047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 79, "offsetEnd": 84}, "context": "They are illustrated in Figure 3, which will be reused later to illustrate how CAWET works.", "mentionContextAttributes": {"used": {"value": false, "score": 0.010159850120544434}, "created": {"value": false, "score": 0.023145973682403564}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 81, "offsetEnd": 86}, "context": "By considering the execution context formed by previously executed basic blocks, CAWET is able to account for the micro-architecture of the processor pipeline without explicit modeling. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.001124262809753418}, "created": {"value": false, "score": 0.0014842748641967773}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 87, "offsetEnd": 92}, "context": "Accurate timing values must be employed whenever possible when training and validating CAWET, and the method used to obtain the timing values should not interfere with the execution of the code, a phenomenon commonly known as the probe effect. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0023340582847595215}, "created": {"value": false, "score": 9.316205978393555e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GDB", "normalizedForm": "GDB", "offsetStart": 93, "offsetEnd": 96}, "context": "To provide context and assembly code for the timed BB, we retrieve the execution trace using GDB (the GNU Debugger). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999266266822815}, "created": {"value": false, "score": 6.014108657836914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999266266822815}, "created": {"value": false, "score": 6.014108657836914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 93, "offsetEnd": 98}, "context": "This Section provides a comprehensive description of the experimental setup used to evaluate CAWET on multiple ARM Cortex targets, specifically M4, M7, and A53.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9438241124153137}, "created": {"value": false, "score": 0.0009606480598449707}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 95, "offsetEnd": 100}, "context": "The objectives of these experiments are twofold: (i) evaluate the WCET predictions produced by CAWET for a more complex processor than the Cortex M7; (ii) be able to compare CAWET to WE-HML [2], the related work closest to CAWET, that targets this architecture.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00354689359664917}, "created": {"value": false, "score": 0.002252817153930664}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 98, "offsetEnd": 103}, "context": "However, in general, pWCET techniques may miss the worst-case execution path in programs, whereas CAWET, a hybrid technique, will not.", "mentionContextAttributes": {"used": {"value": false, "score": 4.07099723815918e-05}, "created": {"value": false, "score": 6.717443466186523e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 103, "offsetEnd": 108}, "context": "On all benchmarks but one (matrix1), CAWET is much less pessimistic than WE-HML (even for the modified CAWET).", "mentionContextAttributes": {"used": {"value": false, "score": 0.10080409049987793}, "created": {"value": false, "score": 1.8298625946044922e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Heptane", "normalizedForm": "Heptane", "offsetStart": 105, "offsetEnd": 112}, "context": "We thus modified CAWET to add a cache miss penalty to the WCET of a BB when the static cache analysis of Heptane cannot guarantee a cache hit.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9621524810791016}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}, {"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TacleBench", "normalizedForm": "TacleBench", "offsetStart": 105, "offsetEnd": 115}, "context": "To validate the quality of the WCET predictions provided by CAWET, we use a subset of the codes from the TacleBench benchmark suite [13] whose characteristics are given in Table 2. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 7.212162017822266e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 0.02690976858139038}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Debugger", "normalizedForm": "Debugger", "offsetStart": 106, "offsetEnd": 114}, "context": "To provide context and assembly code for the timed BB, we retrieve the execution trace using GDB (the GNU Debugger). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999266266822815}, "created": {"value": false, "score": 6.014108657836914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999266266822815}, "created": {"value": false, "score": 6.014108657836914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 108, "offsetEnd": 113}, "context": "The results in Table 8 show that incorporating the context (A) provides the most significant improvement to CAWET, while the effects of peeking (B) and loop enrolling (C) are less substantial.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9792065024375916}, "created": {"value": false, "score": 3.68952751159668e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 120, "offsetEnd": 125}, "context": "The quality of WCET estimates produced by CAWET is compared to those produced by WE-HML, the HT-ML technique closest to CAWET [2], on 13 programs from the TACLeBench benchmark suite [13].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9981773495674133}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2, "offsetStart": 6419, "offsetEnd": 6422}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2, "offsetStart": 6419, "offsetEnd": 6422}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 121, "offsetEnd": 126}, "context": "[2] accounts for data caches by simulating the worst possible data access pattern for basic blocks within loops, whereas CAWET relies on static analysis through the Heptane tool [16] to obtain less pessimistic estimations of data cache behavior.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004552006721496582}, "created": {"value": false, "score": 6.854534149169922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TacleBench", "normalizedForm": "TacleBench", "offsetStart": 121, "offsetEnd": 131}, "context": "The technique is demonstrated to be empirically reliable and less pessimistic than its competitors in experiments on the TacleBench benchmarks for different target processors. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04358172416687012}, "created": {"value": false, "score": 0.00016736984252929688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": false, "score": 0.02690976858139038}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 122, "offsetEnd": 127}, "context": "Table 6 evaluates WCET predictions produced by CAWET and the baseline NN for the Cortex M7, using a context size of 6 for CAWET.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9660333395004272}, "created": {"value": false, "score": 2.086162567138672e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 127, "offsetEnd": 132}, "context": "While there are still challenges to be addressed, such as the need for more accurate context for less pessimistic predictions, CAWET offers a promising solution for predicting worst-case execution times for Commercial off-the-shelf processors. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012022256851196289}, "created": {"value": false, "score": 0.05864232778549194}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CodeNet", "normalizedForm": "CodeNet", "offsetStart": 130, "offsetEnd": 141}, "context": "We have pre-trained CAWET on a large number of BBs in order for the Transformer to learn the assembly language under study, using CodeNet [28]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997190237045288}, "created": {"value": false, "score": 0.0039601922035217285}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997190237045288}, "created": {"value": false, "score": 0.02566242218017578}, "shared": {"value": false, "score": 1.138448715209961e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 138, "offsetEnd": 143}, "context": "Two factors explain this additional pessimism: (i) the static cache analysis for random cache replacement is inherently pessimistic; (ii) CAWET already captures parts of the cache behavior due to its use of the execution contexts for BBs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005611300468444824}, "created": {"value": false, "score": 1.1980533599853516e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 145, "offsetEnd": 150}, "context": "Similarly, CATREEN [1] uses stacked LSTMs to forecast the average execution time of basic blocks in a contextualized manner, but it differs from CAWET in its focus on average execution time rather than worst-case execution time.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004032254219055176}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "wikidataId": "Q3491191", "wikipediaExternalRef": 4464255, "lang": "en", "confidence": 0.6913, "software-name": {"rawForm": "objdump", "normalizedForm": "objdump", "wikidataId": "Q3491191", "wikipediaExternalRef": 4464255, "lang": "en", "confidence": 0.6913, "offsetStart": 145, "offsetEnd": 152}, "context": "It contains approximately 900,000 C programs, which we cross-compile to the target architecture and disassemble using GNU binary utilities using objdump. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02897655963897705}, "created": {"value": false, "score": 5.1915645599365234e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02897655963897705}, "created": {"value": false, "score": 8.946657180786133e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 155, "offsetEnd": 160}, "context": "The challenge of accurately estimating the WCET of programs has led to the development of various hybrid timing analysis techniques that are compared with CAWET below.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001080632209777832}, "created": {"value": false, "score": 0.00928795337677002}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "TACLeBench", "normalizedForm": "TACLeBench", "offsetStart": 155, "offsetEnd": 165}, "context": "The quality of WCET estimates produced by CAWET is compared to those produced by WE-HML, the HT-ML technique closest to CAWET [2], on 13 programs from the TACLeBench benchmark suite [13]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9981773495674133}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9981773495674133}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 157, "offsetEnd": 162}, "context": "Even though these two studies rely heavily on ML, they focus on contention prediction on multi-core targets and not on WCET prediction for single-cores like CAWET.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3435279130935669}, "created": {"value": false, "score": 9.268522262573242e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 159, "offsetEnd": 164}, "context": "This issue is addressed by restricting the number of BBs added by the unrolling process for the loop body to a fixed value, the hyperparameter context size of CAWET.", "mentionContextAttributes": {"used": {"value": false, "score": 0.009358882904052734}, "created": {"value": false, "score": 0.00013518333435058594}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Heptane", "normalizedForm": "Heptane", "offsetStart": 161, "offsetEnd": 168}, "context": "accounts for data caches by simulating the worst possible data access pattern for basic blocks within loops, whereas CAWET relies on static analysis through the Heptane tool [16] to obtain less pessimistic estimations of data cache behavior. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002745389938354492}, "created": {"value": false, "score": 4.947185516357422e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16, "offsetStart": 33814, "offsetEnd": 33818}, {"label": "[16]", "normalizedForm": "[16]", "refKey": 16, "offsetStart": 33814, "offsetEnd": 33818}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 172, "offsetEnd": 177}, "context": "Table 9 shows the Maximum Observed Execution Times (MOET) and Relative Percentage Error (RPE) for all considered techniques: probabilistic WCET estimation, WE-HML, Vanilla CAWET, and CAWET modified with the results of static cache analysis.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9974324107170105}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Ozone", "normalizedForm": "Ozone", "offsetStart": 172, "offsetEnd": 181}, "context": "The J-Trace Pro trace solution from Segger [31] is used to connect to the JTAG interface of the target processor (in our case Cortex-M4 and Cortex-M7), in conjunction with Ozone [14], a cross-platform debugger and performance analyzer. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.523331344127655}, "created": {"value": false, "score": 1.1146068572998047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.523331344127655}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 174, "offsetEnd": 179}, "context": "The objectives of these experiments are twofold: (i) evaluate the WCET predictions produced by CAWET for a more complex processor than the Cortex M7; (ii) be able to compare CAWET to WE-HML [2], the related work closest to CAWET, that targets this architecture.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00354689359664917}, "created": {"value": false, "score": 0.002252817153930664}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Heptane", "normalizedForm": "Heptane", "offsetStart": 176, "offsetEnd": 183}, "context": "In this section, we analyze the effect of different features of CAWET on the Relative Percentage Error (RPE): context accounting, peek-on mechanism, loop management, and using Heptane's cache analysis.", "mentionContextAttributes": {"used": {"value": false, "score": 0.41604191064834595}, "created": {"value": false, "score": 0.0005985498428344727}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999940991401672}, "created": {"value": true, "score": 0.7462707161903381}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "references": [{"label": "[16]", "normalizedForm": "[16]", "refKey": 16}, {"label": "[16]", "normalizedForm": "[16]", "refKey": 16}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 177, "offsetEnd": 182}, "context": "We, therefore, analyze in Section 4.2 and 4.4 a technique that applies static cache analysis, and we add the overhead obtained by this analysis to the timing values produced by CAWET.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9903347492218018}, "created": {"value": false, "score": 1.9609928131103516e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 183, "offsetEnd": 188}, "context": "Table 9 shows the Maximum Observed Execution Times (MOET) and Relative Percentage Error (RPE) for all considered techniques: probabilistic WCET estimation, WE-HML, Vanilla CAWET, and CAWET modified with the results of static cache analysis.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9974324107170105}, "created": {"value": false, "score": 1.7285346984863281e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 199, "offsetEnd": 204}, "context": "Finally, CAWET is evaluated in Subsection 4.4 on a more complex processor, the Cortex-A53, using a software measurement method and an operating system, allowing us to compare the WCET predictions of CAWET with those of WE-HML [2].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993802905082703}, "created": {"value": false, "score": 3.606081008911133e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 206, "offsetEnd": 211}, "context": "The research works presented in [17,2], similarly to CAWET, propose to extract features from the binary code and to use ML techniques to predict the WCET of individual basic However, contrary to [18,17,2], CAWET takes a more fine-grained approach, considering the context surrounding each basic block, and the dependencies between instructions within it to better consider hardware components such as the pipeline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007881522178649902}, "created": {"value": false, "score": 0.0014840364456176758}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 223, "offsetEnd": 228}, "context": "The objectives of these experiments are twofold: (i) evaluate the WCET predictions produced by CAWET for a more complex processor than the Cortex M7; (ii) be able to compare CAWET to WE-HML [2], the related work closest to CAWET, that targets this architecture. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00354689359664917}, "created": {"value": false, "score": 0.002252817153930664}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CAWET", "normalizedForm": "CAWET", "offsetStart": 312, "offsetEnd": 317}, "context": "We chose these codes because: (i) the programs are analyzable by static WCET estimation tools, and in particular, they contain loop-bound annotations; (ii) they come with input data known to trigger the worst-case execution paths; (iii) they are used in our closest competitor WE-HML [2], allowing us to compare CAWET with this work.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9915797710418701}, "created": {"value": false, "score": 0.00031745433807373047}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997546672821045}, "created": {"value": true, "score": 0.9999211430549622}, "shared": {"value": false, "score": 1.6093254089355469e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}, {"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}], "references": [{"refKey": 2, "tei": "<biblStruct xml:id=\"b2\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">We-hml: hybrid wcet estimation using machine learning for architectures with caches</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Isabelle</forename><surname>Abderaouf N Amalou</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Gilles</forename><surname>Puaut</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><surname>Muller</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">IEEE 27th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date>2021. 2021</date>\n\t\t\t<biblScope unit=\"page\">40</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 16, "tei": "<biblStruct xml:id=\"b16\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Static probabilistic worst case execution time estimation for architectures with faulty instruction caches</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Damien</forename><surname>Hardy</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Isabelle</forename><surname>Puaut</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/2516821.2516842</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 21st International conference on Real-Time Networks and Systems</title>\n\t\t<meeting>the 21st International conference on Real-Time Networks and Systems</meeting>\n\t\t<imprint>\n\t\t\t<publisher>ACM</publisher>\n\t\t\t<date type=\"published\" when=\"2013-10-16\">2017</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 46345, "id": "e62efc0c1169d421ba6048edf5fe822d3b905d35", "metadata": {"id": "e62efc0c1169d421ba6048edf5fe822d3b905d35"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_files/hal-04148587.grobid.tei.xml", "file_name": "hal-04148587.grobid.tei.xml"}