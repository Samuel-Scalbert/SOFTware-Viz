{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:43+0000", "md5": "F0487D755C111BF70DADCEA9E47DA9F5", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 0, "offsetEnd": 11}, "context": "LibriSpeech is one of the first largescale open-source datasets and contains over 1000 hours of audio books, together with textual annotations aligned at the sentence level. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014531612396240234}, "created": {"value": false, "score": 0.00013959407806396484}, "shared": {"value": false, "score": 2.0265579223632812e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 18, "offsetEnd": 29}, "context": "The same official LibriSpeech 4-gram LM is used in both decoding procedures. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.054007649421691895}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 31, "offsetEnd": 47}, "context": "The test sets are identical to LibriSpeech [12] so as to facilitate comparison of weakly supervised results with the state-of-the art in supervised learning. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9001188278198242}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 37, "offsetEnd": 39}, "context": "The same official LibriSpeech 4-gram LM is used in both decoding procedures.", "mentionContextAttributes": {"used": {"value": false, "score": 0.054007649421691895}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "PyTorch", "normalizedForm": "PyTorch", "offsetStart": 38, "offsetEnd": 45}, "context": "In the unsupervised setting, we use a PyTorch implementation of the Contrastive Predictive Coding (CPC) system [7] trained to predict the hidden states of N future speech frames and containing an encoder, a sequence model, and a predictor. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965795874595642}, "created": {"value": false, "score": 0.0004100203514099121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9965795874595642}, "created": {"value": false, "score": 0.0004100203514099121}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 39, "offsetEnd": 50}, "context": "Because the dev and test sets are from LibriSpeech, this allows to compare distant supervision directly with SOTA supervised models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9723934531211853}, "created": {"value": false, "score": 3.409385681152344e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "phonemizer", "normalizedForm": "phonemizer", "offsetStart": 41, "offsetEnd": 51}, "context": "https://gitlab.coml.lscp.ens.fr/mbernard/phonemizer", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017648935317993164}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": true, "score": 0.8291302919387817}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0029324889183044434}, "created": {"value": false, "score": 0.0002918839454650879}, "shared": {"value": true, "score": 0.8291302919387817}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 46, "offsetEnd": 63}, "context": "The dev and test sets are the same as that of LibriSpeech (5.4  For training a language model in the distant supervision setting, we consider the LM corpus provided in LibriSpeech 7 which contains 800M tokens and a vocabulary size of 200k from 14.5k public books from Project Gutenberg. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7090106010437012}, "created": {"value": false, "score": 3.528594970703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wav", "normalizedForm": "wav", "offsetStart": 47, "offsetEnd": 50}, "context": "We decode with a python wrapped version of the wav2letter++ decoder [18], using a 4-gram KenLM [22] language model trained on the unaligned text set. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9958508014678955}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 0.006395161151885986}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[18]", "normalizedForm": "[18]", "refKey": 18}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSLR", "normalizedForm": "OpenSLR", "offsetStart": 47, "offsetEnd": 56}, "context": "Other open-source resources are available from OpenSLR 3 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013196468353271484}, "created": {"value": false, "score": 0.0003139972686767578}, "shared": {"value": false, "score": 0.39572739601135254}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013196468353271484}, "created": {"value": false, "score": 0.0003139972686767578}, "shared": {"value": false, "score": 0.39572739601135254}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 57, "offsetEnd": 68}, "context": "We additionally provide orthographic transcriptions from LibriSpeech and phonetic transcriptions generated from phonemizer 6 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0029324889183044434}, "created": {"value": false, "score": 0.0002918839454650879}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wav", "normalizedForm": "wav", "offsetStart": 61, "offsetEnd": 64}, "context": "We then ran a Voice Activity Detection (VAD) model using the wav2letter++ framework [18] on the recordings to tag onsets and offsets of speech segments.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 0.006395161151885986}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 0.006395161151885986}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[18]", "normalizedForm": "[18]", "refKey": 18}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wav", "normalizedForm": "wav", "offsetStart": 65, "offsetEnd": 68}, "context": "Top: small phone-based TDS [23] models with limited labels using wav2letter++ [18], generating pseudolabels on the 60K dataset with an in-domain LM, retraining a larger TDS acoustic model (PER).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010126233100891113}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999905824661255}, "created": {"value": false, "score": 0.006395161151885986}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "[18]", "normalizedForm": "[18]", "refKey": 18, "offsetStart": 19066, "offsetEnd": 19070}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 72, "offsetEnd": 83}, "context": "For training with limited supervision, we selected three subsets of the LibriSpeech training set: a 10 hour set, a 1 hour set, and six 10-minute sets (the six 10-minute sets together make up the 1h set, and the 1h set is included in the 10h set). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": false, "score": 8.535385131835938e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 82, "offsetEnd": 84}, "context": "For training a language model in the distant supervision setting, we consider the LM corpus provided in LibriSpeech 7 which contains 800M tokens and a vocabulary size of 200k from 14.5k public books from Project Gutenberg.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014593005180358887}, "created": {"value": false, "score": 0.0008775591850280762}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "wav2", "normalizedForm": "wav2", "offsetStart": 89, "offsetEnd": 93}, "context": "The trained model was used to perform inference (greedy frame-byframe decoding) with the wav2letter++ [18] audio analysis pipeline on the unlabeled audio by mapping all of the letters to SPEECH and the silence symbol to NONSPEECH. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999908208847046}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999908208847046}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "references": [{"label": "[18]", "normalizedForm": "[18]", "refKey": 18, "offsetStart": 13477, "offsetEnd": 13481}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 100, "offsetEnd": 111}, "context": "We then removed corrupted files, files with unknown or multiple speakers, and speakers appearing in LibriSpeech dev and test sets.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9952439665794373}, "created": {"value": false, "score": 0.009074926376342773}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 108, "offsetEnd": 119}, "context": "Voice Activity Detection is accomplished using a TDS acoustic model [23] trained using CTC loss [28] on the LibriSpeech dataset using the orthographic transcription.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993232488632202}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "phonemizer", "normalizedForm": "phonemizer", "offsetStart": 112, "offsetEnd": 124}, "context": "We additionally provide orthographic transcriptions from LibriSpeech and phonetic transcriptions generated from phonemizer 6 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0029324889183044434}, "created": {"value": false, "score": 0.0002918839454650879}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0029324889183044434}, "created": {"value": false, "score": 0.0002918839454650879}, "shared": {"value": true, "score": 0.8291302919387817}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 117, "offsetEnd": 128}, "context": "We create pseudo-labels by beam-search decoding the 60k-hours unlabelled data with a 4-gram KenLM decoder trained on LibriSpeech-LM. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.051116228103637695}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 129, "offsetEnd": 131}, "context": "We create pseudo-labels by beam-search decoding the 60k-hours unlabelled data with a 4-gram KenLM decoder trained on LibriSpeech-LM. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.051116228103637695}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 143, "offsetEnd": 145}, "context": "Middle: A CPC system trained with unlabelled speech, finetuned with limited data and integrated with a 4-gram word language model (Librispeech-LM).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016736984252929688}, "created": {"value": false, "score": 6.103515625e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 143, "offsetEnd": 145}, "context": "These labels are used to train larger TDS systems (11 TDS blocks, 37M parameters) from scratch which generate WERs when decoding with the same LM.", "mentionContextAttributes": {"used": {"value": false, "score": 0.030626893043518066}, "created": {"value": false, "score": 2.467632293701172e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 145, "offsetEnd": 147}, "context": "Top: small phone-based TDS [23] models with limited labels using wav2letter++ [18], generating pseudolabels on the 60K dataset with an in-domain LM, retraining a larger TDS acoustic model (PER).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010126233100891113}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 168, "offsetEnd": 179}, "context": "The dev and test sets are the same as that of LibriSpeech (5.4  For training a language model in the distant supervision setting, we consider the LM corpus provided in LibriSpeech 7 which contains 800M tokens and a vocabulary size of 200k from 14.5k public books from Project Gutenberg. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7090106010437012}, "created": {"value": false, "score": 3.528594970703125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 284, "offsetEnd": 295}, "context": "The TDS models above and generated pseudo-labels are trained and generated with the exactly the same procedure introduced in Section 4. Note that the PER/CER results above are not comparable to the semi-supervised ones in Table 3 as pseudo-labels here are generated with the official LibriSpeech LM, whose training set is a super-set of the transcriptions in the supervised training set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997010827064514}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 2.0265579223632812e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LM", "normalizedForm": "LM", "offsetStart": 296, "offsetEnd": 298}, "context": "The TDS models above and generated pseudo-labels are trained and generated with the exactly the same procedure introduced in Section 4. Note that the PER/CER results above are not comparable to the semi-supervised ones in Table 3 as pseudo-labels here are generated with the official LibriSpeech LM, whose training set is a super-set of the transcriptions in the supervised training set.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9945995807647705}, "created": {"value": true, "score": 0.9753795862197876}, "shared": {"value": false, "score": 4.76837158203125e-07}}}], "references": [{"refKey": 18, "tei": "<biblStruct xml:id=\"b18\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Wav2Letter++: A Fast Open-source Speech Recognition System</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vineel</forename><surname>Pratap</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Awni</forename><surname>Hannun</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Qiantong</forename><surname>Xu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jeff</forename><surname>Cai</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jacob</forename><surname>Kahn</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Gabriel</forename><surname>Synnaeve</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vitaliy</forename><surname>Liptchinsky</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ronan</forename><surname>Collobert</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2019.8683535</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2019-05\">2019</date>\n\t\t\t<biblScope unit=\"page\">6464</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 15649, "id": "b2ab955966d75fc54372820ab7bc1c84a620ffcc", "metadata": {"id": "b2ab955966d75fc54372820ab7bc1c84a620ffcc"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02959460.grobid.tei.xml", "file_name": "hal-02959460.grobid.tei.xml"}