{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:38+0000", "md5": "E67363218208D74141AE09BB37B02078", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Kaldi", "normalizedForm": "Kaldi", "offsetStart": 16, "offsetEnd": 26}, "context": "Although we use Kaldi [24] to implement ASVeval, we do not use it to compute the EER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996906518936157}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9996906518936157}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "cllr", "normalizedForm": "cllr", "offsetStart": 34, "offsetEnd": 38}, "context": "https://gitlab.eurecom.fr/nautsch/cllr", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019425153732299805}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": true, "score": 0.8044913411140442}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": true, "score": 0.8044913411140442}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 38, "offsetEnd": 49}, "context": "Due to space limitations, we focus on LibriSpeech here. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.027004718780517578}, "created": {"value": true, "score": 0.9274759292602539}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": true, "score": 0.9274759292602539}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ASVeval", "normalizedForm": "ASVeval", "offsetStart": 40, "offsetEnd": 47}, "context": "Although we use Kaldi [24] to implement ASVeval, we do not use it to compute the EER. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996906518936157}, "created": {"value": false, "score": 2.5987625122070312e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 7.68899917602539e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ASVeval", "normalizedForm": "ASVeval", "offsetStart": 41, "offsetEnd": 48}, "context": "Instead we use the PLDA scores output by ASVeval as inputs to the cllr toolkit3 to compute the ROCCH-EER [25]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 7.68899917602539e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "cllr", "normalizedForm": "cllr", "offsetStart": 66, "offsetEnd": 70}, "context": "Instead we use the PLDA scores output by ASVeval as inputs to the cllr toolkit3 to compute the ROCCH-EER [25]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 2.5033950805664062e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 8.106231689453125e-06}, "shared": {"value": true, "score": 0.8044913411140442}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ASVeval", "normalizedForm": "ASVeval", "offsetStart": 70, "offsetEnd": 77}, "context": "The EER is computed from the distribution of PLDA scores generated by ASVeval. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9980579018592834}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 7.68899917602539e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 78, "offsetEnd": 94}, "context": "2 VoxCeleb-1,2 [20,21] and the train-clean-100 and train-other-500 subsets of LibriSpeech [22] and LibriTTS [23] are used to train the models described in Section 2. The development and test sets are built from LibriSpeech dev-clean and test-clean, respectively. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": true, "score": 0.9274759292602539}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriTTS", "normalizedForm": "LibriTTS", "offsetStart": 99, "offsetEnd": 112}, "context": "2 VoxCeleb-1,2 [20,21] and the train-clean-100 and train-other-500 subsets of LibriSpeech [22] and LibriTTS [23] are used to train the models described in Section 2. The development and test sets are built from LibriSpeech dev-clean and test-clean, respectively. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ASVeval", "normalizedForm": "ASVeval", "offsetStart": 124, "offsetEnd": 131}, "context": "In all scenarios, the attacker implements the attack using a pretrained x-vector-PLDA based Automatic Speaker Verification (ASVeval) system.", "mentionContextAttributes": {"used": {"value": false, "score": 0.17768537998199463}, "created": {"value": false, "score": 7.68899917602539e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998737573623657}, "created": {"value": false, "score": 7.68899917602539e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 147, "offsetEnd": 158}, "context": "The final scenario is the one in which the user is most vul- 2 The VoicePrivacy Challenge involves development and evaluation sets built from both LibriSpeech and VCTK. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011993706226348877}, "created": {"value": false, "score": 0.0003033876419067383}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": true, "score": 0.9274759292602539}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 211, "offsetEnd": 222}, "context": "2 VoxCeleb-1,2 [20,21] and the train-clean-100 and train-other-500 subsets of LibriSpeech [22] and LibriTTS [23] are used to train the models described in Section 2. The development and test sets are built from LibriSpeech dev-clean and test-clean, respectively. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": false, "score": 3.337860107421875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9909548163414001}, "created": {"value": true, "score": 0.9274759292602539}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}], "references": [], "runtime": 6792, "id": "a79d27388f62b80b2d1831ea3241736c61911272", "metadata": {"id": "a79d27388f62b80b2d1831ea3241736c61911272"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02610447.grobid.tei.xml", "file_name": "hal-02610447.grobid.tei.xml"}