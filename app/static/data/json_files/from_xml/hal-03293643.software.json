{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:44+0000", "md5": "4FFEF49C1FF7DAB6D0CD856CF3417944", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 0, "offsetEnd": 7}, "context": "SciBERT, in particular, has been pretrained on 1.14 million papers in the scientific corpus (18% from computer science, 82% from biomedicine), which may make the vocabulary learned more useful for our task than that of language models trained on other corpora; SciBERT [2] shows for instance better performance in sentence classification over scientific articles (ACL-ARC) in Computer Science than BERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6007450222969055}, "created": {"value": false, "score": 3.3855438232421875e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "sklearn-crfsuite", "normalizedForm": "sklearn-crfsuite", "offsetStart": 7, "offsetEnd": 23}, "context": "We use sklearn-crfsuite to perform the training. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999494552612305}, "created": {"value": false, "score": 2.872943878173828e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999494552612305}, "created": {"value": false, "score": 2.872943878173828e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 76, "offsetEnd": 83}, "context": "It may be surprising to see (Table 3) that language models such as Bert and SciBERT taking only information at an individual line level and disregarding any information about lines in the sequence can maintain a validation accuracy around 0.63 on undersampled data.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000110626220703125}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 88, "offsetEnd": 95}, "context": "The language models that we do use in this work (namely, BERT [5], DistilBERT [14], and SciBERT [2]) have been pre-trained to understand the general language rules (English here).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 125, "offsetEnd": 135}, "context": "We access and evaluate the performance of several autoencoding-based models such as Bert base [5], Distil-BERT base [14] and SciBERT [2]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03867822885513306}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 261, "offsetEnd": 268}, "context": "SciBERT, in particular, has been pretrained on 1.14 million papers in the scientific corpus (18% from computer science, 82% from biomedicine), which may make the vocabulary learned more useful for our task than that of language models trained on other corpora; SciBERT [2] shows for instance better performance in sentence classification over scientific articles (ACL-ARC) in Computer Science than BERT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6007450222969055}, "created": {"value": false, "score": 3.3855438232421875e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2, "offsetStart": 3657, "offsetEnd": 3660}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SciBERT", "normalizedForm": "SciBERT", "offsetStart": 303, "offsetEnd": 310}, "context": "The success of transformer-based models is heavily dependent on many crucial factors, some of them being: the quantity of data used for pretraining the model, which can be extremely large for, e.g., BERT; the number of data samples fed in for finetuning the model; the nature of content provided (e.g., SciBERT was specifically trained on a scientific corpus of papers, mostly in the biomedical domain); the size of the Encoder-Decoder stacks (BERT comes in three variants: base/small/large); the type of pretraining used (e.g., GPT-based models see everything before the next token as part of pretraining thus making them relevant for text generation tasks).", "mentionContextAttributes": {"used": {"value": false, "score": 0.3303431272506714}, "created": {"value": false, "score": 1.3470649719238281e-05}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.8269068002700806}, "created": {"value": false, "score": 0.00480806827545166}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "references": [{"label": "[2]", "normalizedForm": "[2]", "refKey": 2}]}], "references": [{"refKey": 2, "tei": "<biblStruct xml:id=\"b2\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">SciBERT: A Pretrained Language Model for Scientific Text</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Iz</forename><surname>Beltagy</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kyle</forename><surname>Lo</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Arman</forename><surname>Cohan</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/d19-1371</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>\n\t\t<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2019\">2019</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 27983, "id": "0e4d6bfea72b1dd556f3cc5098dadd8b45898e91", "metadata": {"id": "0e4d6bfea72b1dd556f3cc5098dadd8b45898e91"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03293643.grobid.tei.xml", "file_name": "hal-03293643.grobid.tei.xml"}