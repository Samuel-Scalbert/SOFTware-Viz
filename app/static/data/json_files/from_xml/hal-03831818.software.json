{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:03+0000", "md5": "7FF75024538B9A9509A2D8BFDA4192EA", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 0, "offsetEnd": 5}, "context": "pGSLM is comprised of two separately trained components: an auto-regressive Multi-Stream Transformer Language Model (MS-TLM) that predicts the next phonetic and prosodic representation given the past ones, and a unit High-Fidelity Generative Adversarial Network (HiFi-GAN) adapted from Polyak et al. (2021) that converts the MS-TLM output into a waveform like a vocoder.", "mentionContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": false, "score": 0.00016248226165771484}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 0, "offsetEnd": 6}, "context": "HuBERT units were found to perform favorably compared to other self-supervised units such as wav2vec 2.0 (Baevski et al., 2020) and VQ-VAE (van den Oord et al., 2017) in terms of lexical content modeling (Lakho-tia et al., 2021) and disentangling prosodic information (Polyak et al., 2021).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895433187484741}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastSpeech", "normalizedForm": "FastSpeech", "offsetStart": 3, "offsetEnd": 13}, "context": "As FastSpeech and FastPitch are designed to improve the inference-time efficiency from auto-regressive models like Tacotron (Wang et al., 2017), they predict prosodic features and spectrograms without introducing dependency between time steps. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010383129119873047}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Ren et al., 2020)", "normalizedForm": "Ren et al., 2020", "refKey": 33}, {"label": "(Ren et al., 2020)", "normalizedForm": "Ren et al., 2020", "refKey": 33}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CrowdMOS", "normalizedForm": "CrowdMOS", "offsetStart": 4, "offsetEnd": 12}, "context": "The CrowdMOS package (Ribeiro et al., 2011) was used for all experiments using the recommended recipes for outlier removal. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999806880950928}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999806880950928}, "created": {"value": false, "score": 1.2040138244628906e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Ribeiro et al., 2011)", "normalizedForm": "Ribeiro et al., 2011", "refKey": 34, "offsetStart": 25121, "offsetEnd": 25143}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 13, "offsetEnd": 18}, "context": "The proposed pGSLM model can be re-purposed as a text-to-speech (TTS) model when the phonetic content (represented as a unit sequence) is given and the prosody is generated by the MS-TLM model.", "mentionContextAttributes": {"used": {"value": false, "score": 7.700920104980469e-05}, "created": {"value": false, "score": 0.012867093086242676}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastPitch", "normalizedForm": "FastPitch", "offsetStart": 18, "offsetEnd": 27}, "context": "As FastSpeech and FastPitch are designed to improve the inference-time efficiency from auto-regressive models like Tacotron (Wang et al., 2017), they predict prosodic features and spectrograms without introducing dependency between time steps. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010383129119873047}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastSpeech", "normalizedForm": "FastSpeech", "offsetStart": 19, "offsetEnd": 29}, "context": "This is similar to FastSpeech (Ren et al., 2020) and FastPitch (\u0141a\u0144cucki, 2021) TTS models, where prosodic features are predicted from text and speech are generated conditioning on both the text and the predicted prosodic features.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 7.176399230957031e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Ren et al., 2020)", "normalizedForm": "Ren et al., 2020", "refKey": 33, "offsetStart": 8218, "offsetEnd": 8236}, {"label": "(Ren et al., 2020)", "normalizedForm": "Ren et al., 2020", "refKey": 33, "offsetStart": 8218, "offsetEnd": 8236}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Adam", "normalizedForm": "Adam", "offsetStart": 27, "offsetEnd": 31}, "context": "Optimization is done using Adam (Kingma and Ba, 2014) with a peak learning rate of 5e-4. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9895179867744446}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9895179867744446}, "created": {"value": false, "score": 6.67572021484375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 35, "offsetEnd": 40}, "context": "Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. 1", "mentionContextAttributes": {"used": {"value": false, "score": 0.002626776695251465}, "created": {"value": false, "score": 0.00011670589447021484}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 36, "offsetEnd": 42}, "context": "As described in Section 3.1, we use HuBERT-based unit representations. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9822092056274414}, "created": {"value": false, "score": 1.811981201171875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 44, "offsetEnd": 50}, "context": "Polyak et al. (2021) has shown that pairing HuBERT units with duration and F0 enables high-quality speech re-synthesis that preserves more prosodic information such as intonation compared to re-synthesizing with only units.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002719759941101074}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 45, "offsetEnd": 50}, "context": "We do not wish to model speaker variation in pGSLM because it is less relevant to spoken language understanding compared to prosody.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000265657901763916}, "created": {"value": false, "score": 0.05831098556518555}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 47, "offsetEnd": 58}, "context": "Both datasets represent audio books and we use LibriSpeech dev-clean and test-clean as validation and test sets. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9990392923355103}, "created": {"value": false, "score": 9.059906005859375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Panayotov et al., 2015)", "normalizedForm": "Panayotov et al., 2015", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Mechanical Turk", "normalizedForm": "Mechanical Turk", "offsetStart": 49, "offsetEnd": 64}, "publisher": {"rawForm": "Amazon", "normalizedForm": "Amazon", "offsetStart": 42, "offsetEnd": 48}, "context": "All participants were recruited using the Amazon Mechanical Turk platform. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998563528060913}, "created": {"value": false, "score": 0.00011909008026123047}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998563528060913}, "created": {"value": false, "score": 0.00011909008026123047}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 53, "offsetEnd": 64}, "context": "The same 100 prompts as (Lakhotia et al., 2021) from LibriSpeech test-other are used, and each system generates one continuation per prompt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9266425967216492}, "created": {"value": false, "score": 3.2186508178710938e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Panayotov et al., 2015)", "normalizedForm": "Panayotov et al., 2015", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastPitch", "normalizedForm": "FastPitch", "offsetStart": 53, "offsetEnd": 77}, "context": "This is similar to FastSpeech (Ren et al., 2020) and FastPitch (\u0141a\u0144cucki, 2021) TTS models, where prosodic features are predicted from text and speech are generated conditioning on both the text and the predicted prosodic features. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 7.176399230957031e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 56, "offsetEnd": 62}, "context": "In rows 9-12 we consider large MS-TLM models trained on HuBERT transcripts of LL6k.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9866913557052612}, "created": {"value": false, "score": 2.1696090698242188e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 56, "offsetEnd": 62}, "context": "This trend holds for different lexical representations (HuBERT, CPC, phone), both continuous and discrete prosodic features, and different delay factors \u03c4 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009902715682983398}, "created": {"value": false, "score": 3.838539123535156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 58, "offsetEnd": 69}, "context": "In Table 1 we report teacher-forcing metric calculated on LibriSpeech dev-clean dataset for a diverse set of models. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.0028672218322753906}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Panayotov et al., 2015)", "normalizedForm": "Panayotov et al., 2015", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 59, "offsetEnd": 84}, "context": "We choose units with a vocabulary size of 100 derived from HuBERT (Hsu et al., 2021a), a selfsupervised speech model, as the phonetic representation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4142935872077942}, "created": {"value": false, "score": 0.0001327991485595703}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 64, "offsetEnd": 70}, "context": "The frame rate of CPC and phone units is 100Hz, and is 50Hz for HuBERT units.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09570175409317017}, "created": {"value": false, "score": 1.2516975402832031e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 68, "offsetEnd": 79}, "context": "In our experiments, we train MS-TLM models on two English datasets: LibriSpeech (Panayotov et al., 2015) and a 6K-hour subset (Rivi\u00e8re and Dupoux, 2020) of Libri-Light (Kahn et al., 2020) which we refer to as LL-6K.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5279784798622131}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Panayotov et al., 2015)", "normalizedForm": "Panayotov et al., 2015", "refKey": 27, "offsetStart": 18612, "offsetEnd": 18636}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 75, "offsetEnd": 80}, "context": "In this work, we present a prosody-aware generative spoken language model (pGSLM).", "mentionContextAttributes": {"used": {"value": false, "score": 4.1484832763671875e-05}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 78, "offsetEnd": 83}, "context": "In this paper, we introduce a prosody-aware generative spoken language model (pGSLM) that jointly models phonetic content and prosody, in order to leverage prosody for comprehension, and to generate speech coherent with the prompt, which is a precursor for building speech-based dialogue systems.", "mentionContextAttributes": {"used": {"value": false, "score": 8.940696716308594e-05}, "created": {"value": true, "score": 0.9998986721038818}, "shared": {"value": false, "score": 1.9073486328125e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 78, "offsetEnd": 89}, "context": "Rows 13 & 14 and 15 & 16 contain metric values for models that are trained on LibriSpeech 960h transcribed using CPC and ground-truth phonetic units. 2 The row 1 corresponds to the prosody-ignorant baseline model of (Lakhotia et al., 2021).", "mentionContextAttributes": {"used": {"value": true, "score": 0.7706051468849182}, "created": {"value": false, "score": 1.7881393432617188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Panayotov et al., 2015)", "normalizedForm": "Panayotov et al., 2015", "refKey": 27}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Lib", "normalizedForm": "Lib", "offsetStart": 80, "offsetEnd": 83}, "context": "In rows 1-8, we report metric values for base MS-TLM models that are trained on Lib-riSpeech 960h transcribed into HuBERT-100 units.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971242547035217}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9971242547035217}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "riSpeech", "normalizedForm": "riSpeech", "offsetStart": 84, "offsetEnd": 92}, "context": "In rows 1-8, we report metric values for base MS-TLM models that are trained on Lib-riSpeech 960h transcribed into HuBERT-100 units.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971242547035217}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9971242547035217}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 85, "offsetEnd": 90}, "context": "In this section, we first describe the phonetic and prosodic representations used in pGSLM, and then introduce the two components it is comprised of: a multi-stream transformer language model and an adapted unit HiFi-GAN.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00023096799850463867}, "created": {"value": true, "score": 0.9814919829368591}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 85, "offsetEnd": 90}, "context": "In this work, we propose a text-free prosody-aware generative spoken language model, pGSLM, which models textual content and prosodic information explicitly and does not use any text supervision by leveraging self-supervised units.", "mentionContextAttributes": {"used": {"value": false, "score": 4.208087921142578e-05}, "created": {"value": true, "score": 0.9999237060546875}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 87, "offsetEnd": 93}, "context": "In Table 2 we report the continuation metrics for four large MS-TLM models, trained on HuBERT transcripts of LL-6k (they correspond to rows 9-12 in Table 1). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965816140174866}, "created": {"value": false, "score": 1.1682510375976562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 103, "offsetEnd": 109}, "context": "Specifically, these units are obtained through clustering the 6th transformer layer output of the base HuBERT model provided in (Hsu et al., 2021a) using a k-means algorithm, following the recipe of HuBERT closely.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "pGSLM", "normalizedForm": "pGSLM", "offsetStart": 106, "offsetEnd": 111}, "context": "Experimental results demonstrate that 1) joint modeling of prosody improves phonetic content modeling, 2) pGSLM can generate speech continuation co-herent with the prompt in term of the content and the prosody, and 3) proper choices of model and prosodic representation is crucial to synthesizing natural, coherent, and expressive speech.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009279251098632812}, "created": {"value": false, "score": 0.00025337934494018555}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.026379764080047607}, "created": {"value": true, "score": 0.9999346733093262}, "shared": {"value": false, "score": 1.9073486328125e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 115, "offsetEnd": 121}, "context": "In rows 1-8, we report metric values for base MS-TLM models that are trained on Lib-riSpeech 960h transcribed into HuBERT-100 units.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9971242547035217}, "created": {"value": false, "score": 8.58306884765625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LibriSpeech", "normalizedForm": "LibriSpeech", "offsetStart": 122, "offsetEnd": 133}, "context": "On the other hand, frame-level phone transcripts are obtained through forced-alignment using the tri6b model from Kaldi's LibriSpeech recipe (Povey et al., 2011).", "mentionContextAttributes": {"used": {"value": true, "score": 0.6197078227996826}, "created": {"value": false, "score": 7.62939453125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9991568326950073}, "created": {"value": false, "score": 0.10050314664840698}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "references": [{"label": "(Povey et al., 2011)", "normalizedForm": "Povey et al., 2011", "refKey": 30, "offsetStart": 19445, "offsetEnd": 19465}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 130, "offsetEnd": 136}, "context": "For instance, this holds in the case of the continuous-F0 models (rows 9 & 11: 1.513 vs. 1.421) and, equally for the quantized F0 HuBERT-based models (rows 10 and 12: 1.522 vs. 1.406).", "mentionContextAttributes": {"used": {"value": false, "score": 0.3899424076080322}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastSpeech2", "normalizedForm": "FastSpeech2", "offsetStart": 159, "offsetEnd": 189}, "context": "A straightforward solution to encode prosody streams d and lf is to represent them as continuous values and minimize an L1 or L2 loss for training, similar to FastSpeech2 (Ren et al., 2020) and FastPitch (\u0141a\u0144cucki, 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 5.269050598144531e-05}, "created": {"value": false, "score": 8.58306884765625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 5.269050598144531e-05}, "created": {"value": false, "score": 8.58306884765625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FastPitch", "normalizedForm": "FastPitch", "offsetStart": 194, "offsetEnd": 219}, "context": "A straightforward solution to encode prosody streams d and lf is to represent them as continuous values and minimize an L1 or L2 loss for training, similar to FastSpeech2 (Ren et al., 2020) and FastPitch (\u0141a\u0144cucki, 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 5.269050598144531e-05}, "created": {"value": false, "score": 8.58306884765625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008241534233093262}, "created": {"value": false, "score": 0.28442323207855225}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HuBERT", "normalizedForm": "HuBERT", "offsetStart": 199, "offsetEnd": 205}, "context": "Specifically, these units are obtained through clustering the 6th transformer layer output of the base HuBERT model provided in (Hsu et al., 2021a) using a k-means algorithm, following the recipe of HuBERT closely. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9989522695541382}, "created": {"value": false, "score": 0.00023025274276733398}, "shared": {"value": false, "score": 9.5367431640625e-07}}}], "references": [{"refKey": 33, "tei": "<biblStruct xml:id=\"b33\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yi</forename><surname>Ren</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Chenxu</forename><surname>Hu</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Xu</forename><surname>Tan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tao</forename><surname>Qin</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sheng</forename><surname>Zhao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zhou</forename><surname>Zhao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tie-Yan</forename><surname>Liu</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:2006.04558</idno>\n\t\t<title level=\"m\">Fastspeech 2: Fast and high-quality end-to-end text to speech</title>\n\t\t<imprint>\n\t\t\t<date>2020</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 34, "tei": "<biblStruct xml:id=\"b34\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">CROWDMOS: An approach for crowdsourcing mean opinion score studies</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Flavio</forename><surname>Ribeiro</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Dinei</forename><surname>Florencio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Cha</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Michael</forename><surname>Seltzer</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2011.5946971</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2011-05\">2011</date>\n\t\t\t<biblScope unit=\"page\" from=\"2416\" to=\"2419\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 27, "tei": "<biblStruct xml:id=\"b27\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Librispeech: An ASR corpus based on public domain audio books</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vassil</forename><surname>Panayotov</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guoguo</forename><surname>Chen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><surname>Povey</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sanjeev</forename><surname>Khudanpur</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1109/icassp.2015.7178964</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE</publisher>\n\t\t\t<date type=\"published\" when=\"2015-04\">2015</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 30, "tei": "<biblStruct xml:id=\"b30\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">The kaldi speech recognition toolkit</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Daniel</forename><surname>Povey</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Arnab</forename><surname>Ghoshal</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Gilles</forename><surname>Boulianne</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Lukas</forename><surname>Burget</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ondrej</forename><surname>Glembek</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nagendra</forename><surname>Goel</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Mirko</forename><surname>Hannemann</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Petr</forename><surname>Motlicek</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yanmin</forename><surname>Qian</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Petr</forename><surname>Schwarz</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">IEEE 2011 workshop on automatic speech recognition and understanding</title>\n\t\t<imprint>\n\t\t\t<publisher>IEEE Signal Processing Society</publisher>\n\t\t\t<date>2011</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 10342, "id": "938f7dcb4d1b74fbdd557d9c90b717703d20e50b", "metadata": {"id": "938f7dcb4d1b74fbdd557d9c90b717703d20e50b"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03831818.grobid.tei.xml", "file_name": "hal-03831818.grobid.tei.xml"}