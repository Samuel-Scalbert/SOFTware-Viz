{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:52+0000", "md5": "788D3BDD66F64EFA43C17CB19A4BF3AA", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 0, "offsetEnd": 7}, "context": "HatEval test set is part of a shared task, and similar in-corpus performance have been reported in prior work (Caselli et al., 2021). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0031737089157104492}, "created": {"value": false, "score": 0.00022560358047485352}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 4, "offsetEnd": 11}, "context": "For HatEval, we use the standard partition of the shared task, whereas the other two datasets are randomly split into train (80%),development (10%), and test (10%). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7570944428443909}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 9, "offsetEnd": 16}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 32, "offsetEnd": 40}, "context": "Finally, in the combined model (HateBERT+U-TDLM), the concatenated vector [T c ; C] is passed through a final FC and a softmax classification layer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.41464900970458984}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 43, "offsetEnd": 51}, "context": "A contextualised representation model like HateBERT can achieve great levels of performance on the abusive language detection task, only when the evaluation dataset does not differ from the training set.", "mentionContextAttributes": {"used": {"value": false, "score": 3.266334533691406e-05}, "created": {"value": false, "score": 0.00017815828323364258}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 52, "offsetEnd": 60}, "context": "Besides, we first perform supervised fine-tuning of HateBERT 1 on the train set of the source corpus.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CrazyTokenizer", "normalizedForm": "CrazyTokenizer", "offsetStart": 57, "offsetEnd": 72}, "context": "Hashtags are split into constituent words using the tool CrazyTokenizer3 , and words are converted into lower-case. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.506909191608429}, "created": {"value": false, "score": 4.4465065002441406e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.506909191608429}, "created": {"value": false, "score": 4.4465065002441406e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 69, "offsetEnd": 77}, "context": "In the individual models, the FC layers for transforming T c and the HateBERT representation have 10 and 600 hidden units, respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6697036027908325}, "created": {"value": false, "score": 3.039836883544922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 79, "offsetEnd": 87}, "context": "The count of True Negatives with the combined model remains similar to that in HateBERT (#TN for Hate-BERT + U-TDLM: 314, #TN for HateBERT: 340).", "mentionContextAttributes": {"used": {"value": false, "score": 0.3806900382041931}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 80, "offsetEnd": 88}, "context": "This indicates that the topic representations improve generalisation along with HateBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007077455520629883}, "created": {"value": false, "score": 6.937980651855469e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 82, "offsetEnd": 90}, "context": "The vector corresponding to the [CLS] token in the final layer of this fine-tuned HateBERT model is chosen as the Hate-BERT representation for a comment.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9405645132064819}, "created": {"value": false, "score": 0.00018733739852905273}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 92, "offsetEnd": 99}, "context": "We perform experiments on three different publicly available abusive tweet corpora, namely, HatEval (Basile et al., 2019), Waseem (Waseem and Hovy, 2016), and Davidson (Davidson et al., 2017). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4493296146392822}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 92, "offsetEnd": 99}, "context": "The first comment for this case have high weights for the abuse-related topics 3 and 7 from HatEval due to the presence of the profane word \"f*ggot\".", "mentionContextAttributes": {"used": {"value": true, "score": 0.9989339709281921}, "created": {"value": false, "score": 8.225440979003906e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 97, "offsetEnd": 105}, "context": "The combined model, on the other hand, has higher True Positives compared to those obtained from HateBERT (#TP for HateBERT+U-TDLM: 1556, #TP for HateBERT: 1267).", "mentionContextAttributes": {"used": {"value": false, "score": 0.1826343536376953}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 104, "offsetEnd": 112}, "context": "Taking these studies into account, we investigate if combining topic representation with contextualised HateBERT representations can result in better generalisability in cross-corpora abuse detection.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003499269485473633}, "created": {"value": false, "score": 0.0766669511795044}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 105, "offsetEnd": 113}, "context": "Overall, comparing the cross-corpora performances of all models, we can observe that the combined model (HateBERT + U-TDLM) either outperforms Hate-BERT or retains its performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6614787578582764}, "created": {"value": false, "score": 2.9087066650390625e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 115, "offsetEnd": 123}, "context": "The combined model, on the other hand, has higher True Positives compared to those obtained from HateBERT (#TP for HateBERT+U-TDLM: 1556, #TP for HateBERT: 1267).", "mentionContextAttributes": {"used": {"value": false, "score": 0.1826343536376953}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 130, "offsetEnd": 138}, "context": "The count of True Negatives with the combined model remains similar to that in HateBERT (#TN for Hate-BERT + U-TDLM: 314, #TN for HateBERT: 340).", "mentionContextAttributes": {"used": {"value": false, "score": 0.3806900382041931}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 132, "offsetEnd": 139}, "context": "It is shown in Table that the cross-corpora performance degrades substantially as compared to the in-corpus performance, except for HatEval which indeed has a low in-corpus performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.009287774562835693}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HatEval", "normalizedForm": "HatEval", "offsetStart": 132, "offsetEnd": 139}, "context": "As per our analysis, we found that all of these source topics are highly correlated with the abusive labels in the source corpus of HatEval.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": false, "score": 2.6226043701171875e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999707937240601}, "created": {"value": true, "score": 0.7178393602371216}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 132, "offsetEnd": 140}, "context": "Recently, Caselli et al. (2021) have \"retrained\" BERT (Devlin et al., 2019) over large-scale abusive Reddit comments to provide the HateBERT model which has displayed better generalisability in cross-corpora experiments.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011435747146606445}, "created": {"value": false, "score": 0.0012575984001159668}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 146, "offsetEnd": 154}, "context": "The combined model, on the other hand, has higher True Positives compared to those obtained from HateBERT (#TP for HateBERT+U-TDLM: 1556, #TP for HateBERT: 1267).", "mentionContextAttributes": {"used": {"value": false, "score": 0.1826343536376953}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 150, "offsetEnd": 158}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 159, "offsetEnd": 167}, "context": "While topic space representations tend to lose the exact context of a comment, combining them with Hate-BERT representations can give modest improvements over HateBERT or at the least, retain the performance of HateBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003751516342163086}, "created": {"value": false, "score": 1.6808509826660156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 211, "offsetEnd": 219}, "context": "While topic space representations tend to lose the exact context of a comment, combining them with Hate-BERT representations can give modest improvements over HateBERT or at the least, retain the performance of HateBERT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003751516342163086}, "created": {"value": false, "score": 1.6808509826660156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 221, "offsetEnd": 229}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 284, "offsetEnd": 292}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 377, "offsetEnd": 385}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "HateBERT", "normalizedForm": "HateBERT", "offsetStart": 407, "offsetEnd": 415}, "context": "Train on HatEval \u2192Test on Davidson: In this case, while U-TDLM performs considerably well, the combined model only provides a slight improvement over HateBERT, as per Table 2. U-TDLM has a higher TP when compared to both HateBERT and the combined model (#TP for U-TDLM: 1924, #TP for HateBERT+U-TDLM: 1106, #TP for Hate-BERT: 1076), with lower TN (#TN for U-TDLM: 130, #TN for HateBERT+U-TDLM: 373, #TN for HateBERT: 374).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9099377393722534}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9817870855331421}, "created": {"value": true, "score": 0.9961509704589844}, "shared": {"value": false, "score": 5.960464477539062e-07}}}], "references": [], "runtime": 6612, "id": "c10cd2da6d7166b6b5a2708220fbfa8f57968ba9", "metadata": {"id": "c10cd2da6d7166b6b5a2708220fbfa8f57968ba9"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-03212196.grobid.tei.xml", "file_name": "hal-03212196.grobid.tei.xml"}