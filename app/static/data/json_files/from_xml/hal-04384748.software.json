{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:09+0000", "md5": "89A8DA2C9126957591A7CA5C826B9410", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 16, "offsetEnd": 20}, "context": "0.38) for multi-VNMT and 0.15 (resp.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999310970306396}, "created": {"value": false, "score": 2.491474151611328e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SketchRNN", "normalizedForm": "SketchRNN", "offsetStart": 16, "offsetEnd": 25}, "context": "However, unlike SketchRNN, we use a Transformer backbone for the encoder and the decoder and train our model in a end-to-end manner on canonical parallel corpora. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018613338470458984}, "created": {"value": false, "score": 0.0003389120101928711}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0018613338470458984}, "created": {"value": true, "score": 0.9847292304039001}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 18, "offsetEnd": 22}, "context": "indicate that our VNMT model leads to embeddings that are more robust to noise even when used in a classic transformer-based NMT baseline.", "mentionContextAttributes": {"used": {"value": false, "score": 5.626678466796875e-05}, "created": {"value": true, "score": 0.9259621500968933}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 23, "offsetEnd": 27}, "context": "We can notice how both VNMT systems have a tendency to separate noisy and normalized sentences compared to Transformer, while both having higher cosine similarity than the latter.", "mentionContextAttributes": {"used": {"value": false, "score": 0.001232147216796875}, "created": {"value": false, "score": 2.276897430419922e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 30, "offsetEnd": 34}, "context": "\u2022 we report evidence that our VNMT models act as regularizers of their backbone models, leading to more robust source embeddings that can be later transferred with a relatively high performance gain in our zero-shot UCG translation scenario.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0011980533599853516}, "created": {"value": false, "score": 0.00812751054763794}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenNMT-py", "normalizedForm": "OpenNMT-py", "offsetStart": 34, "offsetEnd": 44}, "version": {"rawForm": "3", "normalizedForm": "3", "offsetStart": 45, "offsetEnd": 66}, "context": "The model has been implemented in OpenNMT-py 3 (Klein et al., 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021249055862426758}, "created": {"value": false, "score": 0.03311491012573242}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00021249055862426758}, "created": {"value": false, "score": 0.03311491012573242}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "references": [{"label": "(Klein et al., 2018)", "normalizedForm": "Klein et al., 2018", "refKey": 15, "offsetStart": 11916, "offsetEnd": 11936}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 41, "offsetEnd": 45}, "context": "Results in Table 4 provide evidence that VNMT enforces more robust embeddings, which perform consistently better over the PFSMB UGC test set compared to the baseline, the system Frozen embs giving the most consistent results over UGC. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.4819108247756958}, "created": {"value": false, "score": 2.205371856689453e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 43, "offsetEnd": 47}, "context": "We also display the results when using the VNMT-baseline baseline and the Transformer model to assess improvement of our proposed architecture. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999547004699707}, "created": {"value": false, "score": 0.002969503402709961}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 45, "offsetEnd": 49}, "context": "First, we aim to evaluate the performance of VNMT when translating a special kind of OOD texts: French socialmedia noisy UGC.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3974894881248474}, "created": {"value": false, "score": 0.21330702304840088}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 46, "offsetEnd": 50}, "context": "We evaluated our best performing model (multi-VNMT trained on OpenSubtitles) on the blind test sets described in \u00a7 5, translating another set of tests to assess whether our approach proves useful for generalization over different types of UGC.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": false, "score": 0.00024062395095825195}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 51, "offsetEnd": 55}, "context": "This is in line with the regularizing character of VNMT (Zhang et al., 2016).", "mentionContextAttributes": {"used": {"value": false, "score": 0.10206824541091919}, "created": {"value": false, "score": 0.00020688772201538086}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41, "offsetStart": 3055, "offsetEnd": 3075}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 51, "offsetEnd": 55}, "context": "It also appears that, on out-of-domain text, multi-VNMT, the approach proposed in this work, outperforms the standard Transformer model as well as the state-of-the-art VNMT model, supporting our hypothesis that considering several variational inference components allows to better capture all the variations that can be found in UGC and will result in improved translation quality.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018554925918579102}, "created": {"value": true, "score": 0.5469130873680115}, "shared": {"value": false, "score": 3.4570693969726562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 55, "offsetEnd": 68}, "context": "When trained (using the same KL annealing schedule) on OpenSubtitles (resp.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 0.0002853274345397949}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 56, "offsetEnd": 60}, "context": "\u2022 we study the performance, in a zero-shot scenario, of VNMT models and evaluate their capacity to translate French UGC into English, which resulted in a consistent improvement of translation quality;", "mentionContextAttributes": {"used": {"value": true, "score": 0.9749844074249268}, "created": {"value": false, "score": 9.846687316894531e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 59, "offsetEnd": 63}, "context": "(3) In MT, normalizing flows were recently used to improve VNMT models: Setiawan et al. (2020) show that using them in an in-domain evaluation setting results in an increase of +1.3 BLEU points on the IWSLT'14 (De-En) and +0.2 BLEU points on the WMT'18 (En-De); in a simulated out-domain evaluation, NF still improve translation quality: adding NF to the model trained on WMT'18 result in a +0.9 BLEU score improvements than the baseline Transformer system and +0.6 compared to the VNMT without using NF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9872604608535767}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "Setiawan et al. (2020)", "normalizedForm": "Setiawan et al. (2020)", "refKey": 35, "offsetStart": 7048, "offsetEnd": 7070}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 61, "offsetEnd": 65}, "context": "D KL (q \u03d5 (z|x, y)||p \u03b8 (z|x)) on the encoder side) of multi-VNMT and its ablated ver-  sion without the MDN module in an in-domain setting.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6994043588638306}, "created": {"value": false, "score": 4.172325134277344e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 61, "offsetEnd": 74}, "context": "We have performed FT using the same data configuration as in OpenSubtitles and continued training for 3 epochs from the Transformer model in Table 2 while replacing the Transformer's source embeddings by their VNMT-learned version's weights.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995567202568054}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 62, "offsetEnd": 75}, "context": "We evaluated our best performing model (multi-VNMT trained on OpenSubtitles) on the blind test sets described in \u00a7 5, translating another set of tests to assess whether our approach proves useful for generalization over different types of UGC.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": false, "score": 0.00024062395095825195}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubTest", "normalizedForm": "OpenSubTest", "offsetStart": 63, "offsetEnd": 74}, "context": "Specifically, PMUMT Noisy is the least correlated to in-domain OpenSubTest and out-ofdomain newstest'14 corpora, which points to the MDN reacting differently to content domain and UGC specificities in the noise; this observation is also supported by the associated figure. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7775275707244873}, "created": {"value": false, "score": 7.748603820800781e-06}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7775275707244873}, "created": {"value": false, "score": 2.8133392333984375e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 69, "offsetEnd": 73}, "context": "The dimension of the encoder vari-3 https://github.com/josecar25/MDN-VNMT", "mentionContextAttributes": {"used": {"value": false, "score": 0.2870216369628906}, "created": {"value": false, "score": 3.4570693969726562e-06}, "shared": {"value": true, "score": 0.9753137230873108}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SketchRNN", "normalizedForm": "SketchRNN", "offsetStart": 72, "offsetEnd": 81}, "context": "Our model adopts a variational encoder-decoder architecture inspired by SketchRNN ( \u00a72) that uses an MDN on the decoder's variational network to model multiple and independent continuous generative variational distributions. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002974867820739746}, "created": {"value": true, "score": 0.9847292304039001}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0018613338470458984}, "created": {"value": true, "score": 0.9847292304039001}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 77, "offsetEnd": 81}, "context": "MT Performance Our first experiment aims to compare the performance of multi-VNMT, the model we introduced in Section 3, to that of a \"vanilla\" Transformer model and of a state-of-the-art VNMT system using NF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006002187728881836}, "created": {"value": true, "score": 0.6717483997344971}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 77, "offsetEnd": 90}, "context": "Thus, in Table 4, we report BLEU scores for the Transformer model trained on OpenSubtitles, by either initializing the VNMT-pretrained source-side embeddings before training, or fine-tuning (FT) the system. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9873079657554626}, "created": {"value": false, "score": 4.696846008300781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 77, "offsetEnd": 90}, "context": "This system also achieves the best newstest'14 canonical OOD test set in the OpenSubtitles setup, while taking advantage of an increased robustness to UGC.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008915066719055176}, "created": {"value": false, "score": 0.00018829107284545898}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 79, "offsetEnd": 83}, "context": "We have also included the 4Square corpus (Berard et al., 2019) to validate our VNMT system on other domain of UGC (restaurant reviews).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9540455937385559}, "created": {"value": false, "score": 0.01886904239654541}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 83, "offsetEnd": 87}, "context": "In this Section, we describe several experiments aiming at understanding how multi-VNMT uncovers more robust representations than the VNMT baseline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019019842147827148}, "created": {"value": true, "score": 0.9994208812713623}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 84, "offsetEnd": 88}, "context": "In this work, we focus on a specific latent variable model for MT, Variational NMT (VNMT) (Zhang et al., 2016) which has been reported to have good performance and interesting adaptability properties (Przystupa, 2020;Xiao et al., 2020).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00034606456756591797}, "created": {"value": true, "score": 0.9989272952079773}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41, "offsetStart": 1657, "offsetEnd": 1677}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 86, "offsetEnd": 90}, "context": "Transferring learning representations As discussed above, in Figure 3 we noticed that VNMT seems to enforce noisy morphology modeling to the Transformer's embeddings in an implicit way. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5175889730453491}, "created": {"value": false, "score": 0.00012171268463134766}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SketchRNN", "normalizedForm": "SketchRNN", "offsetStart": 88, "offsetEnd": 116}, "context": "In the past, MDN has been used to address sequence-tosequence generative tasks, such as SketchRNN (Ha and Eck, 2018) and modeling of sequential environment states in reinforcement learning (Ha and Schmidhuber, 2018).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013709068298339844}, "created": {"value": false, "score": 0.0005579590797424316}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0018613338470458984}, "created": {"value": true, "score": 0.9847292304039001}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 92, "offsetEnd": 96}, "context": "Furthermore, to account for the diversity of UGC phenomena, we introduce a new extension of VNMT that relies on Mixture Density Networks (Bishop, 1994) and Normalizing Flows (Rezende and Mohamed, 2015).", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010347366333007812}, "created": {"value": true, "score": 0.998900294303894}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 94, "offsetEnd": 98}, "context": "In the following, we will first describe the general architecture of our model, denoted multi-VNMT, and then detail the encoder and decoder parameters.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011706352233886719}, "created": {"value": true, "score": 0.9990159273147583}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 99, "offsetEnd": 103}, "context": "In a sequence-to-sequence MT task, where x and y are respectively the source and target sentences, VNMT (Zhang et al., 2016) architectures assume there exists an hidden variable z modeling the implicit structure (i.e.", "mentionContextAttributes": {"used": {"value": false, "score": 0.021620512008666992}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41, "offsetStart": 4606, "offsetEnd": 4626}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 106, "offsetEnd": 110}, "context": "We report such results in Table 5, where we can see that, when translating our blind UGC test sets, multi-VNMT consistently outperforms the baselines.", "mentionContextAttributes": {"used": {"value": false, "score": 0.3246275782585144}, "created": {"value": false, "score": 0.0001690387725830078}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 113, "offsetEnd": 117}, "context": "We observe that the average cosine similarity between the noisy and normalized learning representations of multi-VNMT is 0.36 compared to an average similarity of 0.26 for the representations of VNMT-baseline, sug- gesting that the former provides more robust representations of UGC than the latter, a conclusion supported by the distribution of similarities shown in Figure 2.", "mentionContextAttributes": {"used": {"value": true, "score": 0.957427442073822}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 118, "offsetEnd": 122}, "context": "Training for, at most, 300K training iterations on a single Nvidia V100 took about 40 hours to converge for the multi-VNMT models, 34 hours for VNMT-baseline and 28 hours for the non-latent Transformer baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992412328720093}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 119, "offsetEnd": 123}, "context": "Thus, in Table 4, we report BLEU scores for the Transformer model trained on OpenSubtitles, by either initializing the VNMT-pretrained source-side embeddings before training, or fine-tuning (FT) the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9873079657554626}, "created": {"value": false, "score": 4.696846008300781e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SACREBLEU", "normalizedForm": "SACREBLEU", "offsetStart": 122, "offsetEnd": 144}, "context": "Protocols Translation quality was evaluated using BLEU (Papineni et al., 2002) and chrF2 (Popovic, 2017) both computed by SACREBLEU (Post, 2018) with the 'intl' tokenization, after detokenizing the systems outputs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999814033508301}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999814033508301}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 134, "offsetEnd": 138}, "context": "In this Section, we describe several experiments aiming at understanding how multi-VNMT uncovers more robust representations than the VNMT baseline.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019019842147827148}, "created": {"value": true, "score": 0.9994208812713623}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubTest", "normalizedForm": "OpenSubTest", "offsetStart": 141, "offsetEnd": 152}, "context": "Comparing the visualization in Figure 6, we can notice how the noisy UGC PMUMT and the out-of-domain newstest'14, diverge from the in-domain OpenSubTest and normalized UGC PMUMT corpus. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.35946446657180786}, "created": {"value": false, "score": 1.4543533325195312e-05}, "shared": {"value": false, "score": 9.5367431640625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7775275707244873}, "created": {"value": false, "score": 2.8133392333984375e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 144, "offsetEnd": 148}, "context": "Training for, at most, 300K training iterations on a single Nvidia V100 took about 40 hours to converge for the multi-VNMT models, 34 hours for VNMT-baseline and 28 hours for the non-latent Transformer baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992412328720093}, "created": {"value": false, "score": 1.1205673217773438e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 156, "offsetEnd": 160}, "context": "More precisely, we compare the source-side embeddings of the 400 original noisy UGC sentences and their corresponding 400 fullynormalized versions built by VNMT-baseline and multi-VNMT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984063506126404}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 165, "offsetEnd": 169}, "context": "\u2022 by probing the learned latent representations, we show the importance of using several latent distributions to model UGC and the positive impact of the ability of VNMT models to discriminate between noisy and regular sentences while maintaining their representation closer in the embedding space;", "mentionContextAttributes": {"used": {"value": true, "score": 0.6982226967811584}, "created": {"value": false, "score": 0.005473673343658447}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 168, "offsetEnd": 172}, "context": "It also appears that, on out-of-domain text, multi-VNMT, the approach proposed in this work, outperforms the standard Transformer model as well as the state-of-the-art VNMT model, supporting our hypothesis that considering several variational inference components allows to better capture all the variations that can be found in UGC and will result in improved translation quality.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00018554925918579102}, "created": {"value": true, "score": 0.5469130277633667}, "shared": {"value": false, "score": 3.4570693969726562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 180, "offsetEnd": 184}, "context": "More precisely, we compare the source-side embeddings of the 400 original noisy UGC sentences and their corresponding 400 fullynormalized versions built by VNMT-baseline and multi-VNMT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9984063506126404}, "created": {"value": false, "score": 5.9604644775390625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 188, "offsetEnd": 192}, "context": "MT Performance Our first experiment aims to compare the performance of multi-VNMT, the model we introduced in Section 3, to that of a \"vanilla\" Transformer model and of a state-of-the-art VNMT system using NF.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006002187728881836}, "created": {"value": true, "score": 0.6717484593391418}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubTest", "normalizedForm": "OpenSubTest", "offsetStart": 188, "offsetEnd": 199}, "context": "On the other hand, the visualization suggests that both yellow (50-60%) and blue components (30-40% of activation) are variable across test sets, being very similar between PMUMT Norm and OpenSubTest, which could indicate that the mixture components are learning to encode different types of texts, potentially working as an implicit topic modeling module. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5434761047363281}, "created": {"value": false, "score": 2.8133392333984375e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.7775275707244873}, "created": {"value": false, "score": 2.8133392333984375e-05}, "shared": {"value": false, "score": 1.430511474609375e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 195, "offsetEnd": 199}, "context": "We observe that the average cosine similarity between the noisy and normalized learning representations of multi-VNMT is 0.36 compared to an average similarity of 0.26 for the representations of VNMT-baseline, sug- gesting that the former provides more robust representations of UGC than the latter, a conclusion supported by the distribution of similarities shown in Figure 2.", "mentionContextAttributes": {"used": {"value": true, "score": 0.957427442073822}, "created": {"value": false, "score": 5.0067901611328125e-06}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 210, "offsetEnd": 214}, "context": "We have performed FT using the same data configuration as in OpenSubtitles and continued training for 3 epochs from the Transformer model in Table 2 while replacing the Transformer's source embeddings by their VNMT-learned version's weights.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995567202568054}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 212, "offsetEnd": 216}, "context": "\u2022 we introduce a new model that uses state-ofthe-art transformer as the backbone of a variational inference network to produce robust representation of noisy source sentences, and whose results outperform strong VNMT and non-latent baselines when translating UGC in a zero-shot scenario.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014925003051757812}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 239, "offsetEnd": 243}, "context": "Ablation study To better understand the impact of the different components of our model, we conduct an ablation study whose results are reported in Table 3. Overall, we obtain the best BLEU scores across all test sets for the \"full\" multi-VNMT model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8796256184577942}, "created": {"value": false, "score": 0.013009250164031982}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 260, "offsetEnd": 273}, "context": "In particular, it appears that static latent representation (z static in Table 3), where instead of sampling from the learned distributions, we retrieve their mean as output, show slightly better BLEU scores when translating the MTNT with the model trained on OpenSubtitles and the newstest'14 test set with the model trained on WMT (+0.1 improvement in the two cases). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9772943258285522}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "OpenSubtitles", "normalizedForm": "OpenSubtitles", "offsetStart": 283, "offsetEnd": 296}, "context": "It is also interesting to note that using a categorical variational version of the mixing coefficients rather than the usual choice of computing them with a softmax improves translations quality: the latter is only performing better for the newstest'14 test set when training on the OpenSubtitles corpus (\u03c0 non-latent).", "mentionContextAttributes": {"used": {"value": false, "score": 0.038401901721954346}, "created": {"value": false, "score": 1.3113021850585938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999923706054688}, "created": {"value": false, "score": 0.0005050897598266602}, "shared": {"value": false, "score": 0.0002853274345397949}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VNMT", "normalizedForm": "VNMT", "offsetStart": 482, "offsetEnd": 486}, "context": "(3) In MT, normalizing flows were recently used to improve VNMT models: Setiawan et al. (2020) show that using them in an in-domain evaluation setting results in an increase of +1.3 BLEU points on the IWSLT'14 (De-En) and +0.2 BLEU points on the WMT'18 (En-De); in a simulated out-domain evaluation, NF still improve translation quality: adding NF to the model trained on WMT'18 result in a +0.9 BLEU score improvements than the baseline Transformer system and +0.6 compared to the VNMT without using NF.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9872604608535767}, "created": {"value": false, "score": 3.814697265625e-06}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999769926071167}, "created": {"value": true, "score": 0.9997358918190002}, "shared": {"value": true, "score": 0.9753137230873108}}, "references": [{"label": "(Zhang et al., 2016)", "normalizedForm": "Zhang et al., 2016", "refKey": 41}]}], "references": [{"refKey": 41, "tei": "<biblStruct xml:id=\"b41\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Variational neural machine translation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Biao</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Deyi</forename><surname>Xiong</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jinsong</forename><surname>Su</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hong</forename><surname>Duan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Min</forename><surname>Zhang</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016</title>\n\t\t<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016</meeting>\n\t\t<imprint>\n\t\t\t<publisher>The Association for Computational Linguistics</publisher>\n\t\t\t<date>2016. November 1-4, 2016</date>\n\t\t\t<biblScope unit=\"page\">530</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 15, "tei": "<biblStruct xml:id=\"b15\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Opennmt: Neural machine translation toolkit</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Guillaume</forename><surname>Klein</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yoon</forename><surname>Kim</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Yuntian</forename><surname>Deng</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Vincent</forename><surname>Nguyen</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jean</forename><surname>Senellart</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Alexander</forename><forename type=\"middle\">M</forename><surname>Rush</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 13th Conference of the Association for Machine Translation in the Americas, AMTA 2018</title>\n\t\t<meeting>the 13th Conference of the Association for Machine Translation in the Americas, AMTA 2018</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Research Papers</publisher>\n\t\t\t<date>2018. March 17-21, 2018</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">184</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 35, "tei": "<biblStruct xml:id=\"b35\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Variational neural machine translation with normalizing flows</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Hendra</forename><surname>Setiawan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthias</forename><surname>Sperber</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Udhyakumar</forename><surname>Nallasamy</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Matthias</forename><surname>Paulik</surname></persName>\n\t\t</author>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>\n\t\t<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date>2020. July 5-10, 2020</date>\n\t\t\t<biblScope unit=\"page\">7777</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 23551, "id": "7189b28a4aebdd5500c0569548dc171d072f70f1", "metadata": {"id": "7189b28a4aebdd5500c0569548dc171d072f70f1"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04384748.grobid.tei.xml", "file_name": "hal-04384748.grobid.tei.xml"}