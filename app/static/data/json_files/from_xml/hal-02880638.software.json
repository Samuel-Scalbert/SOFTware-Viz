{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:49+0000", "md5": "5632D624DFE789234EA4B92201DB9063", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 0, "offsetEnd": 5}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Spark allows a much faster data process in contrast to transferring it through needless Hadoop MapReduce mechanisms. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.9948692321777344e-05}, "created": {"value": false, "score": 0.00028210878372192383}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 0, "offsetEnd": 5}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Spark revolves around the concept of a resilient distributed dataset (RDD) 17 , which is the Spark programming model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001971125602722168}, "created": {"value": false, "score": 0.31478309631347656}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 0, "offsetEnd": 6}, "context": "Hadoop is based on simple programming paradigms that allow a highly scalable and reliable parallel processing of high dimensional data sets. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.4928321838378906e-05}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 0, "offsetEnd": 9}, "context": "MapReduce is the core of the Hadoop framework. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005880594253540039}, "created": {"value": false, "score": 0.017611801624298096}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 0, "offsetEnd": 12}, "context": "Apache Spark is characterized by its capability of improving the system's effectiveness-which is achieved via the use of intensive memory-, its efficiency, and its high transparency for users. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.262561798095703e-05}, "created": {"value": false, "score": 0.008869409561157227}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Storm", "normalizedForm": "Apache Storm", "offsetStart": 0, "offsetEnd": 14}, "context": "Apache Storm 6 and Apache Samza7 are among the most popular stream processing frameworks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020688772201538086}, "created": {"value": false, "score": 5.1856040954589844e-05}, "shared": {"value": false, "score": 1.7881393432617188e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00020688772201538086}, "created": {"value": false, "score": 5.1856040954589844e-05}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SignificanceAttributeEval", "normalizedForm": "SignificanceAttributeEval", "offsetStart": 2, "offsetEnd": 27}, "context": "\u2022 SignificanceAttributeEval: computes the Probabilistic Significance as a two-way function (attributeclasses and classes-attribute association)", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011157989501953125}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00011157989501953125}, "created": {"value": false, "score": 2.6226043701171875e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 5, "offsetEnd": 17}, "context": "(ii) Apache Spark provides high speed benefits with a trade-off in the usage of high memory. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.604194641113281e-05}, "created": {"value": false, "score": 3.5881996154785156e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 6, "offsetEnd": 11}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "(iii) Spark is one of the well-known and certified distributed frameworks and also a mature hybrid system.", "mentionContextAttributes": {"used": {"value": false, "score": 5.2094459533691406e-05}, "created": {"value": false, "score": 0.04325664043426514}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 8, "offsetEnd": 13}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Indeed, Spark has a number of high-level libraries for working with structured data (Spark SQL 10 ), for stream processing (Spark Streaming 11 ), for machine learning (MLlib) 12 [44], and for graphs and graph-parallel computation (GraphX 13 ). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSH-dRST", "normalizedForm": "LSH-dRST", "offsetStart": 10, "offsetEnd": 18}, "context": "To do so, LSH-dRST creates the hash table based on a set of random vectors following a Gaussian distribution, referred to as the family H of hash functions. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002247035503387451}, "created": {"value": false, "score": 0.00022345781326293945}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0398828387260437}, "created": {"value": false, "score": 0.00022345781326293945}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSH-dRST", "normalizedForm": "LSH-dRST", "offsetStart": 11, "offsetEnd": 19}, "context": "Initially, LSH-dRST applies the hashing technique, i.e., LSH, to build and generate the B different buckets based on a hash table as previously explained in Section 3.1. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.003365933895111084}, "created": {"value": false, "score": 2.6345252990722656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0398828387260437}, "created": {"value": false, "score": 0.00022345781326293945}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 13, "offsetEnd": 19}, "context": "Technically, Hadoop works on top of the Hadoop Distributed File System (HDFS), which duplicates the input data files in various storage machines (nodes). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": false, "score": 0.0014182329177856445}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 13, "offsetEnd": 19}, "context": "Based on the Apache Spark framework and by applying Algorithm 3, line 1, we get the following outputs from the different Apache Spark data splits, which are presented in Table 2 and in Table 3:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823814034461975}, "created": {"value": false, "score": 8.273124694824219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 14, "offsetEnd": 19}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "The choice of Spark to design our proposed algorithm based on rough sets for big data feature selection is based on several reasons, which are as follows: (i) To offer a general solution based on a hybrid parallel framework.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00021404027938842773}, "created": {"value": true, "score": 0.9157072305679321}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSH-dRST", "normalizedForm": "LSH-dRST", "offsetStart": 16, "offsetEnd": 24}, "context": "As a next step, LSH-dRST maps the T RDD to work on each single partition in a separate and parallel way. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0398828387260437}, "created": {"value": false, "score": 1.8477439880371094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0398828387260437}, "created": {"value": false, "score": 0.00022345781326293945}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 16, "offsetEnd": 25}, "context": "After that, the MapReduce paradigm assembles all the intermediate (key', value') pairs by key via the shuffling phase. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.013153016567230225}, "created": {"value": false, "score": 5.710124969482422e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 17, "offsetEnd": 26}, "context": "Technically, the MapReduce paradigm is based on a specific data structure, which is the (key, value) pair. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002812683582305908}, "created": {"value": false, "score": 0.0009946227073669434}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 18, "offsetEnd": 27}, "context": "Based on the same MapReduce paradigm, the Spark framework could offer an immediate 10 times increase in the system's performance. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": false, "score": 0.0002790093421936035}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 18, "offsetEnd": 27}, "context": "As mentioned, the MapReduce paradigm is composed of two main tasks/phases, namely the map phase and the reduce phase, which will be the main concepts used in our developed approach (see Sections 5 and 5.2.2). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00022679567337036133}, "created": {"value": false, "score": 0.15241742134094238}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Samza", "normalizedForm": "Apache Samza", "offsetStart": 19, "offsetEnd": 32}, "context": "Apache Storm 6 and Apache Samza7 are among the most popular stream processing frameworks. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020688772201538086}, "created": {"value": false, "score": 5.1856040954589844e-05}, "shared": {"value": false, "score": 1.7881393432617188e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00020688772201538086}, "created": {"value": false, "score": 5.1856040954589844e-05}, "shared": {"value": false, "score": 1.7881393432617188e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 20, "offsetEnd": 25}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Based on the Apache Spark framework and by applying Algorithm 3, line 1, we get the following outputs from the different Apache Spark data splits, which are presented in Table 2 and in Table 3:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823814034461975}, "created": {"value": false, "score": 8.273124694824219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 24, "offsetEnd": 33}, "context": "A representation of the MapReduce framework is given in Figure 1. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.022359728813171387}, "created": {"value": false, "score": 0.0002403855323791504}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 25, "offsetEnd": 30}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "As previously mentioned, Spark is based on MapReduce [25] which is one of the most popular processing techniques and program models for distributed computing to deal with big data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.022105157375335693}, "created": {"value": false, "score": 0.00014007091522216797}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 25, "offsetEnd": 37}, "context": "To deal with this issue, Apache Spark comes into play. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00012624263763427734}, "created": {"value": false, "score": 0.3174266815185547}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 29, "offsetEnd": 35}, "context": "MapReduce is the core of the Hadoop framework. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005880594253540039}, "created": {"value": false, "score": 0.017611801624298096}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 30, "offsetEnd": 42}, "context": "In this research, we focus on Apache Spark. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003788471221923828}, "created": {"value": true, "score": 0.9994066953659058}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 36, "offsetEnd": 41}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "More precisely and in comparison to Spark, in Hadoop MapReduce multiple jobs would be adjusted together to build a data pipeline. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02076900005340576}, "created": {"value": false, "score": 0.00012099742889404297}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 39, "offsetEnd": 48}, "context": "Among the possible alternatives is the MapReduce paradigm [25], which was introduced by Google and offers a robust and efficient framework to deal with big data analysis. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013756752014160156}, "created": {"value": true, "score": 0.7155880331993103}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35, "offsetStart": 11748, "offsetEnd": 11752}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 40, "offsetEnd": 46}, "context": "Technically, Hadoop works on top of the Hadoop Distributed File System (HDFS), which duplicates the input data files in various storage machines (nodes). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": false, "score": 0.0014182329177856445}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Scala", "normalizedForm": "Scala", "offsetStart": 41, "offsetEnd": 46}, "version": {"rawForm": "2.11", "normalizedForm": "2.11", "offsetStart": 47, "offsetEnd": 51}, "context": "The LSH-dRST algorithm is implemented in Scala 2.11 within the Spark 2.1.1 framework. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008127093315124512}, "created": {"value": false, "score": 0.0023638010025024414}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0008127093315124512}, "created": {"value": false, "score": 0.0023638010025024414}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 42, "offsetEnd": 47}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Based on the same MapReduce paradigm, the Spark framework could offer an immediate 10 times increase in the system's performance.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": false, "score": 0.0002790093421936035}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 42, "offsetEnd": 48}, "context": "By applying Algorithm 6 and based on both Apache Spark splits, the output is the following:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": false, "score": 1.8358230590820312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 43, "offsetEnd": 57}, "context": "As previously mentioned, Spark is based on MapReduce [25] which is one of the most popular processing techniques and program models for distributed computing to deal with big data. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.022105157375335693}, "created": {"value": false, "score": 0.00014007091522216797}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 45, "offsetEnd": 51}, "context": "The following partitions and splits based on Apache Spark are obtained for Cl s=1 (k = 2) (Table 4 andTable 5):", "mentionContextAttributes": {"used": {"value": true, "score": 0.9934452772140503}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 45, "offsetEnd": 57}, "context": "In this paper, we mainly focus on the use of Apache Spark.", "mentionContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 46, "offsetEnd": 62}, "context": "More precisely and in comparison to Spark, in Hadoop MapReduce multiple jobs would be adjusted together to build a data pipeline. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02076900005340576}, "created": {"value": false, "score": 0.00012099742889404297}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02076900005340576}, "created": {"value": false, "score": 0.00028210878372192383}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 47, "offsetEnd": 56}, "context": "The map and the reduce concepts constitute the MapReduce paradigm, which was proposed by Google in 2004 and designed to easily scale data processing over multiple computing nodes.", "mentionContextAttributes": {"used": {"value": false, "score": 7.653236389160156e-05}, "created": {"value": true, "score": 0.9898838996887207}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 49, "offsetEnd": 54}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Adding to this specificity, the key concept that Spark offers is a Resilient Distributed Data set (RDD), which is a set of elements that are distributed across the nodes of the used cluster that can be operated on in a parallel way. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.886222839355469e-05}, "created": {"value": false, "score": 0.014581799507141113}, "shared": {"value": false, "score": 1.0728836059570312e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 49, "offsetEnd": 54}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "By applying Algorithm 6 and based on both Apache Spark splits, the output is the following:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": false, "score": 1.8358230590820312e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 52, "offsetEnd": 57}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "The following partitions and splits based on Apache Spark are obtained for Cl s=1 (k = 2) (Table 4 andTable 5):", "mentionContextAttributes": {"used": {"value": true, "score": 0.9934452772140503}, "created": {"value": false, "score": 2.2292137145996094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 52, "offsetEnd": 58}, "context": "The proposed method, named LSH-dRST, is based on an Apache Spark distributed architecture, and integrates a hashing component, which is the Locality Sensitive Hashing algorithm (LSH).", "mentionContextAttributes": {"used": {"value": false, "score": 4.9114227294921875e-05}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Weka", "normalizedForm": "Weka", "offsetStart": 53, "offsetEnd": 57}, "version": {"rawForm": "3.8.2", "normalizedForm": "3.8.2", "offsetStart": 58, "offsetEnd": 66}, "context": "Moreover, we use the Naive Bayes implementation from Weka 3.8.2 24 , again with 10-fold cross-validation.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9978018403053284}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9978018403053284}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 54, "offsetEnd": 63}, "context": "In this process, and in every level of this pipeline, MapReduce will have to read the data from the disk, and then write it back to the disk again. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003504753112792969}, "created": {"value": false, "score": 0.00036895275115966797}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 59, "offsetEnd": 64}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "The proposed method, named LSH-dRST, is based on an Apache Spark distributed architecture, and integrates a hashing component, which is the Locality Sensitive Hashing algorithm (LSH).", "mentionContextAttributes": {"used": {"value": false, "score": 4.9114227294921875e-05}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 60, "offsetEnd": 66}, "context": "LSH-dRST has a distributed architecture with respect to the Apache Spark framework for a parallel and inmemory processing job. ", "mentionContextAttributes": {"used": {"value": false, "score": 9.620189666748047e-05}, "created": {"value": false, "score": 0.00380706787109375}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 63, "offsetEnd": 68}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1", "offsetStart": 69, "offsetEnd": 74}, "context": "The LSH-dRST algorithm is implemented in Scala 2.11 within the Spark 2.1.1 framework. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008127093315124512}, "created": {"value": false, "score": 0.0023638010025024414}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 67, "offsetEnd": 72}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "LSH-dRST has a distributed architecture with respect to the Apache Spark framework for a parallel and inmemory processing job.", "mentionContextAttributes": {"used": {"value": false, "score": 9.620189666748047e-05}, "created": {"value": false, "score": 0.00380706787109375}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 72, "offsetEnd": 81}, "context": "Specifically, the evolutionary algorithms were implemented based on the MapReduce paradigm to obtain subsets of features from big data sets2 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8411574363708496}, "created": {"value": true, "score": 0.9190341234207153}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 74, "offsetEnd": 87}, "context": "Among the well-known streaming processing parallel frameworks, we mention Apache Spark8 and Apache Flink 9 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003610849380493164}, "created": {"value": false, "score": 0.010707855224609375}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Weka", "normalizedForm": "Weka", "offsetStart": 77, "offsetEnd": 81}, "version": {"rawForm": "3.8.2", "normalizedForm": "3.8.2"}, "context": "We compare LSH-dRST with a number of other feature selection techniques from Weka 3.8.2 25   \u2022 CfsSubsetEval: considers the individual predictive ability of each feature along with the degree of redundancy between them", "mentionContextAttributes": {"used": {"value": false, "score": 0.18289726972579956}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9978018403053284}, "created": {"value": false, "score": 4.291534423828125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 84, "offsetEnd": 90}, "context": "This paradigm offers an intensive scalability over a large number of nodes within a Hadoop cluster.", "mentionContextAttributes": {"used": {"value": false, "score": 3.218650817871094e-05}, "created": {"value": false, "score": 0.022421836853027344}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark SQL", "normalizedForm": "Spark SQL", "offsetStart": 85, "offsetEnd": 94}, "context": "Indeed, Spark has a number of high-level libraries for working with structured data (Spark SQL 10 ), for stream processing (Spark Streaming 11 ), for machine learning (MLlib) 12 [44], and for graphs and graph-parallel computation (GraphX 13 ). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google", "normalizedForm": "Google", "offsetStart": 88, "offsetEnd": 94}, "context": "Among the possible alternatives is the MapReduce paradigm [25], which was introduced by Google and offers a robust and efficient framework to deal with big data analysis. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013756752014160156}, "created": {"value": true, "score": 0.7155880331993103}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013756752014160156}, "created": {"value": true, "score": 0.9898838996887207}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop MapReduce", "normalizedForm": "Hadoop MapReduce", "offsetStart": 88, "offsetEnd": 104}, "context": "Spark allows a much faster data process in contrast to transferring it through needless Hadoop MapReduce mechanisms. ", "mentionContextAttributes": {"used": {"value": false, "score": 4.9948692321777344e-05}, "created": {"value": false, "score": 0.00028210878372192383}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.02076900005340576}, "created": {"value": false, "score": 0.00028210878372192383}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Google", "normalizedForm": "Google", "offsetStart": 89, "offsetEnd": 95}, "context": "The map and the reduce concepts constitute the MapReduce paradigm, which was proposed by Google in 2004 and designed to easily scale data processing over multiple computing nodes. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.653236389160156e-05}, "created": {"value": true, "score": 0.9898838996887207}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013756752014160156}, "created": {"value": true, "score": 0.9898838996887207}, "shared": {"value": false, "score": 5.960464477539062e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Flink", "normalizedForm": "Apache Flink", "offsetStart": 92, "offsetEnd": 106}, "context": "Among the well-known streaming processing parallel frameworks, we mention Apache Spark8 and Apache Flink 9 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003610849380493164}, "created": {"value": false, "score": 0.010707855224609375}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0003610849380493164}, "created": {"value": false, "score": 0.010707855224609375}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 93, "offsetEnd": 98}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Spark revolves around the concept of a resilient distributed dataset (RDD) 17 , which is the Spark programming model.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001971125602722168}, "created": {"value": false, "score": 0.31478309631347656}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "VectorSlicer", "normalizedForm": "VectorSlicer", "offsetStart": 94, "offsetEnd": 106}, "context": "There have been very few feature selection techniques, which were proposed, and these are the VectorSlicer, the RFormula and the ChiSqSelector. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019615888595581055}, "created": {"value": false, "score": 0.0054277777671813965}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00019615888595581055}, "created": {"value": false, "score": 0.0054277777671813965}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CfsSubsetEval", "normalizedForm": "CfsSubsetEval", "offsetStart": 95, "offsetEnd": 108}, "context": "We compare LSH-dRST with a number of other feature selection techniques from Weka 3.8.2 25   \u2022 CfsSubsetEval: considers the individual predictive ability of each feature along with the degree of redundancy between them", "mentionContextAttributes": {"used": {"value": false, "score": 0.18289726972579956}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.18289726972579956}, "created": {"value": false, "score": 1.9073486328125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 98, "offsetEnd": 103}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Our work, which is a revision of [11], is based on a distributed partitioning procedure, within a Spark/MapReduce paradigm, that makes our proposed solution scalable and effective in dealing with big data.", "mentionContextAttributes": {"used": {"value": false, "score": 5.2809715270996094e-05}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 98, "offsetEnd": 107}, "context": "Section 4 presents a description of parallel computing frameworks as well as a description of the MapReduce programming model. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001252889633178711}, "created": {"value": false, "score": 0.009219706058502197}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 103, "offsetEnd": 112}, "context": "Recently, a set of new and more flexible paradigms have been proposed aiming at extending the standard MapReduce approach, mainly Apache Spark1  [29], which has been applied with success over a number of data mining and machine learning real-world problems [29]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016117095947265625}, "created": {"value": true, "score": 0.7355144619941711}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CVAttributeEval", "normalizedForm": "CVAttributeEval", "offsetStart": 103, "offsetEnd": 118}, "context": "\u2022 ChiSquaredAttributeEval: computes the value of the chi-squared statistic with respect to the class \u2022 CVAttributeEval: first creates a ranking of attributes based on the Variation value, then divides into two groups, last using Verification method to select the best group", "mentionContextAttributes": {"used": {"value": false, "score": 0.003056943416595459}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.003056943416595459}, "created": {"value": false, "score": 1.6689300537109375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 104, "offsetEnd": 113}, "context": "Our work, which is a revision of [11], is based on a distributed partitioning procedure, within a Spark/MapReduce paradigm, that makes our proposed solution scalable and effective in dealing with big data.", "mentionContextAttributes": {"used": {"value": false, "score": 5.2809715270996094e-05}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[25]", "normalizedForm": "[25]", "refKey": 35}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Hadoop", "normalizedForm": "Hadoop", "offsetStart": 110, "offsetEnd": 118}, "context": "Among the well-known open-source distributed processing frameworks dedicated for batch processing, we mention Hadoop 5 . ", "mentionContextAttributes": {"used": {"value": false, "score": 6.842613220214844e-05}, "created": {"value": false, "score": 0.0031104683876037598}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.007363557815551758}, "created": {"value": true, "score": 0.7135889530181885}, "shared": {"value": false, "score": 7.152557373046875e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MapReduce", "normalizedForm": "MapReduce", "offsetStart": 116, "offsetEnd": 125}, "context": "Several recent works have been concentrated on parallelizing and distributing machine learning techniques using the MapReduce paradigm [26,27,28]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014603137969970703}, "created": {"value": false, "score": 0.26179778575897217}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9504634737968445}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "references": [{"label": "[26,", "normalizedForm": "[26", "refKey": 36, "offsetStart": 11996, "offsetEnd": 12000}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 121, "offsetEnd": 127}, "context": "Based on the Apache Spark framework and by applying Algorithm 3, line 1, we get the following outputs from the different Apache Spark data splits, which are presented in Table 2 and in Table 3:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823814034461975}, "created": {"value": false, "score": 8.273124694824219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark Streaming", "normalizedForm": "Spark Streaming", "offsetStart": 124, "offsetEnd": 139}, "context": "Indeed, Spark has a number of high-level libraries for working with structured data (Spark SQL 10 ), for stream processing (Spark Streaming 11 ), for machine learning (MLlib) 12 [44], and for graphs and graph-parallel computation (GraphX 13 ). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 128, "offsetEnd": 133}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Based on the Apache Spark framework and by applying Algorithm 3, line 1, we get the following outputs from the different Apache Spark data splits, which are presented in Table 2 and in Table 3:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9823814034461975}, "created": {"value": false, "score": 8.273124694824219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ChiSqSelector", "normalizedForm": "ChiSqSelector", "offsetStart": 129, "offsetEnd": 142}, "context": "There have been very few feature selection techniques, which were proposed, and these are the VectorSlicer, the RFormula and the ChiSqSelector. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019615888595581055}, "created": {"value": false, "score": 0.0054277777671813965}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00019615888595581055}, "created": {"value": false, "score": 0.0054277777671813965}, "shared": {"value": false, "score": 1.1920928955078125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 130, "offsetEnd": 148}, "context": "Recently, a set of new and more flexible paradigms have been proposed aiming at extending the standard MapReduce approach, mainly Apache Spark1  [29], which has been applied with success over a number of data mining and machine learning real-world problems [29]. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00016117095947265625}, "created": {"value": true, "score": 0.7355144619941711}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache", "normalizedForm": "Apache", "offsetStart": 161, "offsetEnd": 167}, "context": "Based on Split 1, and by applying Algorithm 5, which aims to generate all the possible combinations AllComb (K) of the set of K attributes, the output from both Apache Spark splits is the following:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9879884719848633}, "created": {"value": false, "score": 1.1920928955078125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.9875741600990295}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MLlib", "normalizedForm": "MLlib", "offsetStart": 168, "offsetEnd": 173}, "context": "Indeed, Spark has a number of high-level libraries for working with structured data (Spark SQL 10 ), for stream processing (Spark Streaming 11 ), for machine learning (MLlib) 12 [44], and for graphs and graph-parallel computation (GraphX 13 ). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Spark", "normalizedForm": "Spark", "offsetStart": 168, "offsetEnd": 173}, "version": {"rawForm": "2.1.1", "normalizedForm": "2.1.1"}, "context": "Based on Split 1, and by applying Algorithm 5, which aims to generate all the possible combinations AllComb (K) of the set of K attributes, the output from both Apache Spark splits is the following:", "mentionContextAttributes": {"used": {"value": true, "score": 0.9879884719848633}, "created": {"value": false, "score": 1.1920928955078125e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997956156730652}, "created": {"value": true, "score": 0.999723494052887}, "shared": {"value": false, "score": 1.0728836059570312e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SignificanceEval", "normalizedForm": "SignificanceEval", "offsetStart": 217, "offsetEnd": 233}, "context": "In terms of runtime for the classifier 29 , we observe that all runtimes for Naive Bayes are much smaller than the ones for Random Forest, ranging from 0.924 seconds for ConsistencySubsetEval and 135.5330 seconds for SignificanceEval with threshold 0. The fastest parameter setting for LSH-dRST is F = 10 and B = 50 (19.1884 ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9447787404060364}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9447787404060364}, "created": {"value": false, "score": 1.5497207641601562e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphX 13", "normalizedForm": "GraphX 13", "offsetStart": 231, "offsetEnd": 240}, "context": "Indeed, Spark has a number of high-level libraries for working with structured data (Spark SQL 10 ), for stream processing (Spark Streaming 11 ), for machine learning (MLlib) 12 [44], and for graphs and graph-parallel computation (GraphX 13 ). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.00013577938079833984}, "created": {"value": false, "score": 0.0001494884490966797}, "shared": {"value": false, "score": 3.5762786865234375e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Apache Spark", "normalizedForm": "Apache Spark", "offsetStart": 247, "offsetEnd": 259}, "context": "Further details and descriptions of such distributed processing frameworks will be given in Section 4. With the aim of choosing the most relevant and pertinent subset of features, a variety of feature reduction techniques were proposed within the Apache Spark framework to deal with big data in a distributed way. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0021555423736572266}, "created": {"value": false, "score": 0.04339486360549927}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.005069434642791748}, "created": {"value": true, "score": 0.9998162388801575}, "shared": {"value": false, "score": 8.344650268554688e-07}}}], "references": [{"refKey": 35, "tei": "<biblStruct xml:id=\"b35\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">MapReduce</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jeffrey</forename><surname>Dean</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sanjay</forename><surname>Ghemawat</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/1629175.1629198</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Communications of the ACM</title>\n\t\t<title level=\"j\" type=\"abbrev\">Commun. ACM</title>\n\t\t<idno type=\"ISSN\">0001-0782</idno>\n\t\t<idno type=\"ISSNe\">1557-7317</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">53</biblScope>\n\t\t\t<biblScope unit=\"issue\">1</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"72\" to=\"77\" />\n\t\t\t<date type=\"published\" when=\"2010-01\">2010</date>\n\t\t\t<publisher>Association for Computing Machinery (ACM)</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 11, "tei": "<biblStruct xml:id=\"b11\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">W</forename><surname>Pedrycz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">A</forename><surname>Skowron</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">V</forename><surname>Kreinovich</surname></persName>\n\t\t</author>\n\t\t<title level=\"m\">Handbook of granular computing</title>\n\t\t<imprint>\n\t\t\t<publisher>John Wiley &amp; Sons</publisher>\n\t\t\t<date>2008</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 0, "tei": "<biblStruct xml:id=\"b0\">\n\t<monogr>\n\t\t<title level=\"m\" type=\"main\">A detailed study of the distributed rough set based locality sensitive hashing feature selection technique</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Zaineb</forename><forename type=\"middle\">Chelly</forename><surname>Dagdia</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christine</forename><surname>Zarges</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.3233/FI-2016-0000</idno>\n\t\t<idno>6483CF7AF97D6599371ACFF58CEF3D71</idno>\n\t\t<imprint>\n\t\t\t<date></date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 36, "tei": "<biblStruct xml:id=\"b36\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Discovering outlying aspects in large datasets</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nguyen</forename><forename type=\"middle\">Xuan</forename><surname>Vinh</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jeffrey</forename><surname>Chan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Simone</forename><surname>Romano</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">James</forename><surname>Bailey</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Christopher</forename><surname>Leckie</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kotagiri</forename><surname>Ramamohanarao</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jian</forename><surname>Pei</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/s10618-016-0453-2</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Data Mining and Knowledge Discovery</title>\n\t\t<title level=\"j\" type=\"abbrev\">Data Min Knowl Disc</title>\n\t\t<idno type=\"ISSN\">1384-5810</idno>\n\t\t<idno type=\"ISSNe\">1573-756X</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">30</biblScope>\n\t\t\t<biblScope unit=\"issue\">6</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"1520\" to=\"1555\" />\n\t\t\t<date type=\"published\" when=\"2016-02-09\">2016</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 13877, "id": "95ba6020b050b5b87484fb6f26071e3b42d83e0c", "metadata": {"id": "95ba6020b050b5b87484fb6f26071e3b42d83e0c"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-02880638.grobid.tei.xml", "file_name": "hal-02880638.grobid.tei.xml"}