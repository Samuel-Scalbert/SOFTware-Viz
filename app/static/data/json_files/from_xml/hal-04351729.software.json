{"application": "software-mentions", "version": "0.8.0", "date": "2024-04-12T17:30+0000", "md5": "172CB39AE7757668E85D334826EF1C8F", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 0, "offsetEnd": 3}, "context": "AMD produced errors and an empty alignment file, so results are only available for four of the matchers: A-LIOn, LogMap, LogMapLt, Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961457252502441}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 0, "offsetEnd": 3}, "context": "AMD was not able to generate any correspondence.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9987784624099731}, "created": {"value": false, "score": 9.41157341003418e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 0, "offsetEnd": 3}, "context": "AMD returned some correspondences but achieved an overall F-Measure of 0.0 for all test cases.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999265074729919}, "created": {"value": false, "score": 1.7821788787841797e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN, ALION, GraphMatcher, Matcha, SEBMatcher are 6 new systems participating in this year.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002752542495727539}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN, GraphMatcher, and SEBMatcher also perform significantly better in both discrete and continuous cases compared to sharp case in term of F-measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04006093740463257}, "created": {"value": false, "score": 1.436471939086914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN and LogMap can both ask the oracle to analyze several conflicting correspondences simultaneously.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007309913635253906}, "created": {"value": false, "score": 5.662441253662109e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 0, "offsetEnd": 4}, "context": "ALIN is the system that improves the most, because its high number of oracle requests and its non-interactive performance was the lowest of the interactive systems, and thus the easiest to improve.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000489652156829834}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 0, "offsetEnd": 5}, "context": "SEALS provided a software infrastructure for automatically executing evaluations and evaluation campaigns for typical semantic web tools, including ontology matching.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003853440284729004}, "created": {"value": false, "score": 0.015185296535491943}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 0, "offsetEnd": 5}, "context": "SEALS, and Web format.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011402368545532227}, "created": {"value": false, "score": 8.636713027954102e-05}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap dominates with 0.61 of F1-measure. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04448139667510986}, "created": {"value": false, "score": 1.7344951629638672e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap and Matcha have similar results for precision. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00690692663192749}, "created": {"value": false, "score": 9.119510650634766e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap requests feedback on only selected correspondences candidates (based on their similarity patterns or their involvement in unsatisfiabilities). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007023811340332031}, "created": {"value": false, "score": 1.7583370208740234e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap, LogMapLt and Matcha performed well on most NCBITAXON-TAXREF-LD subtasks, with slightly the same levels of precision and recall, the larger subtask could only be handled by LogMapLt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9962204098701477}, "created": {"value": false, "score": 1.0311603546142578e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap stands out for its very fast calculation time of 9s and the maximum precision of 1.0. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00030100345611572266}, "created": {"value": false, "score": 3.1888484954833984e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap stands out again for its very fast computation time of only 3s at a high precision of 0.881. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00033414363861083984}, "created": {"value": false, "score": 3.2842159271240234e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha finds 6 wrong correspondences where classes are matched to object properties as in the first test case.", "mentionContextAttributes": {"used": {"value": false, "score": 0.14807844161987305}, "created": {"value": false, "score": 9.357929229736328e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap again stands out for the fast computation time and high precision with 53 correct correspondences out of the 56 in total. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0014587044715881348}, "created": {"value": false, "score": 2.7239322662353516e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap, LogMapLt and Matcha are the only systems able to generated (few) correct correspondences. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027823448181152344}, "created": {"value": false, "score": 5.537271499633789e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap has the best performance overall both in terms of F-measure and run time. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04009592533111572}, "created": {"value": false, "score": 3.8564205169677734e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 0, "offsetEnd": 6}, "context": "LogMap stands out for its very fast calculation time of 8s.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019931793212890625}, "created": {"value": false, "score": 7.444620132446289e-05}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha is the best performing participant in the food test case in terms of precision, recall and F1-measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.014548718929290771}, "created": {"value": false, "score": 8.100271224975586e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 0, "offsetEnd": 6}, "context": "Matcha finds 2 correct correspondences out of the 63 reference correspondences which results in the only non-zero recall for Matcha in the MSE track along with a fair precision of 0.5 at a rather fast calculation time of 21s.", "mentionContextAttributes": {"used": {"value": false, "score": 0.45592039823532104}, "created": {"value": false, "score": 3.9517879486083984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 0, "offsetEnd": 7}, "context": "DLinker participated for the first time.", "mentionContextAttributes": {"used": {"value": true, "score": 0.989021360874176}, "created": {"value": false, "score": 0.00012803077697753906}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 0, "offsetEnd": 7}, "context": "DLinker only participated for EQUALS and OVERLAPS tasks and only for LineStrings to LineStrings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993312954902649}, "created": {"value": false, "score": 2.5331974029541016e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 0, "offsetEnd": 7}, "context": "DLinker perfom well regarding Overlaps and also Equals for Spaten dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.936048150062561}, "created": {"value": false, "score": 3.993511199951172e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 0, "offsetEnd": 7}, "context": "DLinker can be improved to the number of the supported relations as well as to the supported geometries.", "mentionContextAttributes": {"used": {"value": false, "score": 6.026029586791992e-05}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 0, "offsetEnd": 7}, "context": "DLinker participated for the first time but only for the Sanbox task while LogMap participates every year.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7837865948677063}, "created": {"value": false, "score": 5.0961971282958984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "-Sandbox", "normalizedForm": "-Sandbox", "offsetStart": 0, "offsetEnd": 8}, "context": "-Sandbox (380 INSTANCES, 10000 TRIPLES). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9962470531463623}, "created": {"value": false, "score": 1.245737075805664e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9962470531463623}, "created": {"value": false, "score": 1.245737075805664e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt remains the system with the shortest runtime. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009747147560119629}, "created": {"value": false, "score": 2.7835369110107422e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt is almost 30 times slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005273222923278809}, "created": {"value": false, "score": 1.3649463653564453e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt is 6 times slower than LogMap with a slightly lower precision and 2 additional false positives. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000782310962677002}, "created": {"value": false, "score": 5.543231964111328e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapLt is the system that is able to deal with a higher number of matching pairs. ", "mentionContextAttributes": {"used": {"value": false, "score": 6.896257400512695e-05}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapKG", "normalizedForm": "LogMapKG", "offsetStart": 0, "offsetEnd": 8}, "context": "LogMapKG on the other hand tend to only align instances when it is applied to full-size datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003161430358886719}, "created": {"value": false, "score": 4.589557647705078e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 4.589557647705078e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 0, "offsetEnd": 9}, "context": "KGMatcher, LogMap, and Matcha do not return any of those mappings.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13003665208816528}, "created": {"value": false, "score": 7.808208465576172e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SystemPrec", "normalizedForm": "SystemPrec", "offsetStart": 0, "offsetEnd": 10}, "context": "SystemPrec. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009823441505432129}, "created": {"value": false, "score": 3.403425216674805e-05}, "shared": {"value": false, "score": 3.2782554626464844e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0009823441505432129}, "created": {"value": false, "score": 3.403425216674805e-05}, "shared": {"value": false, "score": 3.2782554626464844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLight", "normalizedForm": "LogMapLight", "offsetStart": 0, "offsetEnd": 11}, "context": "LogMapLight stands out for its high number of correspondences and performance indicators all equal to zero.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027680397033691406}, "created": {"value": false, "score": 0.00010329484939575195}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0030667781829833984}, "created": {"value": false, "score": 0.00010329484939575195}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 0, "offsetEnd": 12}, "context": "GraphMatcher produces the highest F-measure under both the continuous (72%) and discrete (72%) evaluation methodologies, indicating that this system's confidence evaluation does a good job of reflecting cohesion among experts on this task. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0012817978858947754}, "created": {"value": false, "score": 5.08427619934082e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 4, "offsetEnd": 8}, "context": "The MELT framework5  [21] was introduced in 2019 and is under active development.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002646446228027344}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 4.231929779052734e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 4, "offsetEnd": 9}, "context": "The SEALS client was developed in 2011.", "mentionContextAttributes": {"used": {"value": false, "score": 8.910894393920898e-05}, "created": {"value": true, "score": 0.9902029633522034}, "shared": {"value": false, "score": 3.7550926208496094e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIMBENCH", "normalizedForm": "SPIMBENCH", "offsetStart": 4, "offsetEnd": 13}, "context": "The SPIMBENCH track consists of matching instances that are found to refer to the same realworld entity corresponding to a creative work (that can be a news item, blog post or programme).", "mentionContextAttributes": {"used": {"value": false, "score": 0.021490395069122314}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIMBENCH", "normalizedForm": "SPIMBENCH", "offsetStart": 4, "offsetEnd": 13}, "context": "The SPIMBENCH task uses two sets of datasets 30 with different scales (i.e., number of instances to match):", "mentionContextAttributes": {"used": {"value": false, "score": 0.11031162738800049}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 5, "offsetEnd": 13}, "context": "Only LogMapLt could handle the task based on ontology files resulting from an automatic transformation of SKOS files into OWL. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 6.258487701416016e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 6, "offsetEnd": 12}, "context": "While LogMap makes use of user interactions exclusively in the post-matching steps to filter their candidate correspondences, ALIN can also add new candidate correspondences to its initial set. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.904104232788086e-05}, "created": {"value": false, "score": 3.248453140258789e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 6, "offsetEnd": 12}, "context": "Since LogMap found only 59 correct correspondences out of the 302 reference correspondences, the recall is rather low but the F1-measure is still the highest of the tested systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9865052103996277}, "created": {"value": false, "score": 8.046627044677734e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 6, "offsetEnd": 18}, "context": "ALIN, GraphMatcher, and SEBMatcher also perform significantly better in both discrete and continuous cases compared to sharp case in term of F-measure. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04006093740463257}, "created": {"value": false, "score": 1.436471939086914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 8, "offsetEnd": 16}, "context": "LogMap, LogMapLt and Matcha performed well on most NCBITAXON-TAXREF-LD subtasks, with slightly the same levels of precision and recall, the larger subtask could only be handled by LogMapLt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9962204098701477}, "created": {"value": false, "score": 1.0311603546142578e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 8, "offsetEnd": 16}, "context": "LogMap, LogMapLt and Matcha are the only systems able to generated (few) correct correspondences. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027823448181152344}, "created": {"value": false, "score": 5.537271499633789e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 9, "offsetEnd": 15}, "context": "ALIN and LogMap can both ask the oracle to analyze several conflicting correspondences simultaneously.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007309913635253906}, "created": {"value": false, "score": 5.662441253662109e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 9, "offsetEnd": 15}, "context": "Although LogMap misses out 10 reference correspondences, the F1-measure of 0.891 is the best of the whole MSE track. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7029958367347717}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 9, "offsetEnd": 15}, "context": "However, LogMap's recall is 4 times less than Matcha's one.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5607706308364868}, "created": {"value": false, "score": 7.337331771850586e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 11, "offsetEnd": 17}, "context": "KGMatcher, LogMap, and Matcha do not return any of those mappings. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.13003665208816528}, "created": {"value": false, "score": 7.808208465576172e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 11, "offsetEnd": 17}, "context": "LogMap and Matcha have similar results for precision.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00690692663192749}, "created": {"value": false, "score": 9.119510650634766e-06}, "shared": {"value": false, "score": 7.748603820800781e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 12, "offsetEnd": 19}, "context": "One system, DLinker only participated for Equals and Overlaps relations and only for Linestrings to Linestrings test cases.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8844344019889832}, "created": {"value": false, "score": 1.0311603546142578e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 13, "offsetEnd": 25}, "context": "ALIN, ALION, GraphMatcher, Matcha, SEBMatcher are 6 new systems participating in this year. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002752542495727539}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 14, "offsetEnd": 22}, "context": "Due to those, LogMapLt achieves a slightly worse F1-measure of 0.857 which is still the second best of the whole MSE track. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.002144455909729004}, "created": {"value": false, "score": 6.496906280517578e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIMBENCH", "normalizedForm": "SPIMBENCH", "offsetStart": 15, "offsetEnd": 24}, "context": "This year, the SPIMBENCH track counted two participants: LogMap and DLinker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9925350546836853}, "created": {"value": false, "score": 1.0669231414794922e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 16, "offsetEnd": 19}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 17, "offsetEnd": 22}, "context": "It relies on the SEALS client's Oracle class to simulate user interactions.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009515881538391113}, "created": {"value": false, "score": 5.97834587097168e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 18, "offsetEnd": 24}, "context": "From the results, Matcha outputs low precision and recall among three different versions of reference alignment in general because it assigns the threshold to zero and the matches with relatively high confidence value even the labels of two entities have low string similarity, for example, \"hasBid\" and \"hasPart\" has similarity over 0.63 and \"addedBy\" and \"awarded by\" also have similarity over 0.66. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5006972551345825}, "created": {"value": false, "score": 1.4901161193847656e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 19, "offsetEnd": 25}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.817), but four other systems obtained an F-measure above 0.88 (SEBMatcher, LogMapBio, LogMap, and AMD) which is at least as good as the best systems in OAEI 2007-2010.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 2.682209014892578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 19, "offsetEnd": 25}, "context": "On the other side, Matcha does not match classes at all, while it dominates in matching properties.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0007030963897705078}, "created": {"value": false, "score": 0.00010842084884643555}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 19, "offsetEnd": 26}, "context": "Regarding runtime, LSMatch (4:17:13) was the slowest system. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 5.185604095458984e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 20, "offsetEnd": 24}, "context": "The exceptions were ALIN which increased in size (from 1119 to 1159), F-measure (from 0.835 to 0.852), recall (from 0.726 to 0.752) and recall+ (from 0.438 to 0.501), and LogMapBio increased in size (from 1586 to 1596), recall (from 0.914 to 0.919) and recall+ (from 0.773 to 0.787).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9666441679000854}, "created": {"value": false, "score": 7.092952728271484e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 20, "offsetEnd": 26}, "context": "This year, only the LogMap family systems (LogMap, LogMapBio and LogMapLt) alongside Matcha managed to generate an output for at least one of the track tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793361186981201}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 21, "offsetEnd": 25}, "context": "Since last year, the MELT framework [21] has been adopted in order to facilitate the SEALS and HOBBIT wrapping and evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006667971611022949}, "created": {"value": false, "score": 0.0026892423629760742}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 21, "offsetEnd": 25}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 21, "offsetEnd": 27}, "context": "LogMap, LogMapLt and Matcha performed well on most NCBITAXON-TAXREF-LD subtasks, with slightly the same levels of precision and recall, the larger subtask could only be handled by LogMapLt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9962204098701477}, "created": {"value": false, "score": 1.0311603546142578e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 21, "offsetEnd": 27}, "context": "LogMap, LogMapLt and Matcha are the only systems able to generated (few) correct correspondences.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00027823448181152344}, "created": {"value": false, "score": 5.537271499633789e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 21, "offsetEnd": 30}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 22, "offsetEnd": 27}, "context": "For some systems, the SEALS client has been used. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.022263765335083008}, "created": {"value": false, "score": 0.0009044408798217773}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 22, "offsetEnd": 30}, "context": "In direct comparison, LogMapLt calculates the alignment in three times the time and achieves much lower precision (0.4) but due to a greater amount of correctly found correspondences the F1-measure is the best of the tested systems in the first test casealthough still low with 0.142. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6352251768112183}, "created": {"value": false, "score": 4.947185516357422e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 22, "offsetEnd": 31}, "context": "In terms of run time, LogMapBio took longer due to the loading of mediating ontologies from BioPortal. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9735978841781616}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 23, "offsetEnd": 29}, "context": "It is supra-linear for LogMap in all datasets.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0009012222290039062}, "created": {"value": false, "score": 7.450580596923828e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 23, "offsetEnd": 29}, "context": "KGMatcher, LogMap, and Matcha do not return any of those mappings.", "mentionContextAttributes": {"used": {"value": false, "score": 0.13003665208816528}, "created": {"value": false, "score": 7.808208465576172e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 24, "offsetEnd": 28}, "context": "This year, two systems (ALIN, and LogMap) participated in the Interactive matching track.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9622639417648315}, "created": {"value": false, "score": 3.68952751159668e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 24, "offsetEnd": 34}, "context": "ALIN, GraphMatcher, and SEBMatcher also perform significantly better in both discrete and continuous cases compared to sharp case in term of F-measure. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.04006093740463257}, "created": {"value": false, "score": 1.436471939086914e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 25, "offsetEnd": 31}, "context": "We can see four systems (LogMap, ATMatcher, KGMatcher+, and LSMatch) perform better than two baselines. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008932352066040039}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 25, "offsetEnd": 34}, "context": "The remaining 4 systems (ATMatcher, GraphMatcher, LogMap, Matcha) have a wide variation  When comparing the performance of the matchers on the uncertain reference alignments versus that on the sharp version, we see that in the discrete case all matchers performed the same or better in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9811494946479797}, "created": {"value": false, "score": 1.5676021575927734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 26, "offsetEnd": 32}, "context": "Of the remaining systems, LogMap has relatively small drops in F-measure when moving from discrete to continuous evaluation, while Matcha drops 14 percent in F-measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017333626747131348}, "created": {"value": false, "score": 1.7464160919189453e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 26, "offsetEnd": 32}, "context": "The request intervals for LogMap and ALIN stay at a few milliseconds for most datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11619830131530762}, "created": {"value": false, "score": 1.627206802368164e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 27, "offsetEnd": 33}, "context": "ALIN, ALION, GraphMatcher, Matcha, SEBMatcher are 6 new systems participating in this year. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002752542495727539}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 28, "offsetEnd": 31}, "context": "This year, only MatchaC and AMD (for some complex subtracks) have been registered to participate.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8347938060760498}, "created": {"value": false, "score": 4.166364669799805e-05}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 29, "offsetEnd": 33}, "context": "On the other hand, this year MELT framework was used instead of SEAL.", "mentionContextAttributes": {"used": {"value": true, "score": 0.7367996573448181}, "created": {"value": false, "score": 4.357099533081055e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepOnto", "normalizedForm": "DeepOnto", "offsetStart": 29, "offsetEnd": 37}, "context": "https://krr-oxford.github.io/DeepOnto/#/", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002480745315551758}, "created": {"value": false, "score": 1.4483928680419922e-05}, "shared": {"value": true, "score": 0.8526659607887268}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999788403511047}, "created": {"value": false, "score": 0.00025641918182373047}, "shared": {"value": true, "score": 0.8526659607887268}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 30, "offsetEnd": 35}, "context": "The results obtained with the SEALS client vary in some cases by 0.5% compared to the results presented in section 4.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999918341636658}, "created": {"value": false, "score": 3.7550926208496094e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 32, "offsetEnd": 36}, "context": "Alternatively, they can use the MELT framework to assist them, as it can be used to wrap any matching system as docker container implementing the HTTP interface.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0022509098052978516}, "created": {"value": false, "score": 0.0006147027015686035}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 32, "offsetEnd": 38}, "context": "LogMapLt is 6 times slower than LogMap with a slightly lower precision and 2 additional false positives. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.000782310962677002}, "created": {"value": false, "score": 5.543231964111328e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher+", "normalizedForm": "KGMatcher+", "offsetStart": 32, "offsetEnd": 42}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 33, "offsetEnd": 42}, "context": "We can see four systems (LogMap, ATMatcher, KGMatcher+, and LSMatch) perform better than two baselines. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008932352066040039}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 34, "offsetEnd": 38}, "context": "They have been computed using the MELT framework without applying any threshold to the results.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999961256980896}, "created": {"value": false, "score": 6.121397018432617e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 34, "offsetEnd": 40}, "context": "This year, two systems (ALIN, and LogMap) participated in the Interactive matching track. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9622639417648315}, "created": {"value": false, "score": 3.68952751159668e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 34, "offsetEnd": 40}, "context": "The highest recall is achieved by Matcha (0.88), a new system participating this year.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5952127575874329}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 34, "offsetEnd": 43}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 34, "offsetEnd": 43}, "context": "This years best overall system is ATMatcher.", "mentionContextAttributes": {"used": {"value": false, "score": 0.10992789268493652}, "created": {"value": false, "score": 8.767843246459961e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 35, "offsetEnd": 39}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 35, "offsetEnd": 45}, "context": "ALIN, ALION, GraphMatcher, Matcha, SEBMatcher are 6 new systems participating in this year. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002752542495727539}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 36, "offsetEnd": 39}, "context": "Similar to 2021 evaluation results, AMD does generate schema alignments but in the wrong format, therefore, they can not be evaluated.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04883003234863281}, "created": {"value": false, "score": 1.1622905731201172e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 36, "offsetEnd": 40}, "context": "This year, most tracks have adopted MELT as their evaluation platform.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005083680152893066}, "created": {"value": false, "score": 0.002118408679962158}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 36, "offsetEnd": 40}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "offsetStart": 36, "offsetEnd": 41}, "context": "The evaluation was carried out on a Linux virtual machine with 128 GB of RAM and 16 vCPUs (2.4 GHz) processors. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 2.2590160369873047e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 3.039836883544922e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 36, "offsetEnd": 41}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor for MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006028413772583008}, "created": {"value": false, "score": 0.00015211105346679688}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 36, "offsetEnd": 48}, "context": "The remaining 4 systems (ATMatcher, GraphMatcher, LogMap, Matcha) have a wide variation  When comparing the performance of the matchers on the uncertain reference alignments versus that on the sharp version, we see that in the discrete case all matchers performed the same or better in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9811494946479797}, "created": {"value": false, "score": 1.5676021575927734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 37, "offsetEnd": 41}, "context": "The request intervals for LogMap and ALIN stay at a few milliseconds for most datasets. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.11619830131530762}, "created": {"value": false, "score": 1.627206802368164e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 38, "offsetEnd": 42}, "context": "In 2022, 10 systems were submitted as MELT Web docker container, 5 systems were submitted as SEALS package, 3 systems were uploaded to the HOBBIT platform, and one system implemented the Web interface directly and provided hosting for the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8212605714797974}, "created": {"value": false, "score": 0.00022411346435546875}, "shared": {"value": false, "score": 2.086162567138672e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StringEquiv", "normalizedForm": "StringEquiv", "offsetStart": 38, "offsetEnd": 49}, "context": "Additionally, we added two baselines: StringEquiv as a string matcher based on string equality applied on local names of entities which were lowercased and edna as a string editing distance matcher.", "mentionContextAttributes": {"used": {"value": false, "score": 0.260697603225708}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998717308044434}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 39, "offsetEnd": 43}, "context": "The evaluation was performed using the MELT platform on a Windows 10 system with Intel Core i7 870 CPU @2.93GHz x4 and 16 GB RAM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99998539686203}, "created": {"value": false, "score": 3.30805778503418e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 39, "offsetEnd": 43}, "context": "The evaluation was performed using the MELT platform.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.00019407272338867188}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 40, "offsetEnd": 45}, "context": "Some tracks are run exclusively through SEALS and others through HOBBIT, but several allow participants to choose the platform they prefer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007432043552398682}, "created": {"value": false, "score": 0.00034487247467041016}, "shared": {"value": false, "score": 4.869699478149414e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "Regarding the ENVO-SWEET task, only the LogMap family systems achieved it with a similar performance to last year. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992849826812744}, "created": {"value": false, "score": 0.00012922286987304688}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "LogMapLt is almost 30 times slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005273222923278809}, "created": {"value": false, "score": 1.3649463653564453e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 40, "offsetEnd": 46}, "context": "In terms of the NELL-DBpedia test case, LogMap, ATMatcher, KGMatcher+, and AMD were able to generate results when applied to the full-size dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 1.055002212524414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 42, "offsetEnd": 51}, "context": "Two systems produced coherent alignments (LogMapBio and LogMap).", "mentionContextAttributes": {"used": {"value": false, "score": 0.027910828590393066}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under a Intel Core CPU 2.00GHz x8 cores.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99383145570755}, "created": {"value": false, "score": 0.0028766989707946777}, "shared": {"value": false, "score": 1.7285346984863281e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 3.039836883544922e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under a Intel Core CPU 2.00GHz x8 processors.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9942510724067688}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 2.9206275939941406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 3.039836883544922e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "offsetStart": 43, "offsetEnd": 48}, "context": "The systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under an Intel Core CPU 2.00GHz x8 processors. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9940752983093262}, "created": {"value": false, "score": 0.004393517971038818}, "shared": {"value": false, "score": 3.039836883544922e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 3.039836883544922e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 43, "offsetEnd": 49}, "context": "This year, only the LogMap family systems (LogMap, LogMapBio and LogMapLt) alongside Matcha managed to generate an output for at least one of the track tasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793361186981201}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 44, "offsetEnd": 50}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 44, "offsetEnd": 50}, "context": "Three systems were first time participants (Matcha, ALIOn and SEBMatcher).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965898990631104}, "created": {"value": false, "score": 1.6033649444580078e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 44, "offsetEnd": 53}, "context": "We can see four systems (LogMap, ATMatcher, KGMatcher+, and LSMatch) perform better than two baselines. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008932352066040039}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DeepOnto", "normalizedForm": "DeepOnto", "offsetStart": 44, "offsetEnd": 54}, "context": "All our evaluations were conducted with the DeepOnto17 library on a local machine with Intel Xeon Bronze 3204 CPU 1.90GHz x11 processors, 126GB RAM, and two Quadro RTX 8000 GPUs. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999788403511047}, "created": {"value": false, "score": 0.00025641918182373047}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999788403511047}, "created": {"value": false, "score": 0.00025641918182373047}, "shared": {"value": true, "score": 0.8526659607887268}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 45, "offsetEnd": 52}, "context": "https://raw.githubusercontent.com/iNovexIrad/MatOnto-Ontologies/master/matonto-release.ttl", "mentionContextAttributes": {"used": {"value": false, "score": 0.00014162063598632812}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": true, "score": 0.951348066329956}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995636343955994}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": true, "score": 0.951348066329956}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 45, "offsetEnd": 54}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 46, "offsetEnd": 52}, "context": "However, LogMap's recall is 4 times less than Matcha's one.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5607706308364868}, "created": {"value": false, "score": 7.337331771850586e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 48, "offsetEnd": 52}, "context": "For evaluating all possible submission formats, MELT framework is used.", "mentionContextAttributes": {"used": {"value": true, "score": 0.996480405330658}, "created": {"value": false, "score": 0.00012683868408203125}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 48, "offsetEnd": 52}, "context": "The impact of the oracle's errors is linear for ALIN in most tasks, as the F-measure according to the oracle remains approximately constant across all error rates.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011071443557739258}, "created": {"value": false, "score": 2.664327621459961e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 48, "offsetEnd": 57}, "context": "In terms of the NELL-DBpedia test case, LogMap, ATMatcher, KGMatcher+, and AMD were able to generate results when applied to the full-size dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 1.055002212524414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 49, "offsetEnd": 52}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 49, "offsetEnd": 52}, "context": "Similar to the previous years, some systems like AMD need a post-processing step of the resulting alignment file to be able to parse it.", "mentionContextAttributes": {"used": {"value": false, "score": 6.002187728881836e-05}, "created": {"value": false, "score": 0.00011271238327026367}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 49, "offsetEnd": 53}, "context": "This year we evaluated all participants with the MELT framework to include all possible submission formats i.e.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999710917472839}, "created": {"value": false, "score": 0.0003103017807006836}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 49, "offsetEnd": 56}, "context": "But we received new participation from CIDER-LM, LSMatch and LSMatch Multilingual.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9972642660140991}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 50, "offsetEnd": 56}, "context": "Surprisingly two of the systems are even quicker (LogMap, LogMapLight) than in the first test case. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0030667781829833984}, "created": {"value": false, "score": 3.784894943237305e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 50, "offsetEnd": 56}, "context": "The remaining 4 systems (ATMatcher, GraphMatcher, LogMap, Matcha) have a wide variation  When comparing the performance of the matchers on the uncertain reference alignments versus that on the sharp version, we see that in the discrete case all matchers performed the same or better in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9811494946479797}, "created": {"value": false, "score": 1.5676021575927734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIMBENCH", "normalizedForm": "SPIMBENCH", "offsetStart": 50, "offsetEnd": 64}, "context": "The datasets were generated and transformed using SPIMBENCH [49] by altering a set of original linked data through value-based, structure-based, and semantics-aware transformations (simple combination of transformations). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 8.52346420288086e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 51, "offsetEnd": 60}, "context": "This year, only the LogMap family systems (LogMap, LogMapBio and LogMapLt) alongside Matcha managed to generate an output for at least one of the track tasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793361186981201}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Pellet", "normalizedForm": "Pellet", "offsetStart": 52, "offsetEnd": 58}, "context": "Alignments are also checked for coherence using the Pellet reasoner. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995186924934387}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995186924934387}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 52, "offsetEnd": 58}, "context": "However, since only one correspondence was found by LogMap, the recall and hence the F1-measure is low (0.083). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995271563529968}, "created": {"value": false, "score": 9.000301361083984e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 52, "offsetEnd": 60}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "software-name": {"rawForm": "Linux", "normalizedForm": "Linux", "wikidataId": "Q14579", "wikipediaExternalRef": 21347315, "lang": "en", "confidence": 0.857, "offsetStart": 53, "offsetEnd": 58}, "context": "The alignment systems have been executed on a Ubuntu Linux machine configured with 32GB of RAM running under a Intel Core CPU 2.00GHz x8 cores. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961917996406555}, "created": {"value": false, "score": 0.0032671093940734863}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999801516532898}, "created": {"value": false, "score": 0.004505276679992676}, "shared": {"value": false, "score": 3.039836883544922e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 54, "offsetEnd": 59}, "context": "This year, three submission formats were allowed: (1) SEALS package, (2) HOBBIT, and (3) MELT Web interface.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5441417694091797}, "created": {"value": false, "score": 0.00015878677368164062}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 54, "offsetEnd": 63}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 55, "offsetEnd": 59}, "context": "Second, for systems that have been well-adapted to the MELT platform, we used MELT to produce the output mappings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994677305221558}, "created": {"value": false, "score": 0.011403083801269531}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 55, "offsetEnd": 64}, "context": "This year, we lost the participation of ALOD2Vec, AML, ATMatcher and Wiktionary.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9887797236442566}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 56, "offsetEnd": 62}, "context": "Two systems produced coherent alignments (LogMapBio and LogMap).", "mentionContextAttributes": {"used": {"value": false, "score": 0.027910828590393066}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "edna", "normalizedForm": "edna", "offsetStart": 57, "offsetEnd": 61}, "context": "Two baseline matchers are used to benchmark the systems: edna string edit distance matcher; and StringEquiv string equivalence matcher as in the anatomy test case.", "mentionContextAttributes": {"used": {"value": true, "score": 0.972187876701355}, "created": {"value": false, "score": 1.5079975128173828e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.972187876701355}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 57, "offsetEnd": 63}, "context": "This year, the SPIMBENCH track counted two participants: LogMap and DLinker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9925350546836853}, "created": {"value": false, "score": 1.0669231414794922e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 57, "offsetEnd": 64}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all.", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 58, "offsetEnd": 64}, "context": "The remaining 4 systems (ATMatcher, GraphMatcher, LogMap, Matcha) have a wide variation  When comparing the performance of the matchers on the uncertain reference alignments versus that on the sharp version, we see that in the discrete case all matchers performed the same or better in terms of F-measure.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9811494946479797}, "created": {"value": false, "score": 1.5676021575927734e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "wikidataId": "Q18168774", "wikipediaExternalRef": 43989914, "lang": "en", "confidence": 0.903, "software-name": {"rawForm": "Windows 10", "normalizedForm": "Windows 10", "wikidataId": "Q18168774", "wikipediaExternalRef": 43989914, "lang": "en", "confidence": 0.903, "offsetStart": 58, "offsetEnd": 68}, "context": "The evaluation was performed using the MELT platform on a Windows 10 system with Intel Core i7 870 CPU @2.93GHz x4 and 16 GB RAM. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.99998539686203}, "created": {"value": false, "score": 3.30805778503418e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99998539686203}, "created": {"value": false, "score": 3.30805778503418e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLight", "normalizedForm": "LogMapLight", "offsetStart": 58, "offsetEnd": 69}, "context": "Surprisingly two of the systems are even quicker (LogMap, LogMapLight) than in the first test case. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0030667781829833984}, "created": {"value": false, "score": 3.784894943237305e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": false, "score": 0.0030667781829833984}, "created": {"value": false, "score": 0.00010329484939575195}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 59, "offsetEnd": 68}, "context": "In terms of the NELL-DBpedia test case, LogMap, ATMatcher, KGMatcher+, and AMD were able to generate results when applied to the full-size dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 1.055002212524414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 60, "offsetEnd": 66}, "context": "Some matching systems participated with different variants (Matcha and LogMap) whereas others were evaluated with different configurations, as requested by developers (see test case sections for details).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9809303283691406}, "created": {"value": false, "score": 9.578466415405273e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 60, "offsetEnd": 67}, "context": "We can see four systems (LogMap, ATMatcher, KGMatcher+, and LSMatch) perform better than two baselines.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008932352066040039}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 61, "offsetEnd": 68}, "context": "But we received new participation from CIDER-LM, LSMatch and LSMatch Multilingual.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9972642660140991}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 62, "offsetEnd": 69}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 62, "offsetEnd": 72}, "context": "Three systems were first time participants (Matcha, ALIOn and SEBMatcher). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965898990631104}, "created": {"value": false, "score": 1.6033649444580078e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 65, "offsetEnd": 70}, "context": "We evaluated all the participating systems that were packaged as SEALS packages or as web services using Docker (even those not registered to participate on this new track).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998176097869873}, "created": {"value": false, "score": 7.396936416625977e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 65, "offsetEnd": 73}, "context": "This year, only the LogMap family systems (LogMap, LogMapBio and LogMapLt) alongside Matcha managed to generate an output for at least one of the track tasks. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793361186981201}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 66, "offsetEnd": 69}, "context": "For the Taxon dataset, as for the Conference dataset, MatchaC and AMD failed to generate alignments.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998944401741028}, "created": {"value": false, "score": 5.662441253662109e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 66, "offsetEnd": 74}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 68, "offsetEnd": 75}, "context": "This year, the SPIMBENCH track counted two participants: LogMap and DLinker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9925350546836853}, "created": {"value": false, "score": 1.0669231414794922e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 69, "offsetEnd": 78}, "context": "ALION is the system whose performance surges most (18%), followed by KGMatcher+ (16%) and LSMatch (16%).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0030391812324523926}, "created": {"value": false, "score": 4.112720489501953e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 70, "offsetEnd": 73}, "context": "This is the first year of the track and four systems were registered: AMD, LogMap, LogMapLite and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5837668180465698}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SPIMBENCH", "normalizedForm": "SPIMBENCH", "offsetStart": 70, "offsetEnd": 79}, "context": "In the Instance matching tracks participation decreased this year for SPIMBENCH and increased for Spatial benchmark.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9985498785972595}, "created": {"value": false, "score": 6.854534149169922e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.999973714351654}, "created": {"value": false, "score": 0.00010448694229125977}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 70, "offsetEnd": 80}, "context": "Seven matchers (AMD, ALIN, ALIOn, ATMatcher, KGMatcher+, LSMatch, and SEBMatcher) do not match properties at all. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.011699676513671875}, "created": {"value": false, "score": 2.3186206817626953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 71, "offsetEnd": 77}, "context": "Some matching systems participated with different variants (Matcha and LogMap) whereas others were evaluated with different configurations, as requested by developers (see test case sections for details). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9809303283691406}, "created": {"value": false, "score": 9.578466415405273e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 71, "offsetEnd": 77}, "context": "A-LIOn produces moderate results but does not bring any advantage over LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 8.779764175415039e-05}, "created": {"value": false, "score": 1.5914440155029297e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 72, "offsetEnd": 77}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 72, "offsetEnd": 81}, "context": "Besides the baselines (which need around 12 minutes for all test cases) ATMatcher (00:18:48) and LogMap (00:55:52) were the fastest systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997663497924805}, "created": {"value": false, "score": 1.043081283569336e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 75, "offsetEnd": 78}, "context": "In terms of the NELL-DBpedia test case, LogMap, ATMatcher, KGMatcher+, and AMD were able to generate results when applied to the full-size dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 1.055002212524414e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 75, "offsetEnd": 79}, "context": "As baseline, we utilize a simple string matcher which is available through MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0868067741394043}, "created": {"value": false, "score": 0.15072482824325562}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 75, "offsetEnd": 81}, "context": "Out of 12 systems 6 (ATMatcher, KGMatcher+, LogMap, LogMapLt, LSMatch, and Matcha) managed to match DBpedia to OntoFarm ontologies. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 75, "offsetEnd": 81}, "context": "This is the first year of the track and four systems were registered: AMD, LogMap, LogMapLite and Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5837668180465698}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 75, "offsetEnd": 81}, "context": "DLinker participated for the first time but only for the Sanbox task while LogMap participates every year. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7837865948677063}, "created": {"value": false, "score": 5.0961971282958984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ekaw", "normalizedForm": "ekaw", "offsetStart": 76, "offsetEnd": 80}, "context": "The Conference dataset is composed of three ontologies: cmt, conference and ekaw from the conference dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4906333088874817}, "created": {"value": false, "score": 6.735324859619141e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998226165771484}, "created": {"value": false, "score": 0.00024271011352539062}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 76, "offsetEnd": 83}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 77, "offsetEnd": 80}, "context": "For this first version of the track, four systems registered to participate: AMD, LogMap, LogMapLt and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9242873787879944}, "created": {"value": false, "score": 0.00027763843536376953}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 78, "offsetEnd": 82}, "context": "Second, for systems that have been well-adapted to the MELT platform, we used MELT to produce the output mappings.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994677305221558}, "created": {"value": false, "score": 0.011403083801269531}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 79, "offsetEnd": 84}, "context": "The OAEI evaluation was carried out in one of three alternative platforms: the SEALS client, the HOBBIT platform, or the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997146129608154}, "created": {"value": false, "score": 0.0002257823944091797}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 81, "offsetEnd": 87}, "context": "In comparison to the first test case, two of the four evaluated systems (A-LIOn, Matcha) need much longer to calculate the alignment. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9891154766082764}, "created": {"value": false, "score": 2.3663043975830078e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 82, "offsetEnd": 88}, "context": "For this first version of the track, four systems registered to participate: AMD, LogMap, LogMapLt and Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9242873787879944}, "created": {"value": false, "score": 0.00027763843536376953}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 83, "offsetEnd": 93}, "context": "This is the first year of the track and four systems were registered: AMD, LogMap, LogMapLite and Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.5837668180465698}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 85, "offsetEnd": 88}, "context": "For systems requiring more RAM, the evaluation was carried out on a computer with an AMD Ryzen 7 5700G 3.80 GHz CPU and 32GB RAM, with 10GB of max heap space allocated to java.Each system was run ten times and the final result of a system for each error rate represents the average of these runs.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998328685760498}, "created": {"value": false, "score": 6.41942024230957e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 85, "offsetEnd": 90}, "context": "Since last year, the MELT framework [21] has been adopted in order to facilitate the SEALS and HOBBIT wrapping and evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006667971611022949}, "created": {"value": false, "score": 0.0026892423629760742}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 85, "offsetEnd": 91}, "context": "This year, only the LogMap family systems (LogMap, LogMapBio and LogMapLt) alongside Matcha managed to generate an output for at least one of the track tasks.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793361186981201}, "created": {"value": false, "score": 0.00018334388732910156}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 85, "offsetEnd": 95}, "context": "Out of the 12 alignment systems, 8 (ALIN, ALION, AMD, KGMatcher+, LogMapLt, LSMatch, SEBMatcher, TOMATO) use 1.0 as the confidence value for all matches they identify.", "mentionContextAttributes": {"used": {"value": false, "score": 0.01606661081314087}, "created": {"value": false, "score": 2.8192996978759766e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 86, "offsetEnd": 93}, "context": "This year, 5 systems have registered to participate in the MultiFarm track: CIDER-LM, LSMatch, LSMatch Multilingual, LogMap and LogMapLt.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03688913583755493}, "created": {"value": false, "score": 0.00012922286987304688}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 88, "offsetEnd": 95}, "context": "This year the Link Discovery track counted four participants: DS-JedAI, Silk, RADON and DLinker.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9855576157569885}, "created": {"value": false, "score": 7.331371307373047e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 89, "offsetEnd": 93}, "context": "This year, three submission formats were allowed: (1) SEALS package, (2) HOBBIT, and (3) MELT Web interface.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5441417694091797}, "created": {"value": false, "score": 0.00015878677368164062}, "shared": {"value": false, "score": 6.556510925292969e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ekaw", "normalizedForm": "ekaw", "offsetStart": 89, "offsetEnd": 93}, "context": "While part of the dataset is openly available, all matching tasks involving the edas and ekaw ontologies (resulting in 55 \u00d7 24 matching tasks) are used for blind evaluation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.029156386852264404}, "created": {"value": false, "score": 1.4007091522216797e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998226165771484}, "created": {"value": false, "score": 0.00024271011352539062}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 90, "offsetEnd": 97}, "context": "ALION is the system whose performance surges most (18%), followed by KGMatcher+ (16%) and LSMatch (16%).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0030391812324523926}, "created": {"value": false, "score": 4.112720489501953e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 90, "offsetEnd": 98}, "context": "For this first version of the track, four systems registered to participate: AMD, LogMap, LogMapLt and Matcha. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9242873787879944}, "created": {"value": false, "score": 0.00027763843536376953}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 91, "offsetEnd": 95}, "context": "For further analysis of the results, we also provide an online dashboard 41 generated with MELT [62].", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998393058776855}, "created": {"value": false, "score": 4.082918167114258e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62, "offsetStart": 65077, "offsetEnd": 65081}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 93, "offsetEnd": 98}, "context": "In 2022, 10 systems were submitted as MELT Web docker container, 5 systems were submitted as SEALS package, 3 systems were uploaded to the HOBBIT platform, and one system implemented the Web interface directly and provided hosting for the system.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8212605714797974}, "created": {"value": false, "score": 0.00022411346435546875}, "shared": {"value": false, "score": 2.086162567138672e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 93, "offsetEnd": 102}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only ATMatcher, KGMatcher+, and AMD were able to generate alignments with the original dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995205998420715}, "created": {"value": false, "score": 2.294778823852539e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 93, "offsetEnd": 103}, "context": "On the YagoWikidata dataset, two systems were not able to outperform the baseline, which are LogMapLite and In terms of runtime, Table 20 also presents the run time as HH:MM:SS where we can observe that all matching were able to finish the task in less than 30 minutes except for KGMatcher+ and LogMapLite. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 1.6093254089355469e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SKOS", "normalizedForm": "SKOS", "offsetStart": 94, "offsetEnd": 98}, "context": "In addition this year, we did confirm on the one hand the inability of most systems to handle SKOS as input format and to handle very large ontologies and thesauri in the other hand.", "mentionContextAttributes": {"used": {"value": false, "score": 0.2915302515029907}, "created": {"value": false, "score": 0.4180949926376343}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 0.4180949926376343}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StringEquiv", "normalizedForm": "StringEquiv", "offsetStart": 94, "offsetEnd": 105}, "context": "Of the 10 systems participating in the Anatomy track, 8 achieved an F-measure higher than the StringEquiv baseline.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998717308044434}, "created": {"value": false, "score": 2.0563602447509766e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998717308044434}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 95, "offsetEnd": 102}, "context": "This year, 5 systems have registered to participate in the MultiFarm track: CIDER-LM, LSMatch, LSMatch Multilingual, LogMap and LogMapLt.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03688913583755493}, "created": {"value": false, "score": 0.00012922286987304688}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 96, "offsetEnd": 100}, "context": "Third, for systems that have been implemented elsewhere and not easy to be made compatible with MELT, we used their source code.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9561129212379456}, "created": {"value": false, "score": 0.0005112290382385254}, "shared": {"value": false, "score": 2.8014183044433594e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 96, "offsetEnd": 106}, "context": "Other systems either fail to complete the task within the allocated 24 hours time limit such as LogMapLite, Matcha, and LsMatch, or produce an empty alignment file such as Matcha, LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003279447555541992}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StringEquiv", "normalizedForm": "StringEquiv", "offsetStart": 96, "offsetEnd": 107}, "context": "Two baseline matchers are used to benchmark the systems: edna string edit distance matcher; and StringEquiv string equivalence matcher as in the anatomy test case.", "mentionContextAttributes": {"used": {"value": true, "score": 0.972187876701355}, "created": {"value": false, "score": 1.5079975128173828e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998717308044434}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 97, "offsetEnd": 101}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor for MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006028413772583008}, "created": {"value": false, "score": 0.00015211105346679688}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 97, "offsetEnd": 103}, "context": "Besides the baselines (which need around 12 minutes for all test cases) ATMatcher (00:18:48) and LogMap (00:55:52) were the fastest systems. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997663497924805}, "created": {"value": false, "score": 1.043081283569336e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 98, "offsetEnd": 104}, "context": "This is the first year of the track and four systems were registered: AMD, LogMap, LogMapLite and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5837668180465698}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 99, "offsetEnd": 105}, "context": "The number of instance correspondences are in the same range (3,641 -5,872) for all systems except Matcha (32,844) which thus reaches a high recall value.", "mentionContextAttributes": {"used": {"value": false, "score": 0.18807154893875122}, "created": {"value": false, "score": 5.441904067993164e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 100, "offsetEnd": 109}, "context": "Most systems achieve lower scores of measures than in the case of matching domain ontologies except KGMatcher+.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00025904178619384766}, "created": {"value": false, "score": 7.092952728271484e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 103, "offsetEnd": 109}, "context": "For this first version of the track, four systems registered to participate: AMD, LogMap, LogMapLt and Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9242873787879944}, "created": {"value": false, "score": 0.00027763843536376953}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 104, "offsetEnd": 109}, "context": "It allows the development, evaluation, and packaging of matching systems for evaluation interfaces like SEALS or HOBBIT.", "mentionContextAttributes": {"used": {"value": false, "score": 3.927946090698242e-05}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 104, "offsetEnd": 113}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only ATMatcher, KGMatcher+, and AMD were able to generate alignments with the original dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995205998420715}, "created": {"value": false, "score": 2.294778823852539e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "offsetStart": 105, "offsetEnd": 111}, "context": "The evaluation was performed using MELT for matchers wrapped using both SEALS, and the web packaging via Docker. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 4.708766937255859e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 7.396936416625977e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "software-name": {"rawForm": "Docker", "normalizedForm": "Docker", "wikidataId": "Q15206305", "wikipediaExternalRef": 40149201, "lang": "en", "confidence": 0.6895, "offsetStart": 105, "offsetEnd": 111}, "context": "We evaluated all the participating systems that were packaged as SEALS packages or as web services using Docker (even those not registered to participate on this new track).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998176097869873}, "created": {"value": false, "score": 7.396936416625977e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": false, "score": 7.396936416625977e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SKOS", "normalizedForm": "SKOS", "offsetStart": 106, "offsetEnd": 110}, "context": "Only LogMapLt could handle the task based on ontology files resulting from an automatic transformation of SKOS files into OWL.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 6.258487701416016e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 0.4180949926376343}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SKOS", "normalizedForm": "SKOS", "offsetStart": 107, "offsetEnd": 111}, "context": "The ANAEETHES-GEMET and AGROVOC-NALT matching tasks have the particularity of being resources developed in SKOS. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.6073355078697205}, "created": {"value": false, "score": 0.00027620792388916016}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 0.4180949926376343}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 108, "offsetEnd": 112}, "context": "The evaluation was carried out on a machine with a 5 core CPU @ 1.80 GHz with 16GB allocated RAM, using the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999678730964661}, "created": {"value": false, "score": 1.7702579498291016e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 108, "offsetEnd": 114}, "context": "Other systems either fail to complete the task within the allocated 24 hours time limit such as LogMapLite, Matcha, and LsMatch, or produce an empty alignment file such as Matcha, LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003279447555541992}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 113, "offsetEnd": 119}, "context": "AMD produced errors and an empty alignment file, so results are only available for four of the matchers: A-LIOn, LogMap, LogMapLt, Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961457252502441}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ekaw", "normalizedForm": "ekaw", "offsetStart": 114, "offsetEnd": 118}, "context": "In order to evaluate resulted alignments we prepared reference alignment of DBpedia to three OntoFarm ontologies (ekaw, sigkdd and confOf) as explained in [54]. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998226165771484}, "created": {"value": false, "score": 0.00024271011352539062}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998226165771484}, "created": {"value": false, "score": 0.00024271011352539062}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SKOS", "normalizedForm": "SKOS", "offsetStart": 117, "offsetEnd": 121}, "context": "This year's OAEI campaign consisted of 14 tracks, all of them including OWL ontologies while only one also including SKOS thesauri, namely the Biodiversity and the Ecology track.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8975508809089661}, "created": {"value": false, "score": 8.195638656616211e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99822998046875}, "created": {"value": false, "score": 0.4180949926376343}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 117, "offsetEnd": 122}, "context": "From 2011, we have been using an environment for automatically processing evaluations which was developed within the SEALS (Semantic Evaluation At Large Scale) project 3 .", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006937980651855469}, "created": {"value": true, "score": 0.9732758402824402}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 117, "offsetEnd": 123}, "context": "This year, 5 systems have registered to participate in the MultiFarm track: CIDER-LM, LSMatch, LSMatch Multilingual, LogMap and LogMapLt. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03688913583755493}, "created": {"value": false, "score": 0.00012922286987304688}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 120, "offsetEnd": 123}, "context": "While on the YAGO-Wikidata dataset, which is large-scale compared to the first dataset, only ATMatcher, KGMatcher+, and AMD were able to generate alignments with the original dataset. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995205998420715}, "created": {"value": false, "score": 2.294778823852539e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LsMatch", "normalizedForm": "LsMatch", "offsetStart": 120, "offsetEnd": 127}, "context": "Other systems either fail to complete the task within the allocated 24 hours time limit such as LogMapLite, Matcha, and LsMatch, or produce an empty alignment file such as Matcha, LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003279447555541992}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DLinker", "normalizedForm": "DLinker", "offsetStart": 120, "offsetEnd": 127}, "context": "The run time scaled very well with the increase if the number of instances while we do not have scaling information for DLinker as it did not participate for the large dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 8.285045623779297e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999557137489319}, "created": {"value": false, "score": 0.00016617774963378906}, "shared": {"value": false, "score": 6.556510925292969e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 121, "offsetEnd": 125}, "context": "The OAEI evaluation was carried out in one of three alternative platforms: the SEALS client, the HOBBIT platform, or the MELT framework.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997146129608154}, "created": {"value": false, "score": 0.0002257823944091797}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 121, "offsetEnd": 129}, "context": "AMD produced errors and an empty alignment file, so results are only available for four of the matchers: A-LIOn, LogMap, LogMapLt, Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961457252502441}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 122, "offsetEnd": 127}, "context": "The evaluation client 6 allows organizers to evaluate packaged systems whereby multiple submission formats are supported (SEALS packages or matchers implemented as Web services).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0027664899826049805}, "created": {"value": false, "score": 0.00026428699493408203}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 125, "offsetEnd": 131}, "context": "Matcha finds 2 correct correspondences out of the 63 reference correspondences which results in the only non-zero recall for Matcha in the MSE track along with a fair precision of 0.5 at a rather fast calculation time of 21s.", "mentionContextAttributes": {"used": {"value": false, "score": 0.45592039823532104}, "created": {"value": false, "score": 3.9517879486083984e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 125, "offsetEnd": 135}, "context": "On the Nell-DBpedia dataset, all systems were able to outperform the basic string matcher, in terms of f-measure, except for LogMapLite. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9991226196289062}, "created": {"value": false, "score": 8.52346420288086e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ekaw", "normalizedForm": "ekaw", "offsetStart": 126, "offsetEnd": 130}, "context": "This dataset results from the translation of 7 ontologies from the conference track (cmt, conference, confOf, iasted, sigkdd, ekaw and edas) into 10 languages: Arabic (ar), Chinese (cn), Czech (cz), Dutch (nl), French (fr), German (de), Italian (it), Portuguese (pt), Russian (ru), and Spanish (es).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9965890049934387}, "created": {"value": false, "score": 2.4437904357910156e-06}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998226165771484}, "created": {"value": false, "score": 0.00024271011352539062}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 126, "offsetEnd": 130}, "context": "While LogMap makes use of user interactions exclusively in the post-matching steps to filter their candidate correspondences, ALIN can also add new candidate correspondences to its initial set.", "mentionContextAttributes": {"used": {"value": false, "score": 3.904104232788086e-05}, "created": {"value": false, "score": 3.248453140258789e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ALIN", "normalizedForm": "ALIN", "offsetStart": 127, "offsetEnd": 131}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.0011328458786010742}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 128, "offsetEnd": 136}, "context": "This year, 5 systems have registered to participate in the MultiFarm track: CIDER-LM, LSMatch, LSMatch Multilingual, LogMap and LogMapLt. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.03688913583755493}, "created": {"value": false, "score": 0.00012922286987304688}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "wikidataId": "Q1461054", "wikipediaExternalRef": 8232236, "lang": "en", "confidence": 0.349, "software-name": {"rawForm": "Openjdk", "normalizedForm": "Openjdk", "wikidataId": "Q1461054", "wikipediaExternalRef": 8232236, "lang": "en", "confidence": 0.349, "offsetStart": 130, "offsetEnd": 137}, "version": {"rawForm": "1.8.0 265", "normalizedForm": "1.8.0 265", "offsetStart": 146, "offsetEnd": 155}, "context": "The evaluation was executed on a virtual machine (VM) with 32GB of RAM and 16 vCPUs (2.4 GHz), with Debian 9 operating system and Openjdk version 1.8.0 265. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999526143074036}, "created": {"value": false, "score": 8.183717727661133e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999526143074036}, "created": {"value": false, "score": 8.183717727661133e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 131, "offsetEnd": 137}, "context": "Of the remaining systems, LogMap has relatively small drops in F-measure when moving from discrete to continuous evaluation, while Matcha drops 14 percent in F-measure.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0017333626747131348}, "created": {"value": false, "score": 1.7464160919189453e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 131, "offsetEnd": 137}, "context": "AMD produced errors and an empty alignment file, so results are only available for four of the matchers: A-LIOn, LogMap, LogMapLt, Matcha.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961457252502441}, "created": {"value": false, "score": 3.874301910400391e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 133, "offsetEnd": 142}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 137, "offsetEnd": 146}, "context": "One reason might be that the properties are typed as rdf:Property and not distinguished into owl:ObjectProperty or owl:DatatypeProperty. ATMatcher reaches the best score with 0.96 F-Measure. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0701184868812561}, "created": {"value": false, "score": 6.377696990966797e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 140, "offsetEnd": 146}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 141, "offsetEnd": 145}, "context": "With the increasing usage of other programming languages than Java and increasing hardware requirements for matching systems, since 2021 the MELT Web interface was introduced in order to address this issue.", "mentionContextAttributes": {"used": {"value": false, "score": 4.32133674621582e-05}, "created": {"value": false, "score": 0.011087477207183838}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 143, "offsetEnd": 153}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.817), but four other systems obtained an F-measure above 0.88 (SEBMatcher, LogMapBio, LogMap, and AMD) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 2.682209014892578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GraphMatcher", "normalizedForm": "GraphMatcher", "offsetStart": 144, "offsetEnd": 156}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 147, "offsetEnd": 150}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56, "offsetStart": 50058, "offsetEnd": 50062}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEALS", "normalizedForm": "SEALS", "offsetStart": 148, "offsetEnd": 153}, "context": "The execution phase was terminated on September 30 \ud835\udc61\u210e , 2022, at which date participants had to submit the (near) final versions of their systems (SEALS-wrapped and/or HOBBIT-wrapped).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9630278944969177}, "created": {"value": false, "score": 0.0002009868621826172}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999945759773254}, "created": {"value": true, "score": 0.9941701889038086}, "shared": {"value": false, "score": 4.869699478149414e-05}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 148, "offsetEnd": 157}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 155, "offsetEnd": 164}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.817), but four other systems obtained an F-measure above 0.88 (SEBMatcher, LogMapBio, LogMap, and AMD) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 2.682209014892578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "edna", "normalizedForm": "edna", "offsetStart": 156, "offsetEnd": 160}, "context": "Additionally, we added two baselines: StringEquiv as a string matcher based on string equality applied on local names of entities which were lowercased and edna as a string editing distance matcher.", "mentionContextAttributes": {"used": {"value": false, "score": 0.260697603225708}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.972187876701355}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 157, "offsetEnd": 163}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 158, "offsetEnd": 164}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 159, "offsetEnd": 165}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 163, "offsetEnd": 167}, "context": "Fourth, we also allowed participants (with trust) to directly upload output mappings if their systems had not been published and had not been made compatible with MELT.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8763163089752197}, "created": {"value": false, "score": 0.006117522716522217}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 166, "offsetEnd": 172}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.817), but four other systems obtained an F-measure above 0.88 (SEBMatcher, LogMapBio, LogMap, and AMD) which is at least as good as the best systems in OAEI 2007-2010. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 2.682209014892578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 166, "offsetEnd": 174}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher+", "normalizedForm": "KGMatcher+", "offsetStart": 167, "offsetEnd": 177}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 169, "offsetEnd": 176}, "context": "The first test case evaluates matching systems regarding their capability to find \"equal\" (=), \"superclass\" (>) and \"subclass\" (<) correspondences between the mid-sized MatOnto and the small-sized (since reduced) MaterialInformation ontology.", "mentionContextAttributes": {"used": {"value": false, "score": 0.04792755842208862}, "created": {"value": false, "score": 1.1742115020751953e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995636343955994}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": true, "score": 0.951348066329956}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapBio", "normalizedForm": "LogMapBio", "offsetStart": 171, "offsetEnd": 180}, "context": "The exceptions were ALIN which increased in size (from 1119 to 1159), F-measure (from 0.835 to 0.852), recall (from 0.726 to 0.752) and recall+ (from 0.438 to 0.501), and LogMapBio increased in size (from 1586 to 1596), recall (from 0.914 to 0.919) and recall+ (from 0.773 to 0.787). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9666441679000854}, "created": {"value": false, "score": 7.092952728271484e-06}, "shared": {"value": false, "score": 1.0132789611816406e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 0.00018906593322753906}, "shared": {"value": false, "score": 1.0132789611816406e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 172, "offsetEnd": 178}, "context": "Other systems either fail to complete the task within the allocated 24 hours time limit such as LogMapLite, Matcha, and LsMatch, or produce an empty alignment file such as Matcha, LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003279447555541992}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 173, "offsetEnd": 179}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57, "offsetStart": 50090, "offsetEnd": 50094}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 178, "offsetEnd": 181}, "context": "Regarding quality, Matcha achieved the highest F-measure (0.941) and recall+ (0.817), but four other systems obtained an F-measure above 0.88 (SEBMatcher, LogMapBio, LogMap, and AMD) which is at least as good as the best systems in OAEI 2007-2010.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9898819327354431}, "created": {"value": false, "score": 2.682209014892578e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 179, "offsetEnd": 189}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 180, "offsetEnd": 186}, "context": "Other systems either fail to complete the task within the allocated 24 hours time limit such as LogMapLite, Matcha, and LsMatch, or produce an empty alignment file such as Matcha, LogMap (only on the YagoWikidata dataset). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003279447555541992}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLt", "normalizedForm": "LogMapLt", "offsetStart": 180, "offsetEnd": 188}, "context": "LogMap, LogMapLt and Matcha performed well on most NCBITAXON-TAXREF-LD subtasks, with slightly the same levels of precision and recall, the larger subtask could only be handled by LogMapLt. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9962204098701477}, "created": {"value": false, "score": 1.0311603546142578e-05}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0009583830833435059}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SEBMatcher", "normalizedForm": "SEBMatcher", "offsetStart": 180, "offsetEnd": 190}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 0.00016236305236816406}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 183, "offsetEnd": 189}, "context": "LogMapLt is almost 30 times slower than LogMap but finds the same amount of correspondences with 2 additional false positives, so it achieves a slightly lower overall F1-measure than LogMap. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005273222923278809}, "created": {"value": false, "score": 1.3649463653564453e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapKG", "normalizedForm": "LogMapKG", "offsetStart": 191, "offsetEnd": 199}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 4.589557647705078e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LsMatch", "normalizedForm": "LsMatch", "offsetStart": 201, "offsetEnd": 208}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 1.6510486602783203e-05}, "shared": {"value": false, "score": 2.980232238769531e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 214, "offsetEnd": 217}, "context": "Here, we include the results of 8 systems that were able to finish the task within the 24 hours time limit with a non-empty alignment file: LogMap, ATMatcher, Matcha, KGMatcher+, LogMapLite, LogMapKG, LsMatch, and AMD.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988036155700684}, "created": {"value": false, "score": 3.3974647521972656e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MELT", "normalizedForm": "MELT", "offsetStart": 220, "offsetEnd": 224}, "context": "As of this campaign, the use of the SEALS client and packaging format is deprecated in favor for MELT, with the sole exception of the Interactive Matching track, as simulated interactive matching is not yet supported by MELT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006028413772583008}, "created": {"value": false, "score": 0.00015211105346679688}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999966025352478}, "created": {"value": false, "score": 0.40564417839050293}, "shared": {"value": false, "score": 8.827447891235352e-05}}, "references": [{"label": "[62]", "normalizedForm": "[62]", "refKey": 62}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "StringEquiv", "normalizedForm": "StringEquiv", "offsetStart": 227, "offsetEnd": 238}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998717308044434}, "created": {"value": false, "score": 0.0018306374549865723}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 228, "offsetEnd": 234}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58, "offsetStart": 50142, "offsetEnd": 50146}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMap", "normalizedForm": "LogMap", "offsetStart": 241, "offsetEnd": 247}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.3709068298339844e-06}}, "references": [{"label": "[58]", "normalizedForm": "[58]", "refKey": 58}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AMD", "normalizedForm": "AMD", "offsetStart": 249, "offsetEnd": 252}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 1.4901161193847656e-06}}, "references": [{"label": "[56]", "normalizedForm": "[56]", "refKey": 56}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LSMatch", "normalizedForm": "LSMatch", "offsetStart": 254, "offsetEnd": 261}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9998794198036194}, "created": {"value": false, "score": 0.00254666805267334}, "shared": {"value": false, "score": 1.3709068298339844e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "ATMatcher", "normalizedForm": "ATMatcher", "offsetStart": 254, "offsetEnd": 263}, "context": "Briefly, we have the following participants for equivalence matching: (i) machine learningbased systems including BERTMap [52], BERTMap-Lite [52], AMD [56], Matcha [57] and Matcha-ML [57]; and (ii) traditional systems including LogMap [58], LogMap-Lite, ATMatcher [59], LSMatcher [60].", "mentionContextAttributes": {"used": {"value": true, "score": 0.971896767616272}, "created": {"value": false, "score": 3.039836883544922e-06}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 0.0004189610481262207}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[59]", "normalizedForm": "[59]", "refKey": 59, "offsetStart": 50171, "offsetEnd": 50175}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 262, "offsetEnd": 269}, "context": "Three out of eight submodules of the MaterialInformation were merged to create the Reduced MaterialInformation (32 classes, 43 properties and 17 individuals) for a more efficient creation of the manual reference alignment in the First Test Case, see Table 5.The MatOnto Ontology v2.1 24 (847 classes, 96 properties and 131 individuals) bases on the upper-level ontology bfo2 25 . ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995636343955994}, "created": {"value": false, "score": 1.8477439880371094e-06}, "shared": {"value": false, "score": 2.980232238769531e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995636343955994}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": true, "score": 0.951348066329956}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher+", "normalizedForm": "KGMatcher+", "offsetStart": 280, "offsetEnd": 290}, "context": "On the YagoWikidata dataset, two systems were not able to outperform the baseline, which are LogMapLite and In terms of runtime, Table 20 also presents the run time as HH:MM:SS where we can observe that all matching were able to finish the task in less than 30 minutes except for KGMatcher+ and LogMapLite. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 1.6093254089355469e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 1.0907649993896484e-05}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "LogMapLite", "normalizedForm": "LogMapLite", "offsetStart": 295, "offsetEnd": 305}, "context": "On the YagoWikidata dataset, two systems were not able to outperform the baseline, which are LogMapLite and In terms of runtime, Table 20 also presents the run time as HH:MM:SS where we can observe that all matching were able to finish the task in less than 30 minutes except for KGMatcher+ and LogMapLite. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 1.6093254089355469e-06}, "shared": {"value": false, "score": 5.364418029785156e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994593858718872}, "created": {"value": false, "score": 0.00028192996978759766}, "shared": {"value": false, "score": 5.364418029785156e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "MatOnto", "normalizedForm": "MatOnto", "offsetStart": 305, "offsetEnd": 312}, "context": "A-LIOn finds the highest number of correspondences, but of those 23 found correspondences 20 are false positives which results in the second best F1-measure The second test case evaluates the matching systems to find correspondences between the large-sized MaterialInformation and the mid-sized BFO-based MatOnto.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8211560845375061}, "created": {"value": false, "score": 1.3709068298339844e-06}, "shared": {"value": false, "score": 1.7881393432617188e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995636343955994}, "created": {"value": false, "score": 2.4378299713134766e-05}, "shared": {"value": true, "score": 0.951348066329956}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "KGMatcher", "normalizedForm": "KGMatcher", "offsetStart": 325, "offsetEnd": 334}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999455809593201}, "created": {"value": false, "score": 9.590387344360352e-05}, "shared": {"value": false, "score": 4.172325134277344e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Matcha", "normalizedForm": "Matcha", "offsetStart": 349, "offsetEnd": 355}, "context": "With regard to two baselines we can group tools according to system's position: six systems outperformed above both baselines (ALIN, ATMatcher, GraphMatcher, LogMap, LogMapLt, and SEBMatcher); two systems performed better than StringEquiv baseline (AMD, LSMatch), and four systems performed worse than both baselines (ALIOn, KGMatcher+, TOMATO, and Matcha).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993940591812134}, "created": {"value": false, "score": 2.3245811462402344e-06}, "shared": {"value": false, "score": 4.172325134277344e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995934367179871}, "created": {"value": false, "score": 0.0013892054557800293}, "shared": {"value": false, "score": 8.940696716308594e-07}}, "references": [{"label": "[57]", "normalizedForm": "[57]", "refKey": 57}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "CodeMeta", "normalizedForm": "CodeMeta", "offsetStart": 498, "offsetEnd": 506}, "context": "The source schemas include discipline agnostic schemas Dublin Core, Data Catalogue Vocabulary (DCAT), Data Catalogue Vocabulary -Application Profile (DCAT-AP), Registry Interchange Format -Collections and Services (RIF-CS), DataCite Schema, Dataverse; and discipline schemas ISO19115-1, EOSC/EDMI, Data Tag Suite (DATS), Bioschemas, B2FIND, Data Documentation Initiative (DDI), European Clinical Research Infrastructure Network (ECRIN), Space Physics Archive Search and Extract (SPASE); as well as CodeMeta for software.", "mentionContextAttributes": {"used": {"value": false, "score": 0.22850173711776733}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 1.1324882507324219e-06}}, "documentContextAttributes": {"used": {"value": false, "score": 0.22850173711776733}, "created": {"value": false, "score": 5.781650543212891e-06}, "shared": {"value": false, "score": 1.1324882507324219e-06}}}], "references": [{"refKey": 56, "tei": "<biblStruct xml:id=\"b56\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Stable Type Solutions of the Complex Laplacian Operators on Hermitian Manifolds</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Z</forename><surname>Wang</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">I</forename><forename type=\"middle\">F</forename><surname>Cruz</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/s00025-021-01512-4</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Results in Mathematics</title>\n\t\t<title level=\"j\" type=\"abbrev\">Results Math</title>\n\t\t<idno type=\"ISSN\">1422-6383</idno>\n\t\t<idno type=\"ISSNe\">1420-9012</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">76</biblScope>\n\t\t\t<biblScope unit=\"issue\">4</biblScope>\n\t\t\t<biblScope unit=\"page\">130</biblScope>\n\t\t\t<date type=\"published\" when=\"2021-09-18\">2021</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 58, "tei": "<biblStruct xml:id=\"b58\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">LogMap: Logic-Based and Scalable Ontology Matching</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Ernesto</forename><surname>Jim\u00e9nez-Ruiz</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Bernardo</forename><surname>Cuenca Grau</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-642-25073-6_18</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">The Semantic Web \u2013 ISWC 2011</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer Berlin Heidelberg</publisher>\n\t\t\t<date type=\"published\" when=\"2011\">2011</date>\n\t\t\t<biblScope unit=\"page\" from=\"273\" to=\"288\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 57, "tei": "<biblStruct xml:id=\"b57\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">D</forename><surname>Faria</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">C</forename><surname>Silva</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Cotovio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">P</forename><surname>Eug\u00e9nio</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">C</forename><surname>Pesquita</surname></persName>\n\t\t</author>\n\t\t<title level=\"m\">Matcha and matcha-dl results for oaei</title>\n\t\t<imprint>\n\t\t\t<date>2022. 2022</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 62, "tei": "<biblStruct xml:id=\"b62\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Visual Analysis of Ontology Matching Results with the MELT Dashboard</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jan</forename><surname>Portisch</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-5420-0663</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sven</forename><surname>Hertling</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0333-5888</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Heiko</forename><surname>Paulheim</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-4386-8195</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-030-62327-2_32</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">The Semantic Web: ESWC 2020 Satellite Events</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer International Publishing</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2020. December 2022</date>\n\t\t\t<biblScope unit=\"page\" from=\"186\" to=\"190\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 59, "tei": "<biblStruct xml:id=\"b59\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">The Knowledge Graph Track at OAEI</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sven</forename><surname>Hertling</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-0333-5888</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Heiko</forename><surname>Paulheim</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0003-4386-8195</idno>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/978-3-030-49461-2_20</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">The Semantic Web</title>\n\t\t<imprint>\n\t\t\t<publisher>Springer International Publishing</publisher>\n\t\t\t<date type=\"published\" when=\"2020\">2021. 2021</date>\n\t\t\t<biblScope unit=\"volume\">3063</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"343\" to=\"359\" />\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 138269, "id": "4ca240260fa956d2d008cb46dcac280ab8ee3621", "metadata": {"id": "4ca240260fa956d2d008cb46dcac280ab8ee3621"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/data/xml_not_sofctied/hal-04351729.grobid.tei.xml", "file_name": "hal-04351729.grobid.tei.xml"}