{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T11:47+0000", "md5": "9C320C3E794578DE7047CFB6B2EEE612", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 0, "offsetEnd": 6}, "context": "DiaBLa is a bilingual test set of spontaneous written dialogues between English and French speakers, mediated by MT.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001963973045349121}, "created": {"value": false, "score": 0.0008388757705688477}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 7, "offsetEnd": 13}, "context": "1-shot DiaBLa fr\u2192en increases from 12.05 to 41.36 and 0-shot Flores-101 hi\u2192en increases from 3.40 to 30.19).", "mentionContextAttributes": {"used": {"value": false, "score": 0.008982181549072266}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "COMET", "normalizedForm": "COMET", "offsetStart": 20, "offsetEnd": 44}, "context": "We additionally use COMET (Rei et al., 2020) for finer grained comparisons when the scores are closer.", "mentionContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 48, "offsetEnd": 54}, "context": "We test the usefulness of linguistic context in DiaBLa in the 1-shot setting (again using xglm-source+target) by changing the origin of 1-shot examples: (i) a random example vs. (ii) the previous dialogue utterance. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9755232334136963}, "created": {"value": false, "score": 1.5139579772949219e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 63, "offsetEnd": 69}, "context": "(of which 30% English), from various  (Goyal et al., 2022) and DiaBLa (Bawden et al., 2021).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 5.4836273193359375e-06}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3, "offsetStart": 8337, "offsetEnd": 8358}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SacreBLEU", "normalizedForm": "SacreBLEU", "offsetStart": 65, "offsetEnd": 86}, "context": "We evaluate using BLEU (Papineni et al., 2002) as implemented in SacreBLEU (Post, 2018), using as tokenisation 13a for WMT and DiaBLa and spm for Flores-101 as recommended (Costa-juss\u00e0 et al., 2022). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9878132343292236}, "created": {"value": false, "score": 0.00011873245239257812}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9878132343292236}, "created": {"value": false, "score": 0.00011873245239257812}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "COMET", "normalizedForm": "COMET", "offsetStart": 69, "offsetEnd": 74}, "context": "BLEU scores are in Table 2a for both 0-shot and 1-shot (results with COMET are given in Appendix A).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8926538825035095}, "created": {"value": false, "score": 1.239776611328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 81, "offsetEnd": 87}, "context": "These general observations apply for WMT and Flores-101, while issues remain for DiaBLa.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9785376787185669}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "COMET", "normalizedForm": "COMET", "offsetStart": 111, "offsetEnd": 116}, "context": "It is unclear whether using previous rather than random context helps: BLEU is higher (38.5 vs. 37.6), whereas COMET is lower (0.328 vs. 0.342).", "mentionContextAttributes": {"used": {"value": false, "score": 0.1255844235420227}, "created": {"value": false, "score": 1.4662742614746094e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.99874347448349}, "created": {"value": false, "score": 3.635883331298828e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 127, "offsetEnd": 133}, "context": "We evaluate using BLEU (Papineni et al., 2002) as implemented in SacreBLEU (Post, 2018), using as tokenisation 13a for WMT and DiaBLa and spm for Flores-101 as recommended (Costa-juss\u00e0 et al., 2022).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9878132343292236}, "created": {"value": false, "score": 0.00011873245239257812}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 132, "offsetEnd": 138}, "context": "Few-shot examples are randomly taken from the data splits according to availability (train for WMT, dev for Flores-101 and test for DiaBLa).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9851948618888855}, "created": {"value": false, "score": 4.649162292480469e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 136, "offsetEnd": 142}, "context": "We focus on BLOOM's multilingual ability by evaluating its machine translation performance across several datasets (WMT, Flores-101 and DiaBLa) and language pairs (high-and low-resourced).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8793954849243164}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "DiaBLa", "normalizedForm": "DiaBLa", "offsetStart": 430, "offsetEnd": 436}, "context": "Our evaluation of BLOOM starts with a comparison across the three datasets and detection of major MT errors with a focus on WMT (Section 5.1) and then we present more in-depth analyses of particular aspects: (i) using WMT, a comparative study of BLOOM model sizes (Section 5.2) and prompts (Section 5.3), (ii) using Flores-101 an evaluation of more language pairs and cross-lingual few-shot transfer (Section 5.4), and (ii) using DiaBLa, a study of the use of linguistic context (Section 5.5). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9928867220878601}, "created": {"value": false, "score": 8.344650268554688e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9994315505027771}, "created": {"value": false, "score": 0.12442922592163086}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "references": [{"label": "(Bawden et al., 2021)", "normalizedForm": "Bawden et al., 2021", "refKey": 3}]}], "references": [{"refKey": 3, "tei": "<biblStruct xml:id=\"b3\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">DiaBLa: a corpus of bilingual spontaneous written dialogues for machine translation</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Rachel</forename><surname>Bawden</surname></persName>\n\t\t\t<idno type=\"ORCID\">0000-0001-9553-1768</idno>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Eric</forename><surname>Bilinski</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Thomas</forename><surname>Lavergne</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sophie</forename><surname>Rosset</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1007/s10579-020-09514-4</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"j\">Language Resources and Evaluation</title>\n\t\t<title level=\"j\" type=\"abbrev\">Lang Resources &amp; Evaluation</title>\n\t\t<idno type=\"ISSN\">1574-020X</idno>\n\t\t<idno type=\"ISSNe\">1574-0218</idno>\n\t\t<imprint>\n\t\t\t<biblScope unit=\"volume\">55</biblScope>\n\t\t\t<biblScope unit=\"issue\">3</biblScope>\n\t\t\t<biblScope unit=\"page\" from=\"635\" to=\"660\" />\n\t\t\t<date type=\"published\" when=\"2020-11-23\">2021</date>\n\t\t\t<publisher>Springer Science and Business Media LLC</publisher>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 9805, "id": "99e235b47eb46923c45faa4c33c5154457fda1b0", "metadata": {"id": "99e235b47eb46923c45faa4c33c5154457fda1b0"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04015863.grobid.tei.xml", "file_name": "hal-04015863.grobid.tei.xml"}