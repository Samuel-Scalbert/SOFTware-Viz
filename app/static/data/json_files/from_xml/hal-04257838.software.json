{"application": "software-mentions", "version": "0.8.0", "date": "2024-10-07T12:05+0000", "md5": "619B28001FCAA1A0154B7F9B23B33480", "mentions": [{"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 0, "offsetEnd": 6}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "WebNLG 2017. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.033488333225250244}, "created": {"value": false, "score": 0.00026983022689819336}, "shared": {"value": false, "score": 2.2649765014648438e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 0, "offsetEnd": 6}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "WebNLG 2020. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0018101334571838379}, "created": {"value": false, "score": 0.0004290938377380371}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 0, "offsetEnd": 6}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "WebNLG 2017 is only has 16 generations improve over 0.1 for FactSpotter, whose baseline is very high. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02877289056777954}, "created": {"value": false, "score": 1.7762184143066406e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 0, "offsetEnd": 11}, "context": "FactSpotter can be extended to other data-to-text tasks via methods for transforming a relational dataset into RDF, such as the R2RML language1 .", "mentionContextAttributes": {"used": {"value": false, "score": 2.753734588623047e-05}, "created": {"value": false, "score": 0.00029343366622924805}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 0, "offsetEnd": 11}, "context": "FactSpotter is the best suited metric on factual faithfulness.", "mentionContextAttributes": {"used": {"value": false, "score": 8.952617645263672e-05}, "created": {"value": false, "score": 3.1113624572753906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 0, "offsetEnd": 11}, "context": "FactSpotter can be trained to correctly classify if a question refers to a triple, even if the object or subject is missing from the question, as we replace the entity with its type.", "mentionContextAttributes": {"used": {"value": false, "score": 6.663799285888672e-05}, "created": {"value": false, "score": 0.0005897283554077148}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 0, "offsetEnd": 11}, "context": "FactSpotter answers whether a fact is present in text; it does not have to address the much harder task of deciding if two sentences are equivalent. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0010700821876525879}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 0, "offsetEnd": 11}, "context": "FactSpotter training FactSpotter receives in the training set two types of negative samples. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005026817321777344}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SimpleQuestions", "normalizedForm": "SimpleQuestions", "offsetStart": 0, "offsetEnd": 15}, "context": "SimpleQuestions (Bordes et al., 2015) is a QA dataset built on Freebase (Bollacker et al., 2008).", "mentionContextAttributes": {"used": {"value": false, "score": 0.013916194438934326}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997730851173401}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "(Bordes et al., 2015)", "normalizedForm": "Bordes et al., 2015", "refKey": 5, "offsetStart": 22738, "offsetEnd": 22759}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 0, "offsetEnd": 25}, "context": "GrailQA (Gu et al., 2021) is also a QA dataset that uses Freebase, created using human annotation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032356977462768555}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 0, "offsetEnd": 58}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "WebNLG (Gardent et al., 2017;Castro Ferreira et al., 2020) is a text generation dataset on DBPedia, created via human annotation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008837580680847168}, "created": {"value": false, "score": 0.002479851245880127}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freebase", "normalizedForm": "Freebase", "offsetStart": 2, "offsetEnd": 10}, "context": "A Freebase domain is a general area of knowledge such as business, politics, economics, etc.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0005199313163757324}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Bollacker et al., 2008)", "normalizedForm": "Bollacker et al., 2008", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 2, "offsetEnd": 13}, "context": "\u2022 FactSpotter cannot be used to determine the precise nature of the error in the generated sentence. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.1407889723777771}, "created": {"value": false, "score": 8.344650268554688e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 2, "offsetEnd": 13}, "context": "4 FactSpotter: An explainable metric for factual faithfulness", "mentionContextAttributes": {"used": {"value": false, "score": 0.0003228187561035156}, "created": {"value": false, "score": 1.3232231140136719e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 3, "offsetEnd": 9}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "On WebNLG 2020, Table 2 shows that FactSpotter has the best performance on factual faithfulness, significantly improving relevance. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8670386672019958}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 3, "offsetEnd": 9}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "On WebNLG 2017, from the worst 40 generations, only two might benefit from improved fluency, while in many examples, the generated sentence was more fluent than the ground truth (14/40). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9976826906204224}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 3, "offsetEnd": 9}, "version": {"rawForm": "2020", "normalizedForm": "2020", "offsetStart": 9, "offsetEnd": 13}, "context": "On WebNLG2020, only one instance exhibits room for improvement in fluency, but 24 instances either omit factual information or contain incorrect facts. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.13654416799545288}, "created": {"value": false, "score": 2.0503997802734375e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 3, "offsetEnd": 9}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "On WebNLG 2017 dataset, three metrics achieve similar scores for semantic adequacy, with no results significantly larger than the others (computed  , 1996) correlation guidelines, where a value between 0.6 to 0.79 is \"strong correlation\" and 0.8 to 1.0 is \"very strong\", we have \"strong\" correlation for the type of sentence correlation to the annotation.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9192308187484741}, "created": {"value": false, "score": 4.887580871582031e-06}, "shared": {"value": false, "score": 1.1920928955078125e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SimpleQuestions", "normalizedForm": "SimpleQuestions", "offsetStart": 3, "offsetEnd": 18}, "context": "On SimpleQuestions, the generations are fluent, however 22/40 have an incorrect predicate.", "mentionContextAttributes": {"used": {"value": true, "score": 0.8725358247756958}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997730851173401}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "(Bordes et al., 2015)", "normalizedForm": "Bordes et al., 2015", "refKey": 5}]}, {"type": "software", "software-type": "implicit", "software-name": {"rawForm": "code", "normalizedForm": "code", "offsetStart": 4, "offsetEnd": 8}, "context": "Our code is available online:", "mentionContextAttributes": {"used": {"value": false, "score": 5.555152893066406e-05}, "created": {"value": false, "score": 0.10541188716888428}, "shared": {"value": false, "score": 0.020322144031524658}}, "documentContextAttributes": {"used": {"value": false, "score": 5.555152893066406e-05}, "created": {"value": false, "score": 0.10541188716888428}, "shared": {"value": false, "score": 0.020322144031524658}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 4, "offsetEnd": 10}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The WebNLG 2020 dataset has 40K pairs, which comprises 10 categories that were previously seen and utilized in WebNLG 2017, as well as 5 categories that were unseen in WebNLG 2017 are now incorporated into the seen data of the WebNLG 2020 dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.17671233415603638}, "created": {"value": false, "score": 4.971027374267578e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 4, "offsetEnd": 10}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "For WebNLG 2017 dataset, 11 generations are more factual, others are rephrased texts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4680315852165222}, "created": {"value": false, "score": 4.410743713378906e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 4, "offsetEnd": 10}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "For WebNLG 2020, 12 generations are more factual, and 3 are rephrased texts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.007128655910491943}, "created": {"value": false, "score": 1.1086463928222656e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 4, "offsetEnd": 10}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "For WebNLG2017, out of 223 human annotated sentences, we have for semantics    The second definition of sentence-level correlation (Banerjee and Lavie, 2005) is computed between the vector containing all the automatic scores for each sentence by a system S given by a metric M , and the vector containing the human metrics for each sentence.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9279923439025879}, "created": {"value": false, "score": 2.86102294921875e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 4, "offsetEnd": 11}, "context": "For GrailQA, in the IID split the predicates are correctly generated, but the models still have difficulties in generating some entity names (16/40).", "mentionContextAttributes": {"used": {"value": false, "score": 0.011324048042297363}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 6, "offsetEnd": 17}, "context": "Thus, FactSpotter is inherently interpretable. ", "mentionContextAttributes": {"used": {"value": false, "score": 3.612041473388672e-05}, "created": {"value": false, "score": 1.0013580322265625e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 7, "offsetEnd": 13}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In the WebNLG 2017 challenge (Shimorina et al., 2018), the organizers annotated 9 submissions on semantic adequacy (the text correctly represents the meaning in the data), text structure (as above, referred in the original paper as grammar) and fluency (as above). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9975950121879578}, "created": {"value": false, "score": 0.0001283884048461914}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 7, "offsetEnd": 18}, "context": "We use FactSpotter to do a more detailed analysis: we investigate what is the percentage of generations in each dataset which had at least a fact considered missing by FactSpotter. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": false, "score": 0.00024133920669555664}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 8, "offsetEnd": 14}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "For the WebNLG 2017 dataset, we can observe that for the small G2T model, T5S, the triples of size 4, 5 and 7 are more challenging, as is shown in Table 19.", "mentionContextAttributes": {"used": {"value": false, "score": 0.03784090280532837}, "created": {"value": false, "score": 6.67572021484375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 8, "offsetEnd": 15}, "context": "For the GrailQA dataset, rooted in Freebase, 99% of input graphs retain consistent entity names in their ground-truth sentences.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 8, "offsetEnd": 15}, "context": "For the GrailQA dataset, only 27% of predicates align perfectly with their KG representations in the ground-truth.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 9, "offsetEnd": 15}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "However, WebNLG and DART datasets have more complex input subgraphs, which has more number of triples, while GrailQA only has input subgraphs with up to 4 triples.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0054267048835754395}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 10, "offsetEnd": 16}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "After the WebNLG 2020 Challenge (Castro Ferreira et al., 2020), the organizers annotated the 16 participating systems on data correctness (the predicates found in the data are correctly mentioned together with their subject and object), data coverage (the text includes descriptions of all predicates presented in the data), and relevance (the text describes only those predicates with related subjects and objects which are in the data), in addition to text structure (the text is grammati-  cal, well structured, and written in good English) and fluency (the text progresses naturally, forms a coherent whole and is easy to understand).", "mentionContextAttributes": {"used": {"value": true, "score": 0.9996613264083862}, "created": {"value": false, "score": 1.0848045349121094e-05}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 11, "offsetEnd": 22}, "context": "Hence, our FactSpotter generally reflects factual faithfulness, but it might still be biased on some hard samples, especially when predicates in knowledge graphs are distant to their natural language representations in the vector space of language models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.000292360782623291}, "created": {"value": false, "score": 0.001357734203338623}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "However, on WebNLG 2020 dataset, all metrics demonstrate a \"moderate\" level of correlation, given that the scores hover between 0.3 and 0.49.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5667084455490112}, "created": {"value": false, "score": 5.245208740234375e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 12, "offsetEnd": 18}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "However, on WebNLG 2017 we observe a higher agreement on semantic adequancy, for which we also observed a high correlation with our metric at sentence level.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995375871658325}, "created": {"value": false, "score": 0.00021582841873168945}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 12, "offsetEnd": 23}, "context": "Our metric, FactSpotter, is trained as a binary classifier. ", "mentionContextAttributes": {"used": {"value": false, "score": 7.092952728271484e-05}, "created": {"value": true, "score": 0.9708622694015503}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 13, "offsetEnd": 24}, "context": "In addition, FactSpotter can be used as a plug-in feature to improve the factual faithfulness of existing models. ", "mentionContextAttributes": {"used": {"value": false, "score": 2.849102020263672e-05}, "created": {"value": false, "score": 0.0005274415016174316}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 14, "offsetEnd": 21}, "context": "Regarding the GrailQA zero-shot split, single-triple verbalization consistently achieves superior scores with FactSpotter.", "mentionContextAttributes": {"used": {"value": false, "score": 0.15328747034072876}, "created": {"value": false, "score": 1.3589859008789062e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 15, "offsetEnd": 21}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "On the dataset WebNLG 2017, our metric assigns a very high score to the models, while the highest average BLEURT score is 73.44%.", "mentionContextAttributes": {"used": {"value": false, "score": 0.27626025676727295}, "created": {"value": false, "score": 1.728534698486328e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 15, "offsetEnd": 22}, "context": "The results of GrailQA dataset are illustrated in Tables 25,29, and 27.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9992233514785767}, "created": {"value": false, "score": 4.0531158447265625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 15, "offsetEnd": 26}, "context": "To ensure that FactSpotter has never encountered the test data, it is trained exclusively on the training set and evaluated it on the validation split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9983521699905396}, "created": {"value": false, "score": 6.818771362304688e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 15, "offsetEnd": 26}, "context": "\u2022 The input of FactSpotter is the concatenation of a fact f represented in triple and a natural language text T , i.e., it has limited input format. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.004462003707885742}, "created": {"value": false, "score": 1.3470649719238281e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 16, "offsetEnd": 27}, "context": "In Table 6, the FactSpotter scores are lower for the WebNLG 2020 test split, although we achieve scores comparable to WebNLG 2017 on its validation split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6424804925918579}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 16, "offsetEnd": 27}, "context": "Remarkably high FactSpotter scores are observed for inputs containing 6 or 7 triples.", "mentionContextAttributes": {"used": {"value": true, "score": 0.582940399646759}, "created": {"value": false, "score": 7.033348083496094e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 17, "offsetEnd": 23}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "5 generations in WebNLG 2020 have higher FactSpotter than baseline generations, but they're still not factual enough.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003955245018005371}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 18, "offsetEnd": 24}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In particular, on WebNLG2020, the annotators were asked to give a score from 0 to 100 to a sentence for a given dimension such as correctness.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 7.867813110351562e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 18, "offsetEnd": 29}, "context": "We note that only FactSpotter is significantly larger than the other metrics on data coverage and relevance for WebNLG 2020, and semantic adequacy for WebNLG 2017, which are metrics about factual faithfulness. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.044040024280548096}, "created": {"value": false, "score": 1.1444091796875e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 18, "offsetEnd": 29}, "context": "After integrating FactSpotter into the inference of G2T generation, without retraining the G2T model, our FactJointGT can generate texts that verbalize facts in subgraphs more correctly and completely.", "mentionContextAttributes": {"used": {"value": false, "score": 6.663799285888672e-05}, "created": {"value": false, "score": 0.34687232971191406}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 19, "offsetEnd": 25}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "For the results on WebNLG 2017 in Table 3, FactSpotter has the highest performance on semantic adequacy, which is the only dimension related to factual faithfulness. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.913621723651886}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 19, "offsetEnd": 30}, "context": "The performance of FactSpotter on the test splits across multiple datasets is detailed in Table 1, with accuracy and F1 score. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9797461628913879}, "created": {"value": false, "score": 3.2782554626464844e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 19, "offsetEnd": 30}, "context": "The integration of FactSpotter enhances the factuality of the results (as evident in F-T5S). ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006542801856994629}, "created": {"value": false, "score": 1.9550323486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 21, "offsetEnd": 32}, "context": "FactSpotter training FactSpotter receives in the training set two types of negative samples. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.005026817321777344}, "created": {"value": false, "score": 9.417533874511719e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 22, "offsetEnd": 33}, "context": "We have observed high FactSpotter scores in Section 6 on the performances of models.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999547004699707}, "created": {"value": false, "score": 3.24249267578125e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 24, "offsetEnd": 31}, "context": "In Appendix A.7, taking GrailQA and WebNLG 2017 as examples, we analysed the difficulty of G2T on datasets from different knowledge graphs, by looking into how often predicates and entity names are rephrased or expressed exactly as in the input graph.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998598039150238}, "created": {"value": false, "score": 3.457069396972656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 24, "offsetEnd": 35}, "context": "We show that our metric FactSpotter achieves the highest correlation with human annotations on data correctness, data coverage, and relevance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.07368600368499756}, "created": {"value": false, "score": 0.11986863613128662}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 24, "offsetEnd": 35}, "context": "Table 5 has the highest FactSpotter score from all datasets, which means that we observe the most factual generations on WebNLG 2017, with F-T5 and FGT having slightly higher scores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.46670079231262207}, "created": {"value": false, "score": 5.7220458984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 25, "offsetEnd": 36}, "context": "Above, we have described FactSpotter as a (trained) classifier.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015163421630859375}, "created": {"value": true, "score": 0.5243136882781982}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 25, "offsetEnd": 36}, "context": "We generally have a high FactSpotter score, indicating that models are already good at relaying factual information.", "mentionContextAttributes": {"used": {"value": false, "score": 0.02341604232788086}, "created": {"value": false, "score": 0.001177966594696045}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 25, "offsetEnd": 36}, "context": "F-T5B can achieve higher FactSpotter score than T5B without compromising fluency.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020760297775268555}, "created": {"value": false, "score": 6.556510925292969e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 27, "offsetEnd": 34}, "context": "For the Zero-shot split of GrailQA, 14 generations are more factual.", "mentionContextAttributes": {"used": {"value": false, "score": 0.033415377140045166}, "created": {"value": false, "score": 1.4781951904296875e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 28, "offsetEnd": 34}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Predicate Generation In the WebNLG 2017 dataset, 49% of predicates appear the same as in the KB in their corresponding ground-truth sentences.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9148977994918823}, "created": {"value": false, "score": 7.152557373046875e-06}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 29, "offsetEnd": 40}, "context": "As we aim to add our metric, FactSpotter, in the inference step of graph-to-text generation, we prefer small language models.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0006566643714904785}, "created": {"value": true, "score": 0.96503084897995}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 30, "offsetEnd": 41}, "context": "For this question, we compare FactSpotter with: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), BERTScore (Zhang et al., 2019), BLEURT (Sellam et al., 2020), BARTScore (Yuan et al., 2021).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8362823128700256}, "created": {"value": false, "score": 6.318092346191406e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 31, "offsetEnd": 37}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "According to the observations, WebNLG 2020 is the most challenging dataset, followed by DART, the zero shot split of GrailQA, and the WebNLG 2017 dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5563043355941772}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AdamW", "normalizedForm": "AdamW", "offsetStart": 32, "offsetEnd": 37}, "context": "We use a beam size of 5 and the AdamW optimizer for both sizes of models. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9995864033699036}, "created": {"value": false, "score": 6.198883056640625e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995864033699036}, "created": {"value": false, "score": 0.008167266845703125}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SimpleQuestions", "normalizedForm": "SimpleQuestions", "offsetStart": 33, "offsetEnd": 48}, "context": "Table 4 shows the results on the SimpleQuestions dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9997730851173401}, "created": {"value": false, "score": 9.5367431640625e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997730851173401}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "(Bordes et al., 2015)", "normalizedForm": "Bordes et al., 2015", "refKey": 5}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 35, "offsetEnd": 42}, "context": "The au-2 https://dki-lab.github.io/GrailQA/ 3 https://gitlab.com/shimorina/webnlg-dataset", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019556283950805664}, "created": {"value": false, "score": 6.9141387939453125e-06}, "shared": {"value": true, "score": 0.9582262635231018}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freebase", "normalizedForm": "Freebase", "offsetStart": 35, "offsetEnd": 43}, "context": "For the GrailQA dataset, rooted in Freebase, 99% of input graphs retain consistent entity names in their ground-truth sentences. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Bollacker et al., 2008)", "normalizedForm": "Bollacker et al., 2008", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 35, "offsetEnd": 46}, "context": "On WebNLG 2020, Table 2 shows that FactSpotter has the best performance on factual faithfulness, significantly improving relevance. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8670386672019958}, "created": {"value": false, "score": 1.5974044799804688e-05}, "shared": {"value": false, "score": 5.960464477539062e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 35, "offsetEnd": 46}, "context": "Hence, we can conclude that adding FactSpotter as a plugin in generation can improve G2T generations on factual faithfulness and does not affect the fluency.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00017970800399780273}, "created": {"value": false, "score": 0.0008674263954162598}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 36, "offsetEnd": 42}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In Appendix A.7, taking GrailQA and WebNLG 2017 as examples, we analysed the difficulty of G2T on datasets from different knowledge graphs, by looking into how often predicates and entity names are rephrased or expressed exactly as in the input graph.", "mentionContextAttributes": {"used": {"value": true, "score": 0.998598039150238}, "created": {"value": false, "score": 3.457069396972656e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 36, "offsetEnd": 42}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Summary of Difficulty Datasets like WebNLG (from DBPedia) and GrailQA (from FreeBase) present challenges on different fronts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004246830940246582}, "created": {"value": false, "score": 3.5643577575683594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 38, "offsetEnd": 49}, "context": "In the remaining of the paper, we use FactSpotter with the parameters 0.9-0.1.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9994109869003296}, "created": {"value": false, "score": 0.0002987980842590332}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freebase", "normalizedForm": "Freebase", "offsetStart": 40, "offsetEnd": 48}, "context": "50% of the pairs from held-out domains (Freebase assigns to each entity and predicate a domain, such as music, sports, etc.) are not covered in training: this is the zero-shot split. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.051078736782073975}, "created": {"value": false, "score": 4.6372413635253906e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Bollacker et al., 2008)", "normalizedForm": "Bollacker et al., 2008", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 41, "offsetEnd": 52}, "context": "5 generations in WebNLG 2020 have higher FactSpotter than baseline generations, but they're still not factual enough.", "mentionContextAttributes": {"used": {"value": false, "score": 0.003955245018005371}, "created": {"value": false, "score": 1.1324882507324219e-05}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 43, "offsetEnd": 54}, "context": "For the results on WebNLG 2017 in Table 3, FactSpotter has the highest performance on semantic adequacy, which is the only dimension related to factual faithfulness. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.913621723651886}, "created": {"value": false, "score": 7.271766662597656e-06}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 43, "offsetEnd": 54}, "context": "The weight \u03bb controls the influence of the FactSpotter on the prediction of the following words.", "mentionContextAttributes": {"used": {"value": false, "score": 0.4110223054885864}, "created": {"value": false, "score": 2.8848648071289062e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 44, "offsetEnd": 55}, "context": "Only 7 samples of IID improve over 0.01 for FactSpotter, so this split is not challenging. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.3855896592140198}, "created": {"value": false, "score": 1.9311904907226562e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 49, "offsetEnd": 60}, "context": "Beginning with two triples, the incorporation of FactSpotter offers a discernible boost in model performance. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0001423358917236328}, "created": {"value": false, "score": 0.008546948432922363}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 50, "offsetEnd": 61}, "context": "In contrast, among the 20 outputs with the lowest FactSpotter, only 4 instances fall into this category.", "mentionContextAttributes": {"used": {"value": false, "score": 0.09956514835357666}, "created": {"value": false, "score": 4.279613494873047e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 50, "offsetEnd": 61}, "context": "To validate that indeed generations improve using FactSpotter in inference, we select the best FGT-T5 model and we analyse the top 20 phrases where the FactSpotter score improved the most compared to the JGT-T5 generations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988829493522644}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 53, "offsetEnd": 59}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In Table 6, the FactSpotter scores are lower for the WebNLG 2020 test split, although we achieve scores comparable to WebNLG 2017 on its validation split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6424804925918579}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freebase", "normalizedForm": "Freebase", "offsetStart": 57, "offsetEnd": 65}, "context": "GrailQA (Gu et al., 2021) is also a QA dataset that uses Freebase, created using human annotation. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0032356977462768555}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Bollacker et al., 2008)", "normalizedForm": "Bollacker et al., 2008", "refKey": 4}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 58, "offsetEnd": 69}, "context": "Hence the factual faithfulness of G2T task is improved by FactSpotter, but the other metrics do not necessary improve, since rephrased high quality texts might also be punished.", "mentionContextAttributes": {"used": {"value": false, "score": 0.08692598342895508}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 59, "offsetEnd": 70}, "context": "We consider the worst 20 sentences according to BLEURT and FactSpotter, hence 40 examples per dataset or split. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9944968819618225}, "created": {"value": false, "score": 2.968311309814453e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 60, "offsetEnd": 67}, "context": "In Table 8, all the metrics are higher for the IID split of GrailQA, and in particular FactSpotter can reach 99.5%, hence the models learn to reproduce triples seen in training.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008855760097503662}, "created": {"value": false, "score": 2.9325485229492188e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 60, "offsetEnd": 71}, "context": "WebNLG 2017 is only has 16 generations improve over 0.1 for FactSpotter, whose baseline is very high. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.02877289056777954}, "created": {"value": false, "score": 1.7762184143066406e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 62, "offsetEnd": 69}, "context": "Summary of Difficulty Datasets like WebNLG (from DBPedia) and GrailQA (from FreeBase) present challenges on different fronts.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0004246830940246582}, "created": {"value": false, "score": 3.5643577575683594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 63, "offsetEnd": 70}, "context": "In Table 11, we vary the value of \u03bb on the different splits of GrailQA on the T5 small model.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6965503692626953}, "created": {"value": false, "score": 1.2755393981933594e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "Freebase", "normalizedForm": "Freebase", "offsetStart": 63, "offsetEnd": 71}, "context": "SimpleQuestions (Bordes et al., 2015) is a QA dataset built on Freebase (Bollacker et al., 2008).", "mentionContextAttributes": {"used": {"value": false, "score": 0.013916194438934326}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9889408946037292}, "created": {"value": false, "score": 0.002154827117919922}, "shared": {"value": false, "score": 1.3113021850585938e-06}}, "references": [{"label": "(Bollacker et al., 2008)", "normalizedForm": "Bollacker et al., 2008", "refKey": 4, "offsetStart": 22794, "offsetEnd": 22818}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 64, "offsetEnd": 70}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In Tables 16 and17, we present the interannotator agreement for WebNLG 2017 and 2020 using Krippendorff's alpha (Krippendorff, 2018). ", "mentionContextAttributes": {"used": {"value": true, "score": 0.8550024032592773}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "SimpleQuestions", "normalizedForm": "SimpleQuestions", "offsetStart": 66, "offsetEnd": 81}, "context": "We obtain the following statistics: 1.94% of texts miss a fact in SimpleQuestions; 7.27% of texts miss at least a fact in DART; 5.79% of WebNLG 2017 texts miss at least one fact, and 12.64% for WebNLG 2020; For GrailQA we have 5.8% for the zero shot split, 4.36% for the compositional split and 1.13 for the IID split. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9074850082397461}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997730851173401}, "created": {"value": false, "score": 0.00011241436004638672}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "references": [{"label": "(Bordes et al., 2015)", "normalizedForm": "Bordes et al., 2015", "refKey": 5}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 71, "offsetEnd": 77}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The human correlation results computed as the second definition on the WebNLG 2017 and 2020 annotations are reported in Tables 14 and15 respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998782873153687}, "created": {"value": false, "score": 2.2649765014648438e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 71, "offsetEnd": 78}, "context": "The samples are from the hardest zero-shot and compositional splits of GrailQA dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9993960857391357}, "created": {"value": false, "score": 3.0994415283203125e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 74, "offsetEnd": 80}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Several datasets are proposed in the literature for the G2T task, such as WebNLG (Gardent et al., 2017).", "mentionContextAttributes": {"used": {"value": false, "score": 0.0002695918083190918}, "created": {"value": false, "score": 0.05327260494232178}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17, "offsetStart": 22331, "offsetEnd": 22353}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 75, "offsetEnd": 81}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We report the human correlation results computed as this definition on the WebNLG 2017 and 2020 annotations in Tables 12 and13 respectively.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999346733093262}, "created": {"value": false, "score": 1.621246337890625e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 75, "offsetEnd": 86}, "context": "We believe our contribution can further advance the state-ofthe-art as: i) FactSpotter requires significantly less computational resources; ii) FactSpotter is self supervised, thus it does not requires additional data to the G2T model; item FactSpotter can be pluged into a G2T to improve its generation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020247697830200195}, "created": {"value": false, "score": 0.2176796793937683}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 81, "offsetEnd": 87}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We also observed a distinct improvement across various numbers of triples in the WebNLG 2020 dataset, especially when handling sentences comprising multiple triples.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998902082443237}, "created": {"value": false, "score": 0.0010237693786621094}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 81, "offsetEnd": 92}, "context": "More precisely, our contributions are as follows: i) We introduce a novel metric FactSpotter for detecting if G2T generations are faithful to the facts present in the input graph; ii) We show how FactSpotter can be used in the inference step of any G2T model to improve its generations; iii) We analyze the difficulty of existing G2T datasets and determine which are (resp., are no longer) challenging for state-of-the-art models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.018280088901519775}, "created": {"value": false, "score": 0.0004601478576660156}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 82, "offsetEnd": 93}, "context": "DART dataset has samples that ground-truth sentences do not match with graphs, so FactSpotter trained on DART has false positives. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.7455152273178101}, "created": {"value": false, "score": 6.079673767089844e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "AdamW", "normalizedForm": "AdamW", "offsetStart": 83, "offsetEnd": 88}, "context": "We train our classifier for 16 epochs, with a learning rate of 5 \u2022 10 -5 , and the AdamW optimizer.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0008152127265930176}, "created": {"value": false, "score": 0.008167266845703125}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9995864033699036}, "created": {"value": false, "score": 0.008167266845703125}, "shared": {"value": false, "score": 2.384185791015625e-07}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 84, "offsetEnd": 95}, "context": "For this, we first explain how to improve the inference step of any G2T model using FactSpotter, and then we present the results of this technique on the stateof-the-art models for G2T generation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.12968343496322632}, "created": {"value": true, "score": 0.9672775268554688}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 84, "offsetEnd": 95}, "context": "In the compositional split, mirroring the trend observed in the zero-shot scenario, FactSpotter scores remain high for single-triple inputs.", "mentionContextAttributes": {"used": {"value": false, "score": 0.023388206958770752}, "created": {"value": false, "score": 8.821487426757812e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 87, "offsetEnd": 98}, "context": "We describe in the Appendix A.4.1 how we chose the percentages of negative samples for FactSpotter.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999823570251465}, "created": {"value": false, "score": 6.639957427978516e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 87, "offsetEnd": 98}, "context": "In Table 8, all the metrics are higher for the IID split of GrailQA, and in particular FactSpotter can reach 99.5%, hence the models learn to reproduce triples seen in training.", "mentionContextAttributes": {"used": {"value": false, "score": 0.008855760097503662}, "created": {"value": false, "score": 2.9325485229492188e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 88, "offsetEnd": 99}, "context": "In this work, we have presented a new metric for measuring factual faithfulness in G2T, FactSpotter.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00010919570922851562}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 92, "offsetEnd": 103}, "context": "Given:i) a graph-to-text generation model M, ii) our factual faithfulness classifier, i.e., FactSpotter, iii) a subgraph G composed of F facts, we encourage factual generations by modifying the prediction step as follows:", "mentionContextAttributes": {"used": {"value": false, "score": 0.20164167881011963}, "created": {"value": false, "score": 1.9073486328125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 95, "offsetEnd": 106}, "context": "Table 9 shows the improvement of factual faithfulness in G2T generation task after integrating FactSpotter into G2T inference.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9894664883613586}, "created": {"value": false, "score": 5.14984130859375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 96, "offsetEnd": 107}, "context": "For the cases where a generation becomes less factual, this is a consequence of the accuracy of FactSpotter, which we present in Section 4. Given that our metric does not correlate strongly with fluency, we perform a second analysis on generations to observe if there is a decrease in fluency.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5362175107002258}, "created": {"value": false, "score": 5.3882598876953125e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 100, "offsetEnd": 111}, "context": "Furthermore, there is a marked improvement for inputs with two or more triples upon the addition of FactSpotter. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.0037131309509277344}, "created": {"value": false, "score": 0.0001316070556640625}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 102, "offsetEnd": 113}, "context": "As for the DART dataset in Table 23, inputs ranging from 1 to 5 triples witness improved results with FactSpotter's addition.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999645948410034}, "created": {"value": false, "score": 3.6954879760742188e-06}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 104, "offsetEnd": 115}, "context": "Inspired by the efficacy of Constrained Beam Search in ensuring accurate entity generation, we designed FactSpotter to enhance the accurate production of rephrased facts, especially rephrased predicates to be correctly generated.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00011873245239257812}, "created": {"value": true, "score": 0.999290943145752}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 109, "offsetEnd": 115}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "This discrepancy may be attributed to the difference in distribution between the test and training splits of WebNLG 2020.", "mentionContextAttributes": {"used": {"value": true, "score": 0.997307538986206}, "created": {"value": false, "score": 2.002716064453125e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 109, "offsetEnd": 115}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Correlation at the system level with human judgment on semantic adequacy, grammar, and fluency, for the 2017 WebNLG dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9998575448989868}, "created": {"value": false, "score": 5.7220458984375e-06}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 109, "offsetEnd": 116}, "context": "However, WebNLG and DART datasets have more complex input subgraphs, which has more number of triples, while GrailQA only has input subgraphs with up to 4 triples.", "mentionContextAttributes": {"used": {"value": false, "score": 0.0054267048835754395}, "created": {"value": false, "score": 2.0742416381835938e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 110, "offsetEnd": 121}, "context": "Regarding the GrailQA zero-shot split, single-triple verbalization consistently achieves superior scores with FactSpotter. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.15328747034072876}, "created": {"value": false, "score": 1.3589859008789062e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 111, "offsetEnd": 117}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The WebNLG 2020 dataset has 40K pairs, which comprises 10 categories that were previously seen and utilized in WebNLG 2017, as well as 5 categories that were unseen in WebNLG 2017 are now incorporated into the seen data of the WebNLG 2020 dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.17671233415603638}, "created": {"value": false, "score": 4.971027374267578e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 112, "offsetEnd": 118}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We note that only FactSpotter is significantly larger than the other metrics on data coverage and relevance for WebNLG 2020, and semantic adequacy for WebNLG 2017, which are metrics about factual faithfulness. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.044040024280548096}, "created": {"value": false, "score": 1.1444091796875e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 114, "offsetEnd": 125}, "context": "For Zero-shot and Compositional splits, larger models are better, and our factual inference improves the score of FactSpotter.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00015532970428466797}, "created": {"value": false, "score": 0.0004973411560058594}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 115, "offsetEnd": 121}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Entity Generation Regarding the difficulty of generating correct entities, we have the following statistics on the WebNLG 2017 dataset (v2.1):", "mentionContextAttributes": {"used": {"value": true, "score": 0.9933826923370361}, "created": {"value": false, "score": 0.0001035928726196289}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 117, "offsetEnd": 124}, "context": "According to the observations, WebNLG 2020 is the most challenging dataset, followed by DART, the zero shot split of GrailQA, and the WebNLG 2017 dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5563043355941772}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 118, "offsetEnd": 124}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "In Table 6, the FactSpotter scores are lower for the WebNLG 2020 test split, although we achieve scores comparable to WebNLG 2017 on its validation split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.6424804925918579}, "created": {"value": false, "score": 1.5020370483398438e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 121, "offsetEnd": 127}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Table 5 has the highest FactSpotter score from all datasets, which means that we observe the most factual generations on WebNLG 2017, with F-T5 and FGT having slightly higher scores.", "mentionContextAttributes": {"used": {"value": false, "score": 0.46670079231262207}, "created": {"value": false, "score": 5.7220458984375e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 123, "offsetEnd": 129}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We explain two distinct definitions of sentencelevel correlation provided by literature and report the correlations on the WebNLG human annotations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9980706572532654}, "created": {"value": false, "score": 0.0014910101890563965}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 134, "offsetEnd": 140}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "According to the observations, WebNLG 2020 is the most challenging dataset, followed by DART, the zero shot split of GrailQA, and the WebNLG 2017 dataset.", "mentionContextAttributes": {"used": {"value": true, "score": 0.5563043355941772}, "created": {"value": false, "score": 1.2874603271484375e-05}, "shared": {"value": false, "score": 1.1920928955078125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 137, "offsetEnd": 143}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We obtain the following statistics: 1.94% of texts miss a fact in SimpleQuestions; 7.27% of texts miss at least a fact in DART; 5.79% of WebNLG 2017 texts miss at least one fact, and 12.64% for WebNLG 2020; For GrailQA we have 5.8% for the zero shot split, 4.36% for the compositional split and 1.13 for the IID split. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9074850082397461}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 138, "offsetEnd": 149}, "context": "To determine the best balance between negative samples of type I, respectively, type II, we compute the correlations between the score of FactSpotter and a subset of 50 annotations per system from the 2020 WebNLG challenge. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961000680923462}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 142, "offsetEnd": 153}, "context": "This problem can be solved by a second classification step for whether predicates or entities are incorrectly verbalized in the text, to make FactSpotter more interpretable.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00019818544387817383}, "created": {"value": false, "score": 5.173683166503906e-05}, "shared": {"value": false, "score": 3.5762786865234375e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 144, "offsetEnd": 155}, "context": "We believe our contribution can further advance the state-ofthe-art as: i) FactSpotter requires significantly less computational resources; ii) FactSpotter is self supervised, thus it does not requires additional data to the G2T model; item FactSpotter can be pluged into a G2T to improve its generation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020247697830200195}, "created": {"value": false, "score": 0.21767973899841309}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 151, "offsetEnd": 157}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We note that only FactSpotter is significantly larger than the other metrics on data coverage and relevance for WebNLG 2020, and semantic adequacy for WebNLG 2017, which are metrics about factual faithfulness. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.044040024280548096}, "created": {"value": false, "score": 1.1444091796875e-05}, "shared": {"value": false, "score": 4.76837158203125e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 152, "offsetEnd": 163}, "context": "To validate that indeed generations improve using FactSpotter in inference, we select the best FGT-T5 model and we analyse the top 20 phrases where the FactSpotter score improved the most compared to the JGT-T5 generations.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9988829493522644}, "created": {"value": false, "score": 1.0132789611816406e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 168, "offsetEnd": 174}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The WebNLG 2020 dataset has 40K pairs, which comprises 10 categories that were previously seen and utilized in WebNLG 2017, as well as 5 categories that were unseen in WebNLG 2017 are now incorporated into the seen data of the WebNLG 2020 dataset. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.17671233415603638}, "created": {"value": false, "score": 4.971027374267578e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 168, "offsetEnd": 179}, "context": "We use FactSpotter to do a more detailed analysis: we investigate what is the percentage of generations in each dataset which had at least a fact considered missing by FactSpotter. ", "mentionContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": false, "score": 0.00024133920669555664}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 194, "offsetEnd": 200}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "We obtain the following statistics: 1.94% of texts miss a fact in SimpleQuestions; 7.27% of texts miss at least a fact in DART; 5.79% of WebNLG 2017 texts miss at least one fact, and 12.64% for WebNLG 2020; For GrailQA we have 5.8% for the zero shot split, 4.36% for the compositional split and 1.13 for the IID split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9074850082397461}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 196, "offsetEnd": 207}, "context": "More precisely, our contributions are as follows: i) We introduce a novel metric FactSpotter for detecting if G2T generations are faithful to the facts present in the input graph; ii) We show how FactSpotter can be used in the inference step of any G2T model to improve its generations; iii) We analyze the difficulty of existing G2T datasets and determine which are (resp., are no longer) challenging for state-of-the-art models. ", "mentionContextAttributes": {"used": {"value": false, "score": 0.018280088901519775}, "created": {"value": false, "score": 0.0004601478576660156}, "shared": {"value": false, "score": 1.430511474609375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 206, "offsetEnd": 212}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "To determine the best balance between negative samples of type I, respectively, type II, we compute the correlations between the score of FactSpotter and a subset of 50 annotations per system from the 2020 WebNLG challenge.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9961000680923462}, "created": {"value": false, "score": 1.1563301086425781e-05}, "shared": {"value": false, "score": 2.384185791015625e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "GrailQA", "normalizedForm": "GrailQA", "offsetStart": 211, "offsetEnd": 218}, "context": "We obtain the following statistics: 1.94% of texts miss a fact in SimpleQuestions; 7.27% of texts miss at least a fact in DART; 5.79% of WebNLG 2017 texts miss at least one fact, and 12.64% for WebNLG 2020; For GrailQA we have 5.8% for the zero shot split, 4.36% for the compositional split and 1.13 for the IID split.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9074850082397461}, "created": {"value": false, "score": 2.0265579223632812e-06}, "shared": {"value": false, "score": 1.6689300537109375e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9997273087501526}, "created": {"value": false, "score": 0.00018984079360961914}, "shared": {"value": true, "score": 0.9582262635231018}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 227, "offsetEnd": 233}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "The WebNLG 2020 dataset has 40K pairs, which comprises 10 categories that were previously seen and utilized in WebNLG 2017, as well as 5 categories that were unseen in WebNLG 2017 are now incorporated into the seen data of the WebNLG 2020 dataset.", "mentionContextAttributes": {"used": {"value": false, "score": 0.17671233415603638}, "created": {"value": false, "score": 4.971027374267578e-05}, "shared": {"value": false, "score": 8.344650268554688e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 241, "offsetEnd": 252}, "context": "We believe our contribution can further advance the state-ofthe-art as: i) FactSpotter requires significantly less computational resources; ii) FactSpotter is self supervised, thus it does not requires additional data to the G2T model; item FactSpotter can be pluged into a G2T to improve its generation.", "mentionContextAttributes": {"used": {"value": false, "score": 0.00020247697830200195}, "created": {"value": false, "score": 0.21767973899841309}, "shared": {"value": false, "score": 7.152557373046875e-07}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "WebNLG", "normalizedForm": "WebNLG", "offsetStart": 251, "offsetEnd": 257}, "version": {"rawForm": "2020", "normalizedForm": "2020"}, "context": "Besides creating tableto-text annotations, the authors also use existing datasets: the QA dataset WikiSQL (Zhong et al., 2017), the cleaned E2E (Du\u0161ek et al., 2019) (entityto-entity relations in the restaurant domain), and the original release of the WebNLG dataset for the 2017 challenge (Shimorina et al., 2018).", "mentionContextAttributes": {"used": {"value": true, "score": 0.8702796101570129}, "created": {"value": false, "score": 3.695487976074219e-05}, "shared": {"value": false, "score": 1.5497207641601562e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999591112136841}, "created": {"value": false, "score": 0.490145742893219}, "shared": {"value": false, "score": 2.5033950805664062e-06}}, "references": [{"label": "(Gardent et al., 2017)", "normalizedForm": "Gardent et al., 2017", "refKey": 17}]}, {"type": "software", "software-type": "software", "software-name": {"rawForm": "FactSpotter", "normalizedForm": "FactSpotter", "offsetStart": 325, "offsetEnd": 336}, "context": "(1 -P f act j (y <i-1 )) log P f act j (y <i ) + log(P (y i |y <i , x)) (1) where: i) P f (y i |y <i , x) is the probability of generating token y i given the factual classifier; ii) P f act j (y <i-1 ) is the probability of correctly representing the fact j in the previously generated tokens y 0 , ..., y i-1 , computed by FactSpotter.", "mentionContextAttributes": {"used": {"value": true, "score": 0.9978931546211243}, "created": {"value": false, "score": 3.5762786865234375e-06}, "shared": {"value": false, "score": 4.887580871582031e-06}}, "documentContextAttributes": {"used": {"value": true, "score": 0.9999855756759644}, "created": {"value": true, "score": 0.9998867511749268}, "shared": {"value": false, "score": 4.887580871582031e-06}}}], "references": [{"refKey": 17, "tei": "<biblStruct xml:id=\"b17\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Creating Training Corpora for NLG Micro-Planners</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Claire</forename><surname>Gardent</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Anastasia</forename><surname>Shimorina</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Shashi</forename><surname>Narayan</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Laura</forename><surname>Perez-Beltrachini</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.18653/v1/p17-1017</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>\n\t\t<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</meeting>\n\t\t<imprint>\n\t\t\t<publisher>Association for Computational Linguistics</publisher>\n\t\t\t<date type=\"published\" when=\"2017\">2017</date>\n\t\t\t<biblScope unit=\"volume\">1</biblScope>\n\t\t\t<biblScope unit=\"page\">188</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 5, "tei": "<biblStruct xml:id=\"b5\">\n\t<monogr>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Antoine</forename><surname>Bordes</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Nicolas</forename><surname>Usunier</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Sumit</forename><surname>Chopra</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jason</forename><surname>Weston</surname></persName>\n\t\t</author>\n\t\t<idno>arXiv:1506.02075</idno>\n\t\t<title level=\"m\">Large-scale simple question answering with memory networks</title>\n\t\t<imprint>\n\t\t\t<date>2015</date>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}, {"refKey": 4, "tei": "<biblStruct xml:id=\"b4\">\n\t<analytic>\n\t\t<title level=\"a\" type=\"main\">Freebase</title>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Kurt</forename><surname>Bollacker</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Colin</forename><surname>Evans</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Praveen</forename><surname>Paritosh</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Tim</forename><surname>Sturge</surname></persName>\n\t\t</author>\n\t\t<author>\n\t\t\t<persName><forename type=\"first\">Jamie</forename><surname>Taylor</surname></persName>\n\t\t</author>\n\t\t<idno type=\"DOI\">10.1145/1376616.1376746</idno>\n\t</analytic>\n\t<monogr>\n\t\t<title level=\"m\">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>\n\t\t<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>\n\t\t<imprint>\n\t\t\t<publisher>ACM</publisher>\n\t\t\t<date type=\"published\" when=\"2008-06-09\">2008</date>\n\t\t\t<biblScope unit=\"page\">1250</biblScope>\n\t\t</imprint>\n\t</monogr>\n</biblStruct>\n"}], "runtime": 13706, "id": "dc3c1d2a2bcc63f361bf7563912a59b52dbe1260", "metadata": {"id": "dc3c1d2a2bcc63f361bf7563912a59b52dbe1260"}, "original_file_path": "../../datalake/Samuel/SOFTware-Sync/downloads/xml/hal-04257838.grobid.tei.xml", "file_name": "hal-04257838.grobid.tei.xml"}