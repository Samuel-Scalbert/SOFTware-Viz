<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-04264050</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
        </availability>
        <date when="2024-09-30T02:11:51+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">From Text to Source: Results in Detecting Large Language Model-Generated Content</title>
            <author role="aut">
              <persName>
                <forename type="first">Wissam</forename>
                <surname>Antoun</surname>
              </persName>
              <email type="md5">63950a3b5625439fa32a52b29ff4f0b2</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">wissam-antoun</idno>
              <idno type="idhal" notation="numeric">1214021</idno>
              <idno type="halauthorid" notation="string">2691933-1214021</idno>
              <idno type="ARXIV">https://arxiv.org/a/antoun_w_1</idno>
              <idno type="GOOGLE SCHOLAR">fEgsyU4AAAAJ</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-8021-5834</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Djamé</forename>
                <surname>Seddah</surname>
              </persName>
              <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
              <email type="domain">paris-sorbonne.fr</email>
              <idno type="idhal" notation="string">djameseddah</idno>
              <idno type="idhal" notation="numeric">11545</idno>
              <idno type="halauthorid" notation="string">1878-11545</idno>
              <idno type="IDREF">https://www.idref.fr/086185136</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Benoît</forename>
                <surname>Sagot</surname>
              </persName>
              <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">bsagot</idno>
              <idno type="idhal" notation="numeric">1461</idno>
              <idno type="halauthorid" notation="string">17075-1461</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/177454229</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Wissam</forename>
                <surname>Antoun</surname>
              </persName>
              <email type="md5">63950a3b5625439fa32a52b29ff4f0b2</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projanr-50388"/>
            <funder ref="#projeurop-716888"/>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2024-03-27 12:12:01</date>
              <date type="whenModified">2024-07-01 17:19:01</date>
              <date type="whenReleased">2024-03-27 13:34:49</date>
              <date type="whenProduced">2024-05-20</date>
              <date type="whenEndEmbargoed">2024-03-27</date>
              <ref type="file" target="https://inria.hal.science/hal-04264050v1/document">
                <date notBefore="2024-03-27"/>
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-04264050v1/file/jqjkvxpwgxhvpqdrgmkzhnygcyyxnqfx.pdf">
                <date notBefore="2024-03-27"/>
              </ref>
              <ref type="externalLink" target="http://arxiv.org/pdf/2309.13322"/>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="1372417">
                <persName>
                  <forename>Wissam</forename>
                  <surname>Antoun</surname>
                </persName>
                <email type="md5">63950a3b5625439fa32a52b29ff4f0b2</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-04264050</idno>
            <idno type="halUri">https://inria.hal.science/hal-04264050</idno>
            <idno type="halBibtex">antoun:hal-04264050</idno>
            <idno type="halRefHtml">&lt;i&gt;The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)&lt;/i&gt;, May 2024, Torino, Italy</idno>
            <idno type="halRef">The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), May 2024, Torino, Italy</idno>
            <availability status="restricted">
              <licence target="http://creativecommons.org/licenses/by/">Attribution</licence>
            </availability>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-ROCQ">INRIA Paris - Rocquencourt</idno>
            <idno type="stamp" n="OPENAIRE">OpenAIRE</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="PNRIA">Programme National de Recherche en IA</idno>
            <idno type="stamp" n="ANR">ANR</idno>
            <idno type="stamp" n="PRAIRIE-IA">PaRis AI Research InstitutE</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">From Text to Source: Results in Detecting Large Language Model-Generated Content</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Wissam</forename>
                    <surname>Antoun</surname>
                  </persName>
                  <email type="md5">63950a3b5625439fa32a52b29ff4f0b2</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">wissam-antoun</idno>
                  <idno type="idhal" notation="numeric">1214021</idno>
                  <idno type="halauthorid" notation="string">2691933-1214021</idno>
                  <idno type="ARXIV">https://arxiv.org/a/antoun_w_1</idno>
                  <idno type="GOOGLE SCHOLAR">fEgsyU4AAAAJ</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-8021-5834</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Djamé</forename>
                    <surname>Seddah</surname>
                  </persName>
                  <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
                  <email type="domain">paris-sorbonne.fr</email>
                  <idno type="idhal" notation="string">djameseddah</idno>
                  <idno type="idhal" notation="numeric">11545</idno>
                  <idno type="halauthorid" notation="string">1878-11545</idno>
                  <idno type="IDREF">https://www.idref.fr/086185136</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Benoît</forename>
                    <surname>Sagot</surname>
                  </persName>
                  <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">bsagot</idno>
                  <idno type="idhal" notation="numeric">1461</idno>
                  <idno type="halauthorid" notation="string">17075-1461</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/177454229</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
              </analytic>
              <monogr>
                <title level="m">The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) - Main Conference Proceedings</title>
                <meeting>
                  <title>The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</title>
                  <date type="start">2024-05-20</date>
                  <date type="end">2024-05-25</date>
                  <settlement>Torino</settlement>
                  <country key="IT">Italy</country>
                </meeting>
                <imprint>
                  <date type="datePub">2023-09-23</date>
                </imprint>
              </monogr>
              <idno type="arxiv">2309.13322</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-cl">Computer Science [cs]/Computation and Language [cs.CL]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>The widespread use of Large Language Models (LLMs), celebrated for their ability to generate human-like text, has raised concerns about misinformation and ethical implications. Addressing these concerns necessitates the development of robust methods to detect and attribute text generated by LLMs. This paper investigates "Cross-Model Detection," by evaluating whether a classifier trained to distinguish between source LLM-generated and human-written text can also detect text from a target LLM without further training. The study comprehensively explores various LLM sizes and families, and assesses the impact of conversational fine-tuning techniques, quantization, and watermarking on classifier generalization. The research also explores Model Attribution, encompassing source model identification, model family, and model size classification, in addition to quantization and watermarking detection. Our results reveal several key findings: a clear inverse relationship between classifier effectiveness and model size, with larger LLMs being more challenging to detect, especially when the classifier is trained on data from smaller models. Training on data from similarly sized LLMs can improve detection performance from larger models but may lead to decreased performance when dealing with smaller models. Additionally, model attribution experiments show promising results in identifying source models and model families, highlighting detectable signatures in LLM-generated text, with particularly remarkable outcomes in watermarking detection, while no detectable signatures of quantization were observed. Overall, our study contributes valuable insights into the interplay of model size, family, and training data in LLM detection and attribution.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-482775" status="VALID">
          <idno type="RNSR">201722248N</idno>
          <orgName>Automatic Language Modelling and ANAlysis &amp; Computational Humanities</orgName>
          <orgName type="acronym">ALMAnaCH</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.inria.fr/equipes/almanach</ref>
          </desc>
          <listRelation>
            <relation active="#struct-454310" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-454310" status="VALID">
          <idno type="IdRef">241614864</idno>
          <idno type="RNSR">196718247G</idno>
          <orgName>Inria de Paris</orgName>
          <date type="start">2016-03-10</date>
          <desc>
            <address>
              <addrLine>2 rue Simone Iff -CS 42112 -75589 Paris Cedex 12</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/centre/paris</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-50388" status="VALID">
          <idno type="anr">ANR-19-P3IA-0001</idno>
          <orgName>PRAIRIE</orgName>
          <desc>PaRis Artificial Intelligence Research InstitutE</desc>
          <date type="start">2019</date>
        </org>
        <org type="europeanProject" xml:id="projeurop-716888" status="INCOMING">
          <idno type="number">101021607</idno>
          <orgName>Counter</orgName>
          <desc>Privacy-First Situational Awareness Platform for Violent Terrorism and Crime Prediction, Counter Radicalisation and Citizen Protection</desc>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>