<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of lirmm-02010805</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-10-06T23:05:38+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">CountNet: Estimating the Number of Concurrent Speakers Using Supervised Learning</title>
            <author role="aut">
              <persName>
                <forename type="first">Fabian-Robert</forename>
                <surname>Stöter</surname>
              </persName>
              <email type="md5">0b5439c577746a8b9c9ffb7988b31746</email>
              <email type="domain">lirmm.fr</email>
              <idno type="idhal" notation="string">fabian-robert-stoter</idno>
              <idno type="idhal" notation="numeric">741450</idno>
              <idno type="halauthorid" notation="string">46051-741450</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=7HsSdqwAAAAJ&amp;hl=en</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-2534-1165</idno>
              <affiliation ref="#struct-141072"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Soumitro</forename>
                <surname>Chakrabarty</surname>
              </persName>
              <idno type="halauthorid">1518087-0</idno>
              <affiliation ref="#struct-444601"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Bernd</forename>
                <surname>Edler</surname>
              </persName>
              <idno type="halauthorid">977732-0</idno>
              <affiliation ref="#struct-444601"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Emanuël</forename>
                <forename type="middle">A. P.</forename>
                <surname>Habets</surname>
              </persName>
              <email type="md5">273709fe912df00c4245088be4dda0d6</email>
              <email type="domain">audiolabs-erlangen.de</email>
              <idno type="idhal" notation="numeric">938660</idno>
              <idno type="halauthorid" notation="string">700405-938660</idno>
              <affiliation ref="#struct-444601"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Isabelle</forename>
                <surname>Gouat</surname>
              </persName>
              <email type="md5">01a8910ec35817770bca127295d8d38a</email>
              <email type="domain">lirmm.fr</email>
            </editor>
            <funder>The authors gratefully acknowledge the compute resources and support provided by the Erlangen Regional Computing Center (RRZE). They would like to thank A. Liutkus for his constructive criticism of the paper.</funder>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2020-03-02 19:37:14</date>
              <date type="whenModified">2024-04-15 11:18:12</date>
              <date type="whenReleased">2020-03-03 12:54:49</date>
              <date type="whenProduced">2019-02</date>
              <date type="whenEndEmbargoed">2020-03-02</date>
              <ref type="file" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-02010805v1/document">
                <date notBefore="2020-03-02"/>
              </ref>
              <ref type="file" subtype="author" n="1" target="https://hal-lirmm.ccsd.cnrs.fr/lirmm-02010805v1/file/stoeter_sourcecount_arxiv.pdf">
                <date notBefore="2020-03-02"/>
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="102079">
                <persName>
                  <forename>Isabelle</forename>
                  <surname>Gouat</surname>
                </persName>
                <email type="md5">01a8910ec35817770bca127295d8d38a</email>
                <email type="domain">lirmm.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">lirmm-02010805</idno>
            <idno type="halUri">https://hal-lirmm.ccsd.cnrs.fr/lirmm-02010805</idno>
            <idno type="halBibtex">stoter:lirmm-02010805</idno>
            <idno type="halRefHtml">&lt;i&gt;IEEE/ACM Transactions on Audio, Speech and Language Processing&lt;/i&gt;, 2019, IEEE/ACM Transactions on Audio, Speech, and Language Processing, 27 (2), pp.268-282. &lt;a target="_blank" href="https://dx.doi.org/10.1109/TASLP.2018.2877892"&gt;&amp;#x27E8;10.1109/TASLP.2018.2877892&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">IEEE/ACM Transactions on Audio, Speech and Language Processing, 2019, IEEE/ACM Transactions on Audio, Speech, and Language Processing, 27 (2), pp.268-282. &amp;#x27E8;10.1109/TASLP.2018.2877892&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-SOPHIA">INRIA Sophia Antipolis - Méditerranée</idno>
            <idno type="stamp" n="INRIASO">INRIA-SOPHIA</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA34">Montpellier</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="ZENITH" corresp="LIRMM">Scientific Data Management</idno>
            <idno type="stamp" n="LIRMM">Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="MIPS">Mathématiques, Informatique, Physique et Systèmes</idno>
            <idno type="stamp" n="UNIV-MONTPELLIER">Université de Montpellier</idno>
            <idno type="stamp" n="UM-2015-2021" corresp="UNIV-MONTPELLIER">Université de Montpellier (2015-2021)</idno>
            <idno type="stamp" n="INRIAARTDOI">INRIAARTDOI</idno>
            <idno type="stamp" n="INRIA-ALLEMAGNE">INRIA-ALLEMAGNE</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">CountNet: Estimating the Number of Concurrent Speakers Using Supervised Learning</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Fabian-Robert</forename>
                    <surname>Stöter</surname>
                  </persName>
                  <email type="md5">0b5439c577746a8b9c9ffb7988b31746</email>
                  <email type="domain">lirmm.fr</email>
                  <idno type="idhal" notation="string">fabian-robert-stoter</idno>
                  <idno type="idhal" notation="numeric">741450</idno>
                  <idno type="halauthorid" notation="string">46051-741450</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=7HsSdqwAAAAJ&amp;hl=en</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-2534-1165</idno>
                  <affiliation ref="#struct-141072"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Soumitro</forename>
                    <surname>Chakrabarty</surname>
                  </persName>
                  <idno type="halauthorid">1518087-0</idno>
                  <affiliation ref="#struct-444601"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Bernd</forename>
                    <surname>Edler</surname>
                  </persName>
                  <idno type="halauthorid">977732-0</idno>
                  <affiliation ref="#struct-444601"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Emanuël</forename>
                    <forename type="middle">A. P.</forename>
                    <surname>Habets</surname>
                  </persName>
                  <email type="md5">273709fe912df00c4245088be4dda0d6</email>
                  <email type="domain">audiolabs-erlangen.de</email>
                  <idno type="idhal" notation="numeric">938660</idno>
                  <idno type="halauthorid" notation="string">700405-938660</idno>
                  <affiliation ref="#struct-444601"/>
                </author>
              </analytic>
              <monogr>
                <idno type="halJournalId" status="VALID">95999</idno>
                <idno type="issn">2329-9290</idno>
                <idno type="eissn">2329-9304</idno>
                <title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing</title>
                <imprint>
                  <publisher>Institute of Electrical and Electronics Engineers</publisher>
                  <biblScope unit="serie">IEEE/ACM Transactions on Audio, Speech, and Language Processing</biblScope>
                  <biblScope unit="volume">27</biblScope>
                  <biblScope unit="issue">2</biblScope>
                  <biblScope unit="pp">268-282</biblScope>
                  <date type="datePub">2019-02</date>
                </imprint>
              </monogr>
              <idno type="doi">10.1109/TASLP.2018.2877892</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">cocktail-party.</term>
                <term xml:lang="en">overlap detection</term>
                <term xml:lang="en">number of concurrent speakers</term>
                <term xml:lang="en">Speaker count estimation</term>
              </keywords>
              <classCode scheme="halDomain" n="math.math-lo">Mathematics [math]/Logic [math.LO]</classCode>
              <classCode scheme="halTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halOldTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halTreeTypology" n="ART">Journal articles</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Estimating the maximum number of concurrent speakers from single-channel mixtures is a challenging problem and an essential first step to address various audio-based tasks such as blind source separation, speaker diarization, and audio surveillance. We propose a unifying probabilistic paradigm, where deep neural network architectures are used to infer output posterior distributions. These probabilities are in turn processed to yield discrete point estimates. Designing such architectures often involves two important and complementary aspects that we investigate and discuss. First, we study how recent advances in deep architectures may be exploited for the task of speaker count estimation. In particular, we show that convolutional recurrent neural networks outperform recurrent networks used in a previous study when adequate input features are used. Even for short segments of speech mixtures, we can estimate up to five speakers, with a significantly lower error than other methods. Second, through comprehensive evaluation, we compare the best-performing method to several baselines, as well as the influence of gain variations, different data sets, and reverberation. The output of our proposed method is compared to human performance. Finally, we give insights into the strategy used by our proposed method.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-141072" status="OLD">
          <idno type="RNSR">201121208J</idno>
          <orgName>Scientific Data Management</orgName>
          <orgName type="acronym">ZENITH</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>LIRMM, 161 rue Ada, 34000 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">https://team.inria.fr/zenith/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-181" type="direct"/>
            <relation name="UMR5506" active="#struct-410122" type="indirect"/>
            <relation name="UMR5506" active="#struct-441569" type="indirect"/>
            <relation active="#struct-34586" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-444601" status="VALID">
          <orgName>International Audio Laboratories Erlangen</orgName>
          <orgName type="acronym">AUDIO LABS</orgName>
          <desc>
            <address>
              <addrLine>International Audio Laboratories Erlangen Am Wolfsmantel 33, 91058 Erlangen</addrLine>
              <country key="DE"/>
            </address>
            <ref type="url">https://www.audiolabs-erlangen.de/home</ref>
          </desc>
          <listRelation>
            <relation active="#struct-311714" type="direct"/>
            <relation active="#struct-569680" type="direct"/>
            <relation active="#struct-330453" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-181" status="OLD">
          <idno type="IdRef">139590827</idno>
          <idno type="ISNI">0000000405990488</idno>
          <idno type="RNSR">199111950H</idno>
          <idno type="ROR">https://ror.org/013yean28</idno>
          <orgName>Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier</orgName>
          <orgName type="acronym">LIRMM</orgName>
          <date type="start">1995-01-01</date>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>161 rue Ada - 34095 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.lirmm.fr</ref>
          </desc>
          <listRelation>
            <relation name="UMR5506" active="#struct-410122" type="direct"/>
            <relation name="UMR5506" active="#struct-441569" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-410122" status="OLD">
          <idno type="ISNI">0000000120970141</idno>
          <idno type="ROR">https://ror.org/051escj72</idno>
          <orgName>Université de Montpellier</orgName>
          <orgName type="acronym">UM</orgName>
          <date type="end">2021-12-31</date>
          <desc>
            <address>
              <addrLine>163 rue Auguste Broussonnet - 34090 Montpellier</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.umontpellier.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-34586" status="VALID">
          <idno type="RNSR">198318250R</idno>
          <idno type="ROR">https://ror.org/01nzkaw91</idno>
          <orgName>Inria Sophia Antipolis - Méditerranée</orgName>
          <orgName type="acronym">CRISAM</orgName>
          <desc>
            <address>
              <addrLine>2004 route des Lucioles BP 93 06902 Sophia Antipolis</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/centre/sophia/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-311714" status="VALID">
          <idno type="ROR">https://ror.org/00f7hpc57</idno>
          <orgName>Friedrich-Alexander Universität Erlangen-Nürnberg = University of Erlangen-Nuremberg</orgName>
          <orgName type="acronym">FAU</orgName>
          <desc>
            <address>
              <addrLine>Schlossplatz 4, 91054 Erlangen, Germany</addrLine>
              <country key="DE"/>
            </address>
            <ref type="url">http://www.fau.eu/</ref>
          </desc>
        </org>
        <org type="institution" xml:id="struct-569680" status="VALID">
          <idno type="ROR">https://ror.org/024ape423</idno>
          <orgName>Fraunhofer Institute for Integrated Circuits</orgName>
          <orgName type="acronym">Fraunhofer IIS</orgName>
          <desc>
            <address>
              <addrLine>Am Wolfsmantel 33, 91058 Erlangen</addrLine>
              <country key="DE"/>
            </address>
            <ref type="url">https://www.iis.fraunhofer.de/en.html</ref>
          </desc>
          <listRelation>
            <relation active="#struct-330453" type="direct"/>
          </listRelation>
        </org>
        <org type="regroupinstitution" xml:id="struct-330453" status="VALID">
          <idno type="ISNI">0000 0000 9261 3939</idno>
          <idno type="ROR">https://ror.org/05hkkdn48</idno>
          <orgName>Fraunhofer</orgName>
          <orgName type="acronym">Fraunhofer-Gesellschaft</orgName>
          <desc>
            <address>
              <addrLine>Hansastraße 27c, 80686 München</addrLine>
              <country key="DE"/>
            </address>
            <ref type="url">https://www.fraunhofer.de/en.html</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>