<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03204193</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-10-07T15:24:39+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Learning emotions latent representation with CVAE for Text-Driven Expressive AudioVisual Speech Synthesis</title>
            <author role="aut">
              <persName>
                <forename type="first">Sara</forename>
                <surname>Dahmani</surname>
              </persName>
              <idno type="halauthorid">1058570-0</idno>
              <affiliation ref="#struct-420403"/>
              <affiliation ref="#struct-206040"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Vincent</forename>
                <surname>Colotte</surname>
              </persName>
              <email type="md5">ab816571e53968bf183455695681dcf9</email>
              <email type="domain">loria.fr</email>
              <idno type="idhal" notation="string">vincent-colotte</idno>
              <idno type="idhal" notation="numeric">16268</idno>
              <idno type="halauthorid" notation="string">20214-16268</idno>
              <idno type="IDREF">https://www.idref.fr/070401683</idno>
              <idno type="ORCID">https://orcid.org/0009-0000-5040-6971</idno>
              <orgName ref="#struct-413289"/>
              <affiliation ref="#struct-420403"/>
              <affiliation ref="#struct-206040"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Valérian</forename>
                <surname>Girard</surname>
              </persName>
              <idno type="halauthorid">1615146-0</idno>
              <affiliation ref="#struct-420403"/>
              <affiliation ref="#struct-206040"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Slim</forename>
                <surname>Ouni</surname>
              </persName>
              <email type="md5">1517367d1493022adbd79f7094e9d1b4</email>
              <email type="domain">loria.fr</email>
              <idno type="idhal" notation="string">slim-ouni</idno>
              <idno type="idhal" notation="numeric">1158</idno>
              <idno type="halauthorid" notation="string">3421-1158</idno>
              <idno type="ORCID">https://orcid.org/0000-0001-5286-7368</idno>
              <orgName ref="#struct-300292"/>
              <affiliation ref="#struct-420403"/>
              <affiliation ref="#struct-206040"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Slim</forename>
                <surname>Ouni</surname>
              </persName>
              <email type="md5">1517367d1493022adbd79f7094e9d1b4</email>
              <email type="domain">loria.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2021-04-21 13:24:10</date>
              <date type="whenModified">2024-04-24 15:01:07</date>
              <date type="whenReleased">2021-04-21 13:32:21</date>
              <date type="whenProduced">2021</date>
              <date type="whenEndEmbargoed">2021-04-21</date>
              <ref type="file" target="https://inria.hal.science/hal-03204193v1/document">
                <date notBefore="2021-04-21"/>
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-03204193v1/file/neural_networks_journal-8.pdf">
                <date notBefore="2021-04-21"/>
              </ref>
              <ref type="externalLink" target="https://hal.inria.fr/hal-03204193/file/neural_networks_journal-8.pdf"/>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="102504">
                <persName>
                  <forename>Slim</forename>
                  <surname>Ouni</surname>
                </persName>
                <email type="md5">1517367d1493022adbd79f7094e9d1b4</email>
                <email type="domain">loria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03204193</idno>
            <idno type="halUri">https://inria.hal.science/hal-03204193</idno>
            <idno type="halBibtex">dahmani:hal-03204193</idno>
            <idno type="halRefHtml">&lt;i&gt;Neural Networks&lt;/i&gt;, 2021, 141, pp.315-329. &lt;a target="_blank" href="https://dx.doi.org/10.1016/j.neunet.2021.04.021"&gt;&amp;#x27E8;10.1016/j.neunet.2021.04.021&amp;#x27E9;&lt;/a&gt;</idno>
            <idno type="halRef">Neural Networks, 2021, 141, pp.315-329. &amp;#x27E8;10.1016/j.neunet.2021.04.021&amp;#x27E9;</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="SHS">Sciences de l'Homme et de la Société</idno>
            <idno type="stamp" n="CNRS">CNRS - Centre national de la recherche scientifique</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="AO-LINGUISTIQUE">Archives ouvertes de la Linguistique</idno>
            <idno type="stamp" n="INRIA_TEST">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-LORRAINE">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="LORIA2">Publications du LORIA</idno>
            <idno type="stamp" n="INRIA-NANCY-GRAND-EST">INRIA Nancy - Grand Est</idno>
            <idno type="stamp" n="GRID5000" corresp="SILECS">Grid'5000</idno>
            <idno type="stamp" n="GIP-BE">GIP Bretagne Environnement</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="UNIV-LORRAINE">Université de Lorraine</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="LORIA">Laboratoire Lorrain de Recherche en Informatique et ses Applications</idno>
            <idno type="stamp" n="LORIA-NLPKD" corresp="LORIA">Department of Natural Language Processing &amp; Knowledge Discovery</idno>
            <idno type="stamp" n="SILECS">Publications from users of the SILECS research infrastructure</idno>
            <idno type="stamp" n="CREATIV-LAB">Creativ'Lab</idno>
            <idno type="stamp" n="INRIAARTDOI">INRIAARTDOI</idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Learning emotions latent representation with CVAE for Text-Driven Expressive AudioVisual Speech Synthesis</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Sara</forename>
                    <surname>Dahmani</surname>
                  </persName>
                  <idno type="halauthorid">1058570-0</idno>
                  <affiliation ref="#struct-420403"/>
                  <affiliation ref="#struct-206040"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Vincent</forename>
                    <surname>Colotte</surname>
                  </persName>
                  <email type="md5">ab816571e53968bf183455695681dcf9</email>
                  <email type="domain">loria.fr</email>
                  <idno type="idhal" notation="string">vincent-colotte</idno>
                  <idno type="idhal" notation="numeric">16268</idno>
                  <idno type="halauthorid" notation="string">20214-16268</idno>
                  <idno type="IDREF">https://www.idref.fr/070401683</idno>
                  <idno type="ORCID">https://orcid.org/0009-0000-5040-6971</idno>
                  <orgName ref="#struct-413289"/>
                  <affiliation ref="#struct-420403"/>
                  <affiliation ref="#struct-206040"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Valérian</forename>
                    <surname>Girard</surname>
                  </persName>
                  <idno type="halauthorid">1615146-0</idno>
                  <affiliation ref="#struct-420403"/>
                  <affiliation ref="#struct-206040"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Slim</forename>
                    <surname>Ouni</surname>
                  </persName>
                  <email type="md5">1517367d1493022adbd79f7094e9d1b4</email>
                  <email type="domain">loria.fr</email>
                  <idno type="idhal" notation="string">slim-ouni</idno>
                  <idno type="idhal" notation="numeric">1158</idno>
                  <idno type="halauthorid" notation="string">3421-1158</idno>
                  <idno type="ORCID">https://orcid.org/0000-0001-5286-7368</idno>
                  <orgName ref="#struct-300292"/>
                  <affiliation ref="#struct-420403"/>
                  <affiliation ref="#struct-206040"/>
                </author>
              </analytic>
              <monogr>
                <idno type="halJournalId" status="VALID">7360</idno>
                <idno type="issn">0893-6080</idno>
                <title level="j">Neural Networks</title>
                <imprint>
                  <publisher>Elsevier</publisher>
                  <biblScope unit="volume">141</biblScope>
                  <biblScope unit="pp">315-329</biblScope>
                  <date type="datePub">2021</date>
                  <date type="dateEpub">2021-04-21</date>
                </imprint>
              </monogr>
              <idno type="doi">10.1016/j.neunet.2021.04.021</idno>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="en">Expressive audiovisual speech synthesis</term>
                <term xml:lang="en">conditional variationalauto-encoder</term>
                <term xml:lang="en">Expressive talking avatar</term>
                <term xml:lang="en">emotion</term>
                <term xml:lang="en">facial expression</term>
                <term xml:lang="en">deeplearning</term>
                <term xml:lang="en">bidirectional long short-term memory (BLSTM)</term>
              </keywords>
              <classCode scheme="halDomain" n="sdv.ot">Life Sciences [q-bio]/Other [q-bio.OT]</classCode>
              <classCode scheme="halDomain" n="shs.info">Humanities and Social Sciences/Library and information sciences</classCode>
              <classCode scheme="halDomain" n="shs.langue">Humanities and Social Sciences/Linguistics</classCode>
              <classCode scheme="halDomain" n="spi.signal">Engineering Sciences [physics]/Signal and Image processing</classCode>
              <classCode scheme="halDomain" n="stat.ml">Statistics [stat]/Machine Learning [stat.ML]</classCode>
              <classCode scheme="halDomain" n="scco.comp">Cognitive science/Computer science</classCode>
              <classCode scheme="halDomain" n="scco.ling">Cognitive science/Linguistics</classCode>
              <classCode scheme="halDomain" n="math.math-mg">Mathematics [math]/Metric Geometry [math.MG]</classCode>
              <classCode scheme="halTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halOldTypology" n="ART">Journal articles</classCode>
              <classCode scheme="halTreeTypology" n="ART">Journal articles</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Great improvement has been made in the field of expressive audiovisual Text-to-Speech synthesis (EAVTTS) thanks to deep learning techniques. However, generating realistic speech is still an open issue and researchers in this area have been focusing lately on controlling the speech variability.In this paper, we use different neural architectures to synthesize emotional speech. We study the application of unsupervised learning techniques for emotional speech modeling as well as methods for restructuring emotions representation to make it continuous and more flexible. This manipulation of the emotional representation should allow us to generate new styles of speech by mixing emotions. We first present our expressive audiovisual corpus. We validate the emotional content of this corpus with three perceptual experiments using acoustic only, visual only and audiovisual stimuli.After that, we analyze the performance of a fully connected neural network in learning characteristics specific to different emotions for the phone duration aspect and the acoustic and visual modalities.We also study the contribution of a joint and separate training of the acoustic and visual modalities in the quality of the generated synthetic speech.In the second part of this paper, we use a conditional variational auto-encoder (CVAE) architecture to learn a latent representation of emotions. We applied this method in an unsupervised manner to generate features of expressive speech. We used a probabilistic metric to compute the overlapping degree between emotions latent clusters to choose the best parameters for the CVAE. By manipulating the latent vectors, we were able to generate nuances of a given emotion and to generate new emotions that do not exist in our database. For these new emotions, we obtain a coherent articulation. We conducted four perceptual experiments to evaluate our findings.</p>
            </abstract>
            <particDesc>
              <org type="consortium">Grid'5000</org>
            </particDesc>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-420403" status="VALID">
          <idno type="RNSR">201421147E</idno>
          <orgName>Speech Modeling for Facilitating Oral-Based Communication</orgName>
          <orgName type="acronym">MULTISPEECH</orgName>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/equipes/multispeech</ref>
          </desc>
          <listRelation>
            <relation active="#struct-129671" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
            <relation active="#struct-423086" type="direct"/>
            <relation active="#struct-206040" type="indirect"/>
            <relation active="#struct-413289" type="indirect"/>
            <relation name="UMR7503" active="#struct-441569" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-206040" status="VALID">
          <idno type="IdRef">067077927</idno>
          <idno type="ISNI">0000000121795429</idno>
          <idno type="RNSR">198912571S</idno>
          <idno type="IdUnivLorraine">[UL]RSI--</idno>
          <idno type="ROR">https://ror.org/02vnf0c38</idno>
          <orgName>Laboratoire Lorrain de Recherche en Informatique et ses Applications</orgName>
          <orgName type="acronym">LORIA</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>Campus Scientifique BP 239 54506 Vandoeuvre-lès-Nancy Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.loria.fr</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
            <relation active="#struct-413289" type="direct"/>
            <relation name="UMR7503" active="#struct-441569" type="direct"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-129671" status="VALID">
          <idno type="RNSR">198618246Y</idno>
          <idno type="ROR">https://ror.org/03fcjvn64</idno>
          <orgName>Inria Nancy - Grand Est</orgName>
          <desc>
            <address>
              <addrLine>615 rue du Jardin Botanique 54600 Villers-lès-Nancy</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/nancy</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
        <org type="department" xml:id="struct-423086" status="VALID">
          <orgName>Department of Natural Language Processing &amp; Knowledge Discovery</orgName>
          <orgName type="acronym">LORIA - NLPKD</orgName>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.loria.fr/en/research/departments/natural-language-processing-and-knowledge-discovery/</ref>
          </desc>
          <listRelation>
            <relation active="#struct-206040" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
            <relation active="#struct-413289" type="indirect"/>
            <relation name="UMR7503" active="#struct-441569" type="indirect"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-413289" status="VALID">
          <idno type="IdRef">157040569</idno>
          <idno type="IdUnivLorraine">[UL]100--</idno>
          <idno type="ROR">https://ror.org/04vfs2w97</idno>
          <orgName>Université de Lorraine</orgName>
          <orgName type="acronym">UL</orgName>
          <date type="start">2012-01-01</date>
          <desc>
            <address>
              <addrLine>34 cours Léopold - CS 25233 - 54052 Nancy cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.univ-lorraine.fr/</ref>
          </desc>
        </org>
        <org type="regroupinstitution" xml:id="struct-441569" status="VALID">
          <idno type="IdRef">02636817X</idno>
          <idno type="ISNI">0000000122597504</idno>
          <idno type="ROR">https://ror.org/02feahw73</idno>
          <orgName>Centre National de la Recherche Scientifique</orgName>
          <orgName type="acronym">CNRS</orgName>
          <date type="start">1939-10-19</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.cnrs.fr/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>