<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-02294316</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-10-05T19:21:58+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">Enhancing BERT for Lexical Normalization</title>
            <author role="aut">
              <persName>
                <forename type="first">Benjamin</forename>
                <surname>Muller</surname>
              </persName>
              <idno type="halauthorid">1163840-0</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Benoît</forename>
                <surname>Sagot</surname>
              </persName>
              <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">bsagot</idno>
              <idno type="idhal" notation="numeric">1461</idno>
              <idno type="halauthorid" notation="string">17075-1461</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/177454229</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
              <orgName ref="#struct-300009"/>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Djamé</forename>
                <surname>Seddah</surname>
              </persName>
              <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
              <email type="domain">paris-sorbonne.fr</email>
              <idno type="idhal" notation="string">djameseddah</idno>
              <idno type="idhal" notation="numeric">11545</idno>
              <idno type="halauthorid" notation="string">1878-11545</idno>
              <idno type="IDREF">https://www.idref.fr/086185136</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Benoît</forename>
                <surname>Sagot</surname>
              </persName>
              <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
              <email type="domain">inria.fr</email>
            </editor>
            <funder ref="#projanr-44644"/>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2019-09-30 18:33:53</date>
              <date type="whenModified">2024-06-15 03:17:29</date>
              <date type="whenReleased">2019-10-01 08:33:33</date>
              <date type="whenProduced">2019-11-04</date>
              <date type="whenEndEmbargoed">2019-09-30</date>
              <ref type="file" target="https://inria.hal.science/hal-02294316v1/document">
                <date notBefore="2019-09-30"/>
              </ref>
              <ref type="file" subtype="author" n="1" target="https://inria.hal.science/hal-02294316v1/file/Enhancing_BERT_for_lexical_normalisation_WNUT2019_proceeding-5.pdf">
                <date notBefore="2019-09-30"/>
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="108708">
                <persName>
                  <forename>Benoît</forename>
                  <surname>Sagot</surname>
                </persName>
                <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
                <email type="domain">inria.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-02294316</idno>
            <idno type="halUri">https://inria.hal.science/hal-02294316</idno>
            <idno type="halBibtex">muller:hal-02294316</idno>
            <idno type="halRefHtml">&lt;i&gt;The 5th Workshop on Noisy User-generated Text (W-NUT)&lt;/i&gt;, Nov 2019, Hong Kong, China</idno>
            <idno type="halRef">The 5th Workshop on Noisy User-generated Text (W-NUT), Nov 2019, Hong Kong, China</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="UNIV-RENNES1">Université de Rennes 1</idno>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-ROCQ">INRIA Paris - Rocquencourt</idno>
            <idno type="stamp" n="IRISA">Irisa</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="UR1-HAL">Publications labos UR1 dans HAL-Rennes 1</idno>
            <idno type="stamp" n="UR1-MATH-STIC">UR1 - publications Maths-STIC</idno>
            <idno type="stamp" n="UR1-UFR-ISTIC">UFR ISTIC Informatique et électronique</idno>
            <idno type="stamp" n="TEST-UR-CSS">TEST Université de Rennes CSS</idno>
            <idno type="stamp" n="UNIV-RENNES">Université de Rennes</idno>
            <idno type="stamp" n="INRIA-300009">Inria 300009</idno>
            <idno type="stamp" n="ANR">ANR</idno>
            <idno type="stamp" n="UR1-MATH-NUM">Pôle UnivRennes - Mathématiques - Numérique </idno>
          </seriesStmt>
          <notesStmt>
            <note type="audience" n="2">International</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">Enhancing BERT for Lexical Normalization</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Benjamin</forename>
                    <surname>Muller</surname>
                  </persName>
                  <idno type="halauthorid">1163840-0</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Benoît</forename>
                    <surname>Sagot</surname>
                  </persName>
                  <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">bsagot</idno>
                  <idno type="idhal" notation="numeric">1461</idno>
                  <idno type="halauthorid" notation="string">17075-1461</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/177454229</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
                  <orgName ref="#struct-300009"/>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Djamé</forename>
                    <surname>Seddah</surname>
                  </persName>
                  <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
                  <email type="domain">paris-sorbonne.fr</email>
                  <idno type="idhal" notation="string">djameseddah</idno>
                  <idno type="idhal" notation="numeric">11545</idno>
                  <idno type="halauthorid" notation="string">1878-11545</idno>
                  <idno type="IDREF">https://www.idref.fr/086185136</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
              </analytic>
              <monogr>
                <meeting>
                  <title>The 5th Workshop on Noisy User-generated Text (W-NUT)</title>
                  <date type="start">2019-11-04</date>
                  <settlement>Hong Kong</settlement>
                  <country key="CN">China</country>
                </meeting>
                <imprint/>
              </monogr>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="en">English</language>
            </langUsage>
            <textClass>
              <classCode scheme="halDomain" n="info.info-cl">Computer Science [cs]/Computation and Language [cs.CL]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Language model-based pre-trained representations have become ubiquitous in natural language processing. They have been shown to significantly improve the performance of neu-ral models on a great variety of tasks. However , it remains unclear how useful those general models can be in handling non-canonical text. In this article, focusing on User Generated Content (UGC) in a resource-scarce scenario , we study the ability of BERT (Devlin et al., 2018) to perform lexical normalisation. Our contribution is simple: by framing lexical normalisation as a token prediction task, by enhancing its architecture and by carefully fine-tuning it, we show that BERT can be a competitive lexical normalisation model without the need of any UGC resources aside from 3,000 training sentences. To the best of our knowledge , it is the first work done in adapting and analysing the ability of this model to handle noisy UGC data.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-482775" status="VALID">
          <idno type="RNSR">201722248N</idno>
          <orgName>Automatic Language Modelling and ANAlysis &amp; Computational Humanities</orgName>
          <orgName type="acronym">ALMAnaCH</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.inria.fr/equipes/almanach</ref>
          </desc>
          <listRelation>
            <relation active="#struct-454310" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
          </listRelation>
        </org>
        <org type="laboratory" xml:id="struct-454310" status="VALID">
          <idno type="IdRef">241614864</idno>
          <idno type="RNSR">196718247G</idno>
          <orgName>Inria de Paris</orgName>
          <date type="start">2016-03-10</date>
          <desc>
            <address>
              <addrLine>2 rue Simone Iff -CS 42112 -75589 Paris Cedex 12</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/centre/paris</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
      </listOrg>
      <listOrg type="projects">
        <org type="anrProject" xml:id="projanr-44644" status="VALID">
          <idno type="anr">ANR-16-CE33-0021</idno>
          <orgName>PARSITI</orgName>
          <desc>Analyser l'impossible, Traduire l'improbable</desc>
          <date type="start">2016</date>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>