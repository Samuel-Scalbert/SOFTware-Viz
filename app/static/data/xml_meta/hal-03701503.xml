<?xml version="1.0" encoding="utf-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:hal="http://hal.archives-ouvertes.fr/" version="1.1" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 http://api.archives-ouvertes.fr/documents/aofr-sword.xsd">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>HAL TEI export of hal-03701503</title>
      </titleStmt>
      <publicationStmt>
        <distributor>CCSD</distributor>
        <availability status="restricted">
          <licence target="http://creativecommons.org/licenses/by/4.0/">Distributed under a Creative Commons Attribution 4.0 International License</licence>
        </availability>
        <date when="2024-10-07T15:27:59+02:00"/>
      </publicationStmt>
      <sourceDesc>
        <p part="N">HAL API platform</p>
      </sourceDesc>
    </fileDesc>
  </teiHeader>
  <text>
    <body>
      <listBibl>
        <biblFull>
          <titleStmt>
            <title xml:lang="en">When Being Unseen from mBERT is just the Beginning : Handling New Languages With Multilingual Language Models</title>
            <title xml:lang="fr">Quand être absent de mBERT n'est que le commencement : Gérer de nouvelles langues à l’aide de modèles de langues multilingues</title>
            <author role="aut">
              <persName>
                <forename type="first">Benjamin</forename>
                <surname>Muller</surname>
              </persName>
              <email type="md5">c1304f100758c5e2a54fd4d47f638841</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="numeric">1072747</idno>
              <idno type="halauthorid" notation="string">1163840-1072747</idno>
              <idno type="IDREF">https://www.idref.fr/26738016X</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Antonios</forename>
                <surname>Anastasopoulos</surname>
              </persName>
              <email type="md5">2ada2b9a4c09c5023a840fa9911bd18b</email>
              <email type="domain">gmail.com</email>
              <idno type="idhal" notation="numeric">1144143</idno>
              <idno type="halauthorid" notation="string">1487805-1144143</idno>
              <affiliation ref="#struct-452410"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Benoît</forename>
                <surname>Sagot</surname>
              </persName>
              <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
              <email type="domain">inria.fr</email>
              <idno type="idhal" notation="string">bsagot</idno>
              <idno type="idhal" notation="numeric">1461</idno>
              <idno type="halauthorid" notation="string">17075-1461</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
              <idno type="IDREF">https://www.idref.fr/177454229</idno>
              <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
              <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <author role="aut">
              <persName>
                <forename type="first">Djamé</forename>
                <surname>Seddah</surname>
              </persName>
              <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
              <email type="domain">paris-sorbonne.fr</email>
              <idno type="idhal" notation="string">djameseddah</idno>
              <idno type="idhal" notation="numeric">11545</idno>
              <idno type="halauthorid" notation="string">1878-11545</idno>
              <idno type="IDREF">https://www.idref.fr/086185136</idno>
              <affiliation ref="#struct-482775"/>
            </author>
            <editor role="depositor">
              <persName>
                <forename>Yannick</forename>
                <surname>Parmentier</surname>
              </persName>
              <email type="md5">352bb4f190f0b06536180c4015640614</email>
              <email type="domain">univ-lorraine.fr</email>
            </editor>
          </titleStmt>
          <editionStmt>
            <edition n="v1" type="current">
              <date type="whenSubmitted">2022-06-24 16:42:07</date>
              <date type="whenModified">2023-10-03 17:18:04</date>
              <date type="whenReleased">2022-06-29 09:53:03</date>
              <date type="whenProduced">2022-06-27</date>
              <ref type="annex" subtype="undefined" n="0" target="https://hal.science/hal-03701503v1/file/5937.pdf">
                <date notBefore="2022-06-24"/>
              </ref>
            </edition>
            <respStmt>
              <resp>contributor</resp>
              <name key="102408">
                <persName>
                  <forename>Yannick</forename>
                  <surname>Parmentier</surname>
                </persName>
                <email type="md5">352bb4f190f0b06536180c4015640614</email>
                <email type="domain">univ-lorraine.fr</email>
              </name>
            </respStmt>
          </editionStmt>
          <publicationStmt>
            <distributor>CCSD</distributor>
            <idno type="halId">hal-03701503</idno>
            <idno type="halUri">https://hal.science/hal-03701503</idno>
            <idno type="halBibtex">muller:hal-03701503</idno>
            <idno type="halRefHtml">&lt;i&gt;TALN 2022 - 29° conférence sur le Traitement Automatique des Langues Naturelles&lt;/i&gt;, Jun 2022, Avignon, France. pp.450-451</idno>
            <idno type="halRef">TALN 2022 - 29° conférence sur le Traitement Automatique des Langues Naturelles, Jun 2022, Avignon, France. pp.450-451</idno>
          </publicationStmt>
          <seriesStmt>
            <idno type="stamp" n="INRIA">INRIA - Institut National de Recherche en Informatique et en Automatique</idno>
            <idno type="stamp" n="INRIA-ROCQ">INRIA Paris - Rocquencourt</idno>
            <idno type="stamp" n="TESTALAIN1">TESTALAIN1</idno>
            <idno type="stamp" n="INRIA2">INRIA 2</idno>
            <idno type="stamp" n="TALN-RECITAL">Conférences TALN RECITAL</idno>
            <idno type="stamp" n="TALN-RECITAL2022" corresp="TALN-RECITAL">Actes de la conférence Traitement Automatique des Langues Naturelles (TALN, 29e édition) et Rencontre des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues</idno>
            <idno type="stamp" n="INRIA-ETATSUNIS">Copublications Inria-Etats-Unis</idno>
          </seriesStmt>
          <notesStmt>
            <note type="commentary">Code available at https://github.com/benjamin-mlr/mbert-unseen-languages.git  Apprentissage par transfert.</note>
            <note type="audience" n="3">National</note>
            <note type="invited" n="0">No</note>
            <note type="popular" n="0">No</note>
            <note type="peer" n="1">Yes</note>
            <note type="proceedings" n="1">Yes</note>
          </notesStmt>
          <sourceDesc>
            <biblStruct>
              <analytic>
                <title xml:lang="en">When Being Unseen from mBERT is just the Beginning : Handling New Languages With Multilingual Language Models</title>
                <title xml:lang="fr">Quand être absent de mBERT n'est que le commencement : Gérer de nouvelles langues à l’aide de modèles de langues multilingues</title>
                <author role="aut">
                  <persName>
                    <forename type="first">Benjamin</forename>
                    <surname>Muller</surname>
                  </persName>
                  <email type="md5">c1304f100758c5e2a54fd4d47f638841</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="numeric">1072747</idno>
                  <idno type="halauthorid" notation="string">1163840-1072747</idno>
                  <idno type="IDREF">https://www.idref.fr/26738016X</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Antonios</forename>
                    <surname>Anastasopoulos</surname>
                  </persName>
                  <email type="md5">2ada2b9a4c09c5023a840fa9911bd18b</email>
                  <email type="domain">gmail.com</email>
                  <idno type="idhal" notation="numeric">1144143</idno>
                  <idno type="halauthorid" notation="string">1487805-1144143</idno>
                  <affiliation ref="#struct-452410"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Benoît</forename>
                    <surname>Sagot</surname>
                  </persName>
                  <email type="md5">ef534712ca682bf74ec7eef17d3d1b5f</email>
                  <email type="domain">inria.fr</email>
                  <idno type="idhal" notation="string">bsagot</idno>
                  <idno type="idhal" notation="numeric">1461</idno>
                  <idno type="halauthorid" notation="string">17075-1461</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.com/citations?user=HXUT9ZkAAAAJ&amp;hl=fr</idno>
                  <idno type="IDREF">https://www.idref.fr/177454229</idno>
                  <idno type="GOOGLE SCHOLAR">https://scholar.google.fr/citations?user=HXUT9ZkAAAAJ</idno>
                  <idno type="ORCID">https://orcid.org/0000-0002-0107-8526</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
                <author role="aut">
                  <persName>
                    <forename type="first">Djamé</forename>
                    <surname>Seddah</surname>
                  </persName>
                  <email type="md5">1a46dccff44eefe8ac69598e3b186e83</email>
                  <email type="domain">paris-sorbonne.fr</email>
                  <idno type="idhal" notation="string">djameseddah</idno>
                  <idno type="idhal" notation="numeric">11545</idno>
                  <idno type="halauthorid" notation="string">1878-11545</idno>
                  <idno type="IDREF">https://www.idref.fr/086185136</idno>
                  <affiliation ref="#struct-482775"/>
                </author>
              </analytic>
              <monogr>
                <title level="m">Actes de la 29e Conférence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conférence principale</title>
                <meeting>
                  <title>TALN 2022 - 29° conférence sur le Traitement Automatique des Langues Naturelles</title>
                  <date type="start">2022-06-27</date>
                  <date type="end">2022-07-01</date>
                  <settlement>Avignon</settlement>
                  <country key="FR">France</country>
                </meeting>
                <editor>Estève, Yannick</editor>
                <editor>Jiménez, Tania</editor>
                <editor>Parcollet, Titouan</editor>
                <editor>Zanon Boito, Marcely</editor>
                <imprint>
                  <publisher>ATALA</publisher>
                  <biblScope unit="pp">450-451</biblScope>
                  <date type="datePub">2022</date>
                </imprint>
              </monogr>
              <ref target="https://hal.inria.fr/hal-03251105v1" type="seeAlso"/>
            </biblStruct>
          </sourceDesc>
          <profileDesc>
            <langUsage>
              <language ident="fr">French</language>
            </langUsage>
            <textClass>
              <keywords scheme="author">
                <term xml:lang="fr">Modèles de langues multilingues neuronaux</term>
                <term xml:lang="fr">Langues peu dotées</term>
                <term xml:lang="fr">Translittération</term>
              </keywords>
              <classCode scheme="halDomain" n="info.info-cl">Computer Science [cs]/Computation and Language [cs.CL]</classCode>
              <classCode scheme="halTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halOldTypology" n="COMM">Conference papers</classCode>
              <classCode scheme="halTreeTypology" n="COMM">Conference papers</classCode>
            </textClass>
            <abstract xml:lang="en">
              <p>Transfer learning based on pretraining language models on a large amount of raw data has become a new norm to reach state-of-the-art performance in NLP. Still, it remains unclear how this approach should be applied for unseen languages that are not covered by any available large-scale multilingual language model and for which only a small amount of raw data is generally available. In this work, by comparing multilingual and monolingual models, we show that such models behave in multiple ways on unseen languages. Some languages greatly benefit from transfer learning and behave similarly to closely related high resource languages whereas others apparently do not. Focusing on the latter, we show that this failure to transfer is largely related to the impact of the script used to write such languages. We show that transliterating those languages significantly improves the potential of large-scale multilingual language models on downstream tasks. This result provides a promising direction towards making these massively multilingual models useful for a new set of unseen languages.</p>
            </abstract>
            <abstract xml:lang="fr">
              <p>L’apprentissage par transfert basé sur le pré-entraînement de modèles de langue sur une grande quantité de données brutes est devenu la norme pour obtenir des performances état de l’art en TAL. Cependant, la façon dont cette approche devrait être appliquée pour des langues inconnues, qui ne sont couvertes par aucun modèle de langue multilingue à grande échelle et pour lesquelles seule une petite quantité de données brutes est le plus souvent disponible, n’est pas claire. Dans ce travail, en comparant des modèles multilingues et monolingues, nous montrons que de tels modèles se comportent de multiples façons sur des langues inconnues. Certaines langues bénéficient grandement de l’apprentissage par transfert et se comportent de manière similaire à des langues proches riches en ressource, alors que ce n’est manifestement pas le cas pour d’autres. En nous concentrant sur ces dernières, nous montrons dans ce travail que cet échec du transfert est largement lié à l’impact du script que ces langues utilisent. Nous montrons que la translittération de ces langues améliore considérablement le potentiel des larges modèles de langue neuronaux multilingues pour des tâches en aval. Ce résultat indique une piste prometteuse pour rendre ces modèles massivement multilingues utiles pour de nouveaux ensembles de langues absentes des données d’entraînement.</p>
            </abstract>
          </profileDesc>
        </biblFull>
      </listBibl>
    </body>
    <back>
      <listOrg type="structures">
        <org type="researchteam" xml:id="struct-482775" status="VALID">
          <idno type="RNSR">201722248N</idno>
          <orgName>Automatic Language Modelling and ANAlysis &amp; Computational Humanities</orgName>
          <orgName type="acronym">ALMAnaCH</orgName>
          <date type="start">2017-01-01</date>
          <desc>
            <address>
              <country key="FR"/>
            </address>
            <ref type="url">https://www.inria.fr/equipes/almanach</ref>
          </desc>
          <listRelation>
            <relation active="#struct-454310" type="direct"/>
            <relation active="#struct-300009" type="indirect"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-452410" status="VALID">
          <idno type="ROR">https://ror.org/02jqj7156</idno>
          <orgName>George Mason University [Fairfax]</orgName>
          <desc>
            <address>
              <addrLine>4400 University Drive, Fairfax, Virginia 22030</addrLine>
              <country key="US"/>
            </address>
            <ref type="url">https://www2.gmu.edu/</ref>
          </desc>
        </org>
        <org type="laboratory" xml:id="struct-454310" status="VALID">
          <idno type="IdRef">241614864</idno>
          <idno type="RNSR">196718247G</idno>
          <orgName>Inria de Paris</orgName>
          <date type="start">2016-03-10</date>
          <desc>
            <address>
              <addrLine>2 rue Simone Iff -CS 42112 -75589 Paris Cedex 12</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/centre/paris</ref>
          </desc>
          <listRelation>
            <relation active="#struct-300009" type="direct"/>
          </listRelation>
        </org>
        <org type="institution" xml:id="struct-300009" status="VALID">
          <idno type="ROR">https://ror.org/02kvxyf05</idno>
          <orgName>Institut National de Recherche en Informatique et en Automatique</orgName>
          <orgName type="acronym">Inria</orgName>
          <desc>
            <address>
              <addrLine>Domaine de VoluceauRocquencourt - BP 10578153 Le Chesnay Cedex</addrLine>
              <country key="FR"/>
            </address>
            <ref type="url">http://www.inria.fr/en/</ref>
          </desc>
        </org>
      </listOrg>
    </back>
  </text>
</TEI>